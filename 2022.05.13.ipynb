{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ae9dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/77 [==============================] - 1s 2ms/step - loss: 10.5440 - accuracy: 0.6159\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 5.4367 - accuracy: 0.6029\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.9292 - accuracy: 0.5208\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.5346 - accuracy: 0.5208\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8896 - accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8072 - accuracy: 0.5234\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7655 - accuracy: 0.6549\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.6628\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.6706\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.6758\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.6797\n",
      "Epoch 12/200\n",
      "77/77 [==============================] - 0s 823us/step - loss: 0.6198 - accuracy: 0.6823\n",
      "Epoch 13/200\n",
      "77/77 [==============================] - 0s 844us/step - loss: 0.6072 - accuracy: 0.6979\n",
      "Epoch 14/200\n",
      "77/77 [==============================] - 0s 821us/step - loss: 0.6112 - accuracy: 0.6966\n",
      "Epoch 15/200\n",
      "77/77 [==============================] - 0s 847us/step - loss: 0.5993 - accuracy: 0.7005\n",
      "Epoch 16/200\n",
      "77/77 [==============================] - 0s 833us/step - loss: 0.5894 - accuracy: 0.6940\n",
      "Epoch 17/200\n",
      "77/77 [==============================] - 0s 824us/step - loss: 0.5915 - accuracy: 0.7057\n",
      "Epoch 18/200\n",
      "77/77 [==============================] - 0s 863us/step - loss: 0.5854 - accuracy: 0.7122\n",
      "Epoch 19/200\n",
      "77/77 [==============================] - 0s 830us/step - loss: 0.5873 - accuracy: 0.6992\n",
      "Epoch 20/200\n",
      "77/77 [==============================] - 0s 862us/step - loss: 0.5820 - accuracy: 0.7070\n",
      "Epoch 21/200\n",
      "77/77 [==============================] - 0s 903us/step - loss: 0.5838 - accuracy: 0.6810\n",
      "Epoch 22/200\n",
      "77/77 [==============================] - 0s 921us/step - loss: 0.5759 - accuracy: 0.7109\n",
      "Epoch 23/200\n",
      "77/77 [==============================] - 0s 927us/step - loss: 0.5752 - accuracy: 0.7148\n",
      "Epoch 24/200\n",
      "77/77 [==============================] - 0s 864us/step - loss: 0.5767 - accuracy: 0.7070\n",
      "Epoch 25/200\n",
      "77/77 [==============================] - 0s 849us/step - loss: 0.5737 - accuracy: 0.7122\n",
      "Epoch 26/200\n",
      "77/77 [==============================] - 0s 890us/step - loss: 0.5664 - accuracy: 0.7161\n",
      "Epoch 27/200\n",
      "77/77 [==============================] - 0s 862us/step - loss: 0.5801 - accuracy: 0.7057\n",
      "Epoch 28/200\n",
      "77/77 [==============================] - 0s 853us/step - loss: 0.5755 - accuracy: 0.7174\n",
      "Epoch 29/200\n",
      "77/77 [==============================] - 0s 827us/step - loss: 0.5654 - accuracy: 0.7161\n",
      "Epoch 30/200\n",
      "77/77 [==============================] - 0s 855us/step - loss: 0.5635 - accuracy: 0.7188\n",
      "Epoch 31/200\n",
      "77/77 [==============================] - 0s 772us/step - loss: 0.5602 - accuracy: 0.7122\n",
      "Epoch 32/200\n",
      "77/77 [==============================] - 0s 859us/step - loss: 0.5683 - accuracy: 0.7109\n",
      "Epoch 33/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7018\n",
      "Epoch 34/200\n",
      "77/77 [==============================] - 0s 863us/step - loss: 0.5578 - accuracy: 0.7214\n",
      "Epoch 35/200\n",
      "77/77 [==============================] - 0s 793us/step - loss: 0.5563 - accuracy: 0.7305\n",
      "Epoch 36/200\n",
      "77/77 [==============================] - 0s 817us/step - loss: 0.5657 - accuracy: 0.7122\n",
      "Epoch 37/200\n",
      "77/77 [==============================] - 0s 807us/step - loss: 0.5529 - accuracy: 0.7070\n",
      "Epoch 38/200\n",
      "77/77 [==============================] - 0s 826us/step - loss: 0.5537 - accuracy: 0.7227\n",
      "Epoch 39/200\n",
      "77/77 [==============================] - 0s 875us/step - loss: 0.5552 - accuracy: 0.7174\n",
      "Epoch 40/200\n",
      "77/77 [==============================] - 0s 803us/step - loss: 0.5539 - accuracy: 0.7292\n",
      "Epoch 41/200\n",
      "77/77 [==============================] - 0s 825us/step - loss: 0.5523 - accuracy: 0.7253\n",
      "Epoch 42/200\n",
      "77/77 [==============================] - 0s 809us/step - loss: 0.5533 - accuracy: 0.7227\n",
      "Epoch 43/200\n",
      "77/77 [==============================] - 0s 825us/step - loss: 0.5535 - accuracy: 0.7201\n",
      "Epoch 44/200\n",
      "77/77 [==============================] - 0s 852us/step - loss: 0.5433 - accuracy: 0.7240\n",
      "Epoch 45/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.7122\n",
      "Epoch 46/200\n",
      "77/77 [==============================] - 0s 874us/step - loss: 0.5478 - accuracy: 0.7161\n",
      "Epoch 47/200\n",
      "77/77 [==============================] - 0s 832us/step - loss: 0.5480 - accuracy: 0.7266\n",
      "Epoch 48/200\n",
      "77/77 [==============================] - 0s 888us/step - loss: 0.5413 - accuracy: 0.7318\n",
      "Epoch 49/200\n",
      "77/77 [==============================] - 0s 900us/step - loss: 0.5410 - accuracy: 0.7253\n",
      "Epoch 50/200\n",
      "77/77 [==============================] - 0s 862us/step - loss: 0.5396 - accuracy: 0.7318\n",
      "Epoch 51/200\n",
      "77/77 [==============================] - 0s 849us/step - loss: 0.5349 - accuracy: 0.7279\n",
      "Epoch 52/200\n",
      "77/77 [==============================] - 0s 857us/step - loss: 0.5345 - accuracy: 0.7383\n",
      "Epoch 53/200\n",
      "77/77 [==============================] - 0s 836us/step - loss: 0.5354 - accuracy: 0.7240\n",
      "Epoch 54/200\n",
      "77/77 [==============================] - 0s 844us/step - loss: 0.5387 - accuracy: 0.7188\n",
      "Epoch 55/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7253\n",
      "Epoch 56/200\n",
      "77/77 [==============================] - 0s 793us/step - loss: 0.5412 - accuracy: 0.7174\n",
      "Epoch 57/200\n",
      "77/77 [==============================] - 0s 761us/step - loss: 0.5511 - accuracy: 0.7240\n",
      "Epoch 58/200\n",
      "77/77 [==============================] - 0s 739us/step - loss: 0.5298 - accuracy: 0.7331\n",
      "Epoch 59/200\n",
      "77/77 [==============================] - 0s 792us/step - loss: 0.5324 - accuracy: 0.7344\n",
      "Epoch 60/200\n",
      "77/77 [==============================] - 0s 782us/step - loss: 0.5280 - accuracy: 0.7292\n",
      "Epoch 61/200\n",
      "77/77 [==============================] - 0s 755us/step - loss: 0.5304 - accuracy: 0.7292\n",
      "Epoch 62/200\n",
      "77/77 [==============================] - 0s 735us/step - loss: 0.5373 - accuracy: 0.7214\n",
      "Epoch 63/200\n",
      "77/77 [==============================] - 0s 723us/step - loss: 0.5283 - accuracy: 0.7357\n",
      "Epoch 64/200\n",
      "77/77 [==============================] - 0s 685us/step - loss: 0.5234 - accuracy: 0.7396\n",
      "Epoch 65/200\n",
      "77/77 [==============================] - 0s 698us/step - loss: 0.5239 - accuracy: 0.7383\n",
      "Epoch 66/200\n",
      "77/77 [==============================] - 0s 807us/step - loss: 0.5215 - accuracy: 0.7344\n",
      "Epoch 67/200\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.5193 - accuracy: 0.7396\n",
      "Epoch 68/200\n",
      "77/77 [==============================] - 0s 822us/step - loss: 0.5241 - accuracy: 0.7357\n",
      "Epoch 69/200\n",
      "77/77 [==============================] - 0s 789us/step - loss: 0.5224 - accuracy: 0.7370\n",
      "Epoch 70/200\n",
      "77/77 [==============================] - 0s 804us/step - loss: 0.5183 - accuracy: 0.7383\n",
      "Epoch 71/200\n",
      "77/77 [==============================] - 0s 798us/step - loss: 0.5164 - accuracy: 0.7344\n",
      "Epoch 72/200\n",
      "77/77 [==============================] - 0s 759us/step - loss: 0.5182 - accuracy: 0.7357\n",
      "Epoch 73/200\n",
      "77/77 [==============================] - 0s 834us/step - loss: 0.5178 - accuracy: 0.7292\n",
      "Epoch 74/200\n",
      "77/77 [==============================] - 0s 821us/step - loss: 0.5187 - accuracy: 0.7396\n",
      "Epoch 75/200\n",
      "77/77 [==============================] - 0s 787us/step - loss: 0.5240 - accuracy: 0.7344\n",
      "Epoch 76/200\n",
      "77/77 [==============================] - 0s 817us/step - loss: 0.5209 - accuracy: 0.7370\n",
      "Epoch 77/200\n",
      "77/77 [==============================] - 0s 759us/step - loss: 0.5177 - accuracy: 0.7331\n",
      "Epoch 78/200\n",
      "77/77 [==============================] - 0s 802us/step - loss: 0.5169 - accuracy: 0.7370\n",
      "Epoch 79/200\n",
      "77/77 [==============================] - 0s 833us/step - loss: 0.5225 - accuracy: 0.7318\n",
      "Epoch 80/200\n",
      "77/77 [==============================] - 0s 776us/step - loss: 0.5092 - accuracy: 0.7435\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 786us/step - loss: 0.5121 - accuracy: 0.7422\n",
      "Epoch 82/200\n",
      "77/77 [==============================] - 0s 710us/step - loss: 0.5087 - accuracy: 0.7461\n",
      "Epoch 83/200\n",
      "77/77 [==============================] - 0s 778us/step - loss: 0.5171 - accuracy: 0.7344\n",
      "Epoch 84/200\n",
      "77/77 [==============================] - 0s 733us/step - loss: 0.5120 - accuracy: 0.7305\n",
      "Epoch 85/200\n",
      "77/77 [==============================] - 0s 759us/step - loss: 0.5088 - accuracy: 0.7461\n",
      "Epoch 86/200\n",
      "77/77 [==============================] - 0s 734us/step - loss: 0.5046 - accuracy: 0.7513\n",
      "Epoch 87/200\n",
      "77/77 [==============================] - 0s 789us/step - loss: 0.5061 - accuracy: 0.7500\n",
      "Epoch 88/200\n",
      "77/77 [==============================] - 0s 733us/step - loss: 0.5073 - accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "77/77 [==============================] - 0s 736us/step - loss: 0.5080 - accuracy: 0.7474\n",
      "Epoch 90/200\n",
      "77/77 [==============================] - 0s 731us/step - loss: 0.5111 - accuracy: 0.7357\n",
      "Epoch 91/200\n",
      "77/77 [==============================] - 0s 744us/step - loss: 0.5293 - accuracy: 0.7305\n",
      "Epoch 92/200\n",
      "77/77 [==============================] - 0s 677us/step - loss: 0.5144 - accuracy: 0.7513\n",
      "Epoch 93/200\n",
      "77/77 [==============================] - 0s 771us/step - loss: 0.5008 - accuracy: 0.7513\n",
      "Epoch 94/200\n",
      "77/77 [==============================] - 0s 711us/step - loss: 0.5034 - accuracy: 0.7461\n",
      "Epoch 95/200\n",
      "77/77 [==============================] - 0s 745us/step - loss: 0.5097 - accuracy: 0.7448\n",
      "Epoch 96/200\n",
      "77/77 [==============================] - 0s 693us/step - loss: 0.4999 - accuracy: 0.7318\n",
      "Epoch 97/200\n",
      "77/77 [==============================] - 0s 642us/step - loss: 0.4978 - accuracy: 0.7552\n",
      "Epoch 98/200\n",
      "77/77 [==============================] - 0s 788us/step - loss: 0.5050 - accuracy: 0.7344\n",
      "Epoch 99/200\n",
      "77/77 [==============================] - 0s 687us/step - loss: 0.5071 - accuracy: 0.7500\n",
      "Epoch 100/200\n",
      "77/77 [==============================] - 0s 726us/step - loss: 0.5004 - accuracy: 0.7513\n",
      "Epoch 101/200\n",
      "77/77 [==============================] - 0s 757us/step - loss: 0.5015 - accuracy: 0.7448\n",
      "Epoch 102/200\n",
      "77/77 [==============================] - 0s 751us/step - loss: 0.4960 - accuracy: 0.7526\n",
      "Epoch 103/200\n",
      "77/77 [==============================] - 0s 717us/step - loss: 0.5054 - accuracy: 0.7409\n",
      "Epoch 104/200\n",
      "77/77 [==============================] - 0s 750us/step - loss: 0.4959 - accuracy: 0.7552\n",
      "Epoch 105/200\n",
      "77/77 [==============================] - 0s 739us/step - loss: 0.4943 - accuracy: 0.7487\n",
      "Epoch 106/200\n",
      "77/77 [==============================] - 0s 747us/step - loss: 0.5006 - accuracy: 0.7526\n",
      "Epoch 107/200\n",
      "77/77 [==============================] - 0s 769us/step - loss: 0.5023 - accuracy: 0.7539\n",
      "Epoch 108/200\n",
      "77/77 [==============================] - 0s 782us/step - loss: 0.5055 - accuracy: 0.7526\n",
      "Epoch 109/200\n",
      "77/77 [==============================] - 0s 695us/step - loss: 0.4918 - accuracy: 0.7487\n",
      "Epoch 110/200\n",
      "77/77 [==============================] - 0s 756us/step - loss: 0.5006 - accuracy: 0.7578\n",
      "Epoch 111/200\n",
      "77/77 [==============================] - 0s 712us/step - loss: 0.4911 - accuracy: 0.7617\n",
      "Epoch 112/200\n",
      "77/77 [==============================] - 0s 720us/step - loss: 0.4916 - accuracy: 0.7500\n",
      "Epoch 113/200\n",
      "77/77 [==============================] - 0s 712us/step - loss: 0.4930 - accuracy: 0.7539\n",
      "Epoch 114/200\n",
      "77/77 [==============================] - 0s 806us/step - loss: 0.4937 - accuracy: 0.7578\n",
      "Epoch 115/200\n",
      "77/77 [==============================] - 0s 757us/step - loss: 0.4932 - accuracy: 0.7565\n",
      "Epoch 116/200\n",
      "77/77 [==============================] - 0s 735us/step - loss: 0.4913 - accuracy: 0.7474\n",
      "Epoch 117/200\n",
      "77/77 [==============================] - 0s 743us/step - loss: 0.4969 - accuracy: 0.7539\n",
      "Epoch 118/200\n",
      "77/77 [==============================] - 0s 685us/step - loss: 0.4920 - accuracy: 0.7474\n",
      "Epoch 119/200\n",
      "77/77 [==============================] - 0s 771us/step - loss: 0.5022 - accuracy: 0.7552\n",
      "Epoch 120/200\n",
      "77/77 [==============================] - 0s 722us/step - loss: 0.4908 - accuracy: 0.7461\n",
      "Epoch 121/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.4847 - accuracy: 0.7526\n",
      "Epoch 122/200\n",
      "77/77 [==============================] - 0s 754us/step - loss: 0.4915 - accuracy: 0.7461\n",
      "Epoch 123/200\n",
      "77/77 [==============================] - 0s 744us/step - loss: 0.4918 - accuracy: 0.7461\n",
      "Epoch 124/200\n",
      "77/77 [==============================] - 0s 733us/step - loss: 0.4932 - accuracy: 0.7487\n",
      "Epoch 125/200\n",
      "77/77 [==============================] - 0s 758us/step - loss: 0.4904 - accuracy: 0.7539\n",
      "Epoch 126/200\n",
      "77/77 [==============================] - 0s 759us/step - loss: 0.4814 - accuracy: 0.7630\n",
      "Epoch 127/200\n",
      "77/77 [==============================] - 0s 683us/step - loss: 0.4960 - accuracy: 0.7578\n",
      "Epoch 128/200\n",
      "77/77 [==============================] - 0s 790us/step - loss: 0.4880 - accuracy: 0.7591\n",
      "Epoch 129/200\n",
      "77/77 [==============================] - 0s 790us/step - loss: 0.4992 - accuracy: 0.7331\n",
      "Epoch 130/200\n",
      "77/77 [==============================] - 0s 768us/step - loss: 0.4868 - accuracy: 0.7565\n",
      "Epoch 131/200\n",
      "77/77 [==============================] - 0s 768us/step - loss: 0.4831 - accuracy: 0.7695\n",
      "Epoch 132/200\n",
      "77/77 [==============================] - 0s 804us/step - loss: 0.4854 - accuracy: 0.7552\n",
      "Epoch 133/200\n",
      "77/77 [==============================] - 0s 711us/step - loss: 0.4851 - accuracy: 0.7643\n",
      "Epoch 134/200\n",
      "77/77 [==============================] - 0s 759us/step - loss: 0.4904 - accuracy: 0.7513\n",
      "Epoch 135/200\n",
      "77/77 [==============================] - 0s 740us/step - loss: 0.4940 - accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "77/77 [==============================] - 0s 753us/step - loss: 0.4827 - accuracy: 0.7435\n",
      "Epoch 137/200\n",
      "77/77 [==============================] - 0s 768us/step - loss: 0.4884 - accuracy: 0.7539\n",
      "Epoch 138/200\n",
      "77/77 [==============================] - 0s 779us/step - loss: 0.4964 - accuracy: 0.7539\n",
      "Epoch 139/200\n",
      "77/77 [==============================] - 0s 840us/step - loss: 0.4841 - accuracy: 0.7578\n",
      "Epoch 140/200\n",
      "77/77 [==============================] - 0s 785us/step - loss: 0.4849 - accuracy: 0.7695\n",
      "Epoch 141/200\n",
      "77/77 [==============================] - 0s 740us/step - loss: 0.4792 - accuracy: 0.7539\n",
      "Epoch 142/200\n",
      "77/77 [==============================] - 0s 702us/step - loss: 0.4827 - accuracy: 0.7591\n",
      "Epoch 143/200\n",
      "77/77 [==============================] - 0s 772us/step - loss: 0.4916 - accuracy: 0.7604\n",
      "Epoch 144/200\n",
      "77/77 [==============================] - 0s 737us/step - loss: 0.4814 - accuracy: 0.7578\n",
      "Epoch 145/200\n",
      "77/77 [==============================] - 0s 741us/step - loss: 0.4941 - accuracy: 0.7526\n",
      "Epoch 146/200\n",
      "77/77 [==============================] - 0s 744us/step - loss: 0.4922 - accuracy: 0.7604\n",
      "Epoch 147/200\n",
      "77/77 [==============================] - 0s 775us/step - loss: 0.4797 - accuracy: 0.7513\n",
      "Epoch 148/200\n",
      "77/77 [==============================] - 0s 666us/step - loss: 0.4808 - accuracy: 0.7513\n",
      "Epoch 149/200\n",
      "77/77 [==============================] - 0s 687us/step - loss: 0.4880 - accuracy: 0.7578\n",
      "Epoch 150/200\n",
      "77/77 [==============================] - 0s 727us/step - loss: 0.4795 - accuracy: 0.7591\n",
      "Epoch 151/200\n",
      "77/77 [==============================] - 0s 689us/step - loss: 0.4826 - accuracy: 0.7630\n",
      "Epoch 152/200\n",
      "77/77 [==============================] - 0s 720us/step - loss: 0.4801 - accuracy: 0.7513\n",
      "Epoch 153/200\n",
      "77/77 [==============================] - 0s 717us/step - loss: 0.4805 - accuracy: 0.7604\n",
      "Epoch 154/200\n",
      "77/77 [==============================] - 0s 747us/step - loss: 0.4812 - accuracy: 0.7656\n",
      "Epoch 155/200\n",
      "77/77 [==============================] - 0s 811us/step - loss: 0.4752 - accuracy: 0.7591\n",
      "Epoch 156/200\n",
      "77/77 [==============================] - 0s 776us/step - loss: 0.4727 - accuracy: 0.7734\n",
      "Epoch 157/200\n",
      "77/77 [==============================] - 0s 728us/step - loss: 0.4836 - accuracy: 0.7539\n",
      "Epoch 158/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.4739 - accuracy: 0.7682\n",
      "Epoch 159/200\n",
      "77/77 [==============================] - 0s 725us/step - loss: 0.4785 - accuracy: 0.7643\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 762us/step - loss: 0.4851 - accuracy: 0.7539\n",
      "Epoch 161/200\n",
      "77/77 [==============================] - 0s 755us/step - loss: 0.4796 - accuracy: 0.7695\n",
      "Epoch 162/200\n",
      "77/77 [==============================] - 0s 782us/step - loss: 0.4798 - accuracy: 0.7565\n",
      "Epoch 163/200\n",
      "77/77 [==============================] - 0s 752us/step - loss: 0.4780 - accuracy: 0.7643\n",
      "Epoch 164/200\n",
      "77/77 [==============================] - 0s 813us/step - loss: 0.4776 - accuracy: 0.7695\n",
      "Epoch 165/200\n",
      "77/77 [==============================] - 0s 779us/step - loss: 0.4839 - accuracy: 0.7591\n",
      "Epoch 166/200\n",
      "77/77 [==============================] - 0s 779us/step - loss: 0.4726 - accuracy: 0.7760\n",
      "Epoch 167/200\n",
      "77/77 [==============================] - 0s 720us/step - loss: 0.4675 - accuracy: 0.7721\n",
      "Epoch 168/200\n",
      "77/77 [==============================] - 0s 684us/step - loss: 0.4769 - accuracy: 0.7630\n",
      "Epoch 169/200\n",
      "77/77 [==============================] - 0s 755us/step - loss: 0.4698 - accuracy: 0.7721\n",
      "Epoch 170/200\n",
      "77/77 [==============================] - 0s 763us/step - loss: 0.4785 - accuracy: 0.7630\n",
      "Epoch 171/200\n",
      "77/77 [==============================] - 0s 654us/step - loss: 0.4658 - accuracy: 0.7669\n",
      "Epoch 172/200\n",
      "77/77 [==============================] - 0s 722us/step - loss: 0.4701 - accuracy: 0.7695\n",
      "Epoch 173/200\n",
      "77/77 [==============================] - 0s 680us/step - loss: 0.4748 - accuracy: 0.7695\n",
      "Epoch 174/200\n",
      "77/77 [==============================] - 0s 737us/step - loss: 0.4653 - accuracy: 0.7643\n",
      "Epoch 175/200\n",
      "77/77 [==============================] - 0s 706us/step - loss: 0.4747 - accuracy: 0.7721\n",
      "Epoch 176/200\n",
      "77/77 [==============================] - 0s 725us/step - loss: 0.4696 - accuracy: 0.7669\n",
      "Epoch 177/200\n",
      "77/77 [==============================] - 0s 710us/step - loss: 0.4744 - accuracy: 0.7643\n",
      "Epoch 178/200\n",
      "77/77 [==============================] - 0s 679us/step - loss: 0.4701 - accuracy: 0.7630\n",
      "Epoch 179/200\n",
      "77/77 [==============================] - 0s 775us/step - loss: 0.4757 - accuracy: 0.7643\n",
      "Epoch 180/200\n",
      "77/77 [==============================] - 0s 668us/step - loss: 0.4661 - accuracy: 0.7552\n",
      "Epoch 181/200\n",
      "77/77 [==============================] - 0s 703us/step - loss: 0.4727 - accuracy: 0.7682\n",
      "Epoch 182/200\n",
      "77/77 [==============================] - 0s 793us/step - loss: 0.4830 - accuracy: 0.7708\n",
      "Epoch 183/200\n",
      "77/77 [==============================] - 0s 765us/step - loss: 0.4648 - accuracy: 0.7604\n",
      "Epoch 184/200\n",
      "77/77 [==============================] - 0s 737us/step - loss: 0.4642 - accuracy: 0.7708\n",
      "Epoch 185/200\n",
      "77/77 [==============================] - 0s 807us/step - loss: 0.4665 - accuracy: 0.7643\n",
      "Epoch 186/200\n",
      "77/77 [==============================] - 0s 733us/step - loss: 0.4678 - accuracy: 0.7747\n",
      "Epoch 187/200\n",
      "77/77 [==============================] - 0s 747us/step - loss: 0.4779 - accuracy: 0.7630\n",
      "Epoch 188/200\n",
      "77/77 [==============================] - 0s 796us/step - loss: 0.4773 - accuracy: 0.7643\n",
      "Epoch 189/200\n",
      "77/77 [==============================] - 0s 737us/step - loss: 0.4652 - accuracy: 0.7708\n",
      "Epoch 190/200\n",
      "77/77 [==============================] - 0s 798us/step - loss: 0.4712 - accuracy: 0.7747\n",
      "Epoch 191/200\n",
      "77/77 [==============================] - 0s 796us/step - loss: 0.4654 - accuracy: 0.7721\n",
      "Epoch 192/200\n",
      "77/77 [==============================] - 0s 761us/step - loss: 0.4674 - accuracy: 0.7591\n",
      "Epoch 193/200\n",
      "77/77 [==============================] - 0s 726us/step - loss: 0.4768 - accuracy: 0.7734\n",
      "Epoch 194/200\n",
      "77/77 [==============================] - 0s 790us/step - loss: 0.4770 - accuracy: 0.7682\n",
      "Epoch 195/200\n",
      "77/77 [==============================] - 0s 747us/step - loss: 0.4659 - accuracy: 0.7786\n",
      "Epoch 196/200\n",
      "77/77 [==============================] - 0s 737us/step - loss: 0.4789 - accuracy: 0.7617\n",
      "Epoch 197/200\n",
      "77/77 [==============================] - 0s 805us/step - loss: 0.4738 - accuracy: 0.7695\n",
      "Epoch 198/200\n",
      "77/77 [==============================] - 0s 778us/step - loss: 0.4705 - accuracy: 0.7591\n",
      "Epoch 199/200\n",
      "77/77 [==============================] - 0s 798us/step - loss: 0.4688 - accuracy: 0.7760\n",
      "Epoch 200/200\n",
      "77/77 [==============================] - 0s 736us/step - loss: 0.4664 - accuracy: 0.7760\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7734\n",
      "\n",
      " Accuracy: 0.7734\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "numpy.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\",\n",
    "                       delimiter=\",\")\n",
    "X=dataset[:,0:8]\n",
    "Y=dataset[:,8]\n",
    "\n",
    "#모델의 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "#모델 컴파일\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics=['accuracy'])\n",
    "#모델 실행\n",
    "model.fit(X,Y,epochs=200,batch_size=10)\n",
    "\n",
    "#결과 출력\n",
    "print(\"\\n Accuracy: %.4f\"%(model.evaluate(X,Y)[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97c0cb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 823.25x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 0s 656us/step - loss: 1.3259 - accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 636us/step - loss: 0.8409 - accuracy: 0.6333\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 683us/step - loss: 0.7110 - accuracy: 0.7267\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 748us/step - loss: 0.6229 - accuracy: 0.6867\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 784us/step - loss: 0.5542 - accuracy: 0.7933\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 750us/step - loss: 0.4988 - accuracy: 0.9067\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 703us/step - loss: 0.4562 - accuracy: 0.9133\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 712us/step - loss: 0.4287 - accuracy: 0.9067\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 728us/step - loss: 0.4006 - accuracy: 0.9267\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 777us/step - loss: 0.3773 - accuracy: 0.9733\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 646us/step - loss: 0.3569 - accuracy: 0.9267\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 666us/step - loss: 0.3367 - accuracy: 0.9333\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 658us/step - loss: 0.3272 - accuracy: 0.9600\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 637us/step - loss: 0.3060 - accuracy: 0.9667\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 705us/step - loss: 0.2920 - accuracy: 0.9667\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 681us/step - loss: 0.2784 - accuracy: 0.9600\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 745us/step - loss: 0.2697 - accuracy: 0.9600\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 727us/step - loss: 0.2639 - accuracy: 0.9533\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 688us/step - loss: 0.2473 - accuracy: 0.9733\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 663us/step - loss: 0.2359 - accuracy: 0.9733\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 656us/step - loss: 0.2274 - accuracy: 0.9733\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 663us/step - loss: 0.2225 - accuracy: 0.9733\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 663us/step - loss: 0.2106 - accuracy: 0.9733\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 654us/step - loss: 0.2062 - accuracy: 0.9667\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 669us/step - loss: 0.1939 - accuracy: 0.9800\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 740us/step - loss: 0.1896 - accuracy: 0.9733\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.1832 - accuracy: 0.9667\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 689us/step - loss: 0.1683 - accuracy: 0.9800\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 714us/step - loss: 0.1714 - accuracy: 0.9667\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 0s 892us/step - loss: 0.1693 - accuracy: 0.9667\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1619 - accuracy: 0.9733\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9667\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 703us/step - loss: 0.1515 - accuracy: 0.9800\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 937us/step - loss: 0.1458 - accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 0s 910us/step - loss: 0.1427 - accuracy: 0.9733\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 850us/step - loss: 0.1421 - accuracy: 0.9667\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 0s 698us/step - loss: 0.1321 - accuracy: 0.9667\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 0s 756us/step - loss: 0.1348 - accuracy: 0.9667\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 0s 573us/step - loss: 0.1274 - accuracy: 0.9800\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 0s 997us/step - loss: 0.1313 - accuracy: 0.9667\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9733\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 0s 618us/step - loss: 0.1212 - accuracy: 0.9733\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 0s 628us/step - loss: 0.1201 - accuracy: 0.9800\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 0s 715us/step - loss: 0.1156 - accuracy: 0.9667\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 0s 687us/step - loss: 0.1205 - accuracy: 0.9600\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 0s 659us/step - loss: 0.1142 - accuracy: 0.9667\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 0s 636us/step - loss: 0.1148 - accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 0s 643us/step - loss: 0.1099 - accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 0s 610us/step - loss: 0.1084 - accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 0s 627us/step - loss: 0.1112 - accuracy: 0.9533\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.1024 - accuracy: 0.9733\n",
      "\n",
      " Accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numpy.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv(\"iris.csv\", names =\n",
    "                 [\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"species\"])\n",
    "\n",
    "sns.pairplot(df, hue = 'species');\n",
    "plt.show()\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y_obj = dataset[:,4]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "Y_encode = tf.keras.utils.to_categorical(Y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim = 4, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X, Y_encode, epochs = 50, batch_size = 1)\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" %(model.evaluate(X, Y_encode)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b924a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "29/29 [==============================] - 1s 1ms/step - loss: 0.2468 - accuracy: 0.4837\n",
      "Epoch 2/130\n",
      "29/29 [==============================] - 0s 756us/step - loss: 0.2384 - accuracy: 0.6013\n",
      "Epoch 3/130\n",
      "29/29 [==============================] - 0s 840us/step - loss: 0.2153 - accuracy: 0.6879\n",
      "Epoch 4/130\n",
      "29/29 [==============================] - 0s 888us/step - loss: 0.2156 - accuracy: 0.7034\n",
      "Epoch 5/130\n",
      "29/29 [==============================] - 0s 885us/step - loss: 0.1945 - accuracy: 0.7643\n",
      "Epoch 6/130\n",
      "29/29 [==============================] - 0s 924us/step - loss: 0.1900 - accuracy: 0.7571\n",
      "Epoch 7/130\n",
      "29/29 [==============================] - 0s 903us/step - loss: 0.1884 - accuracy: 0.7188\n",
      "Epoch 8/130\n",
      "29/29 [==============================] - 0s 881us/step - loss: 0.1708 - accuracy: 0.8209\n",
      "Epoch 9/130\n",
      "29/29 [==============================] - 0s 900us/step - loss: 0.1602 - accuracy: 0.7874\n",
      "Epoch 10/130\n",
      "29/29 [==============================] - 0s 898us/step - loss: 0.1594 - accuracy: 0.8317\n",
      "Epoch 11/130\n",
      "29/29 [==============================] - 0s 973us/step - loss: 0.1691 - accuracy: 0.7945\n",
      "Epoch 12/130\n",
      "29/29 [==============================] - 0s 951us/step - loss: 0.1416 - accuracy: 0.8258\n",
      "Epoch 13/130\n",
      "29/29 [==============================] - 0s 825us/step - loss: 0.1480 - accuracy: 0.7864\n",
      "Epoch 14/130\n",
      "29/29 [==============================] - 0s 906us/step - loss: 0.1470 - accuracy: 0.7765\n",
      "Epoch 15/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.8089\n",
      "Epoch 16/130\n",
      "29/29 [==============================] - 0s 873us/step - loss: 0.1321 - accuracy: 0.8124\n",
      "Epoch 17/130\n",
      "29/29 [==============================] - 0s 906us/step - loss: 0.1372 - accuracy: 0.8276\n",
      "Epoch 18/130\n",
      "29/29 [==============================] - 0s 889us/step - loss: 0.1198 - accuracy: 0.8456\n",
      "Epoch 19/130\n",
      "29/29 [==============================] - 0s 813us/step - loss: 0.1423 - accuracy: 0.8069\n",
      "Epoch 20/130\n",
      "29/29 [==============================] - 0s 916us/step - loss: 0.1233 - accuracy: 0.8632\n",
      "Epoch 21/130\n",
      "29/29 [==============================] - 0s 969us/step - loss: 0.1095 - accuracy: 0.8905\n",
      "Epoch 22/130\n",
      "29/29 [==============================] - 0s 835us/step - loss: 0.1183 - accuracy: 0.8588\n",
      "Epoch 23/130\n",
      "29/29 [==============================] - 0s 944us/step - loss: 0.1107 - accuracy: 0.8669\n",
      "Epoch 24/130\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.1078 - accuracy: 0.8887\n",
      "Epoch 25/130\n",
      "29/29 [==============================] - 0s 884us/step - loss: 0.1025 - accuracy: 0.8494\n",
      "Epoch 26/130\n",
      "29/29 [==============================] - 0s 916us/step - loss: 0.0962 - accuracy: 0.8472\n",
      "Epoch 27/130\n",
      "29/29 [==============================] - 0s 905us/step - loss: 0.0983 - accuracy: 0.8730\n",
      "Epoch 28/130\n",
      "29/29 [==============================] - 0s 837us/step - loss: 0.1062 - accuracy: 0.8712\n",
      "Epoch 29/130\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.0852 - accuracy: 0.8897\n",
      "Epoch 30/130\n",
      "29/29 [==============================] - 0s 885us/step - loss: 0.0823 - accuracy: 0.9166\n",
      "Epoch 31/130\n",
      "29/29 [==============================] - 0s 766us/step - loss: 0.0888 - accuracy: 0.9062\n",
      "Epoch 32/130\n",
      "29/29 [==============================] - 0s 918us/step - loss: 0.0802 - accuracy: 0.9318\n",
      "Epoch 33/130\n",
      "29/29 [==============================] - 0s 769us/step - loss: 0.0812 - accuracy: 0.8913\n",
      "Epoch 34/130\n",
      "29/29 [==============================] - 0s 863us/step - loss: 0.0861 - accuracy: 0.9122\n",
      "Epoch 35/130\n",
      "29/29 [==============================] - 0s 941us/step - loss: 0.0822 - accuracy: 0.8897\n",
      "Epoch 36/130\n",
      "29/29 [==============================] - 0s 804us/step - loss: 0.0724 - accuracy: 0.9093\n",
      "Epoch 37/130\n",
      "29/29 [==============================] - 0s 932us/step - loss: 0.0873 - accuracy: 0.8939\n",
      "Epoch 38/130\n",
      "29/29 [==============================] - 0s 949us/step - loss: 0.0631 - accuracy: 0.9486\n",
      "Epoch 39/130\n",
      "29/29 [==============================] - 0s 928us/step - loss: 0.0669 - accuracy: 0.9349\n",
      "Epoch 40/130\n",
      "29/29 [==============================] - 0s 936us/step - loss: 0.0592 - accuracy: 0.9574\n",
      "Epoch 41/130\n",
      "29/29 [==============================] - 0s 789us/step - loss: 0.0654 - accuracy: 0.9301\n",
      "Epoch 42/130\n",
      "29/29 [==============================] - 0s 951us/step - loss: 0.0598 - accuracy: 0.9631\n",
      "Epoch 43/130\n",
      "29/29 [==============================] - 0s 932us/step - loss: 0.0641 - accuracy: 0.9361\n",
      "Epoch 44/130\n",
      "29/29 [==============================] - 0s 880us/step - loss: 0.0575 - accuracy: 0.9467\n",
      "Epoch 45/130\n",
      "29/29 [==============================] - 0s 884us/step - loss: 0.0563 - accuracy: 0.9301\n",
      "Epoch 46/130\n",
      "29/29 [==============================] - 0s 928us/step - loss: 0.0515 - accuracy: 0.9637\n",
      "Epoch 47/130\n",
      "29/29 [==============================] - 0s 828us/step - loss: 0.0489 - accuracy: 0.9492\n",
      "Epoch 48/130\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.0492 - accuracy: 0.9336\n",
      "Epoch 49/130\n",
      "29/29 [==============================] - 0s 940us/step - loss: 0.0451 - accuracy: 0.9620\n",
      "Epoch 50/130\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.0429 - accuracy: 0.9847\n",
      "Epoch 51/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9342\n",
      "Epoch 52/130\n",
      "29/29 [==============================] - 0s 967us/step - loss: 0.0417 - accuracy: 0.9731\n",
      "Epoch 53/130\n",
      "29/29 [==============================] - 0s 892us/step - loss: 0.0401 - accuracy: 0.9537\n",
      "Epoch 54/130\n",
      "29/29 [==============================] - 0s 818us/step - loss: 0.0297 - accuracy: 0.9883\n",
      "Epoch 55/130\n",
      "29/29 [==============================] - 0s 869us/step - loss: 0.0263 - accuracy: 0.9855\n",
      "Epoch 56/130\n",
      "29/29 [==============================] - 0s 816us/step - loss: 0.0378 - accuracy: 0.9935\n",
      "Epoch 57/130\n",
      "29/29 [==============================] - 0s 860us/step - loss: 0.0265 - accuracy: 0.9926\n",
      "Epoch 58/130\n",
      "29/29 [==============================] - 0s 878us/step - loss: 0.0242 - accuracy: 0.9953\n",
      "Epoch 59/130\n",
      "29/29 [==============================] - 0s 857us/step - loss: 0.0273 - accuracy: 0.9993\n",
      "Epoch 60/130\n",
      "29/29 [==============================] - 0s 899us/step - loss: 0.0313 - accuracy: 0.9741\n",
      "Epoch 61/130\n",
      "29/29 [==============================] - 0s 852us/step - loss: 0.0284 - accuracy: 0.9829\n",
      "Epoch 62/130\n",
      "29/29 [==============================] - 0s 911us/step - loss: 0.0279 - accuracy: 0.9706\n",
      "Epoch 63/130\n",
      "29/29 [==============================] - 0s 843us/step - loss: 0.0271 - accuracy: 0.9685\n",
      "Epoch 64/130\n",
      "29/29 [==============================] - 0s 932us/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 65/130\n",
      "29/29 [==============================] - 0s 846us/step - loss: 0.0222 - accuracy: 0.9973\n",
      "Epoch 66/130\n",
      "29/29 [==============================] - 0s 853us/step - loss: 0.0262 - accuracy: 0.9746\n",
      "Epoch 67/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 68/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 69/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 70/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 71/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9897\n",
      "Epoch 72/130\n",
      "29/29 [==============================] - 0s 748us/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 73/130\n",
      "29/29 [==============================] - 0s 713us/step - loss: 0.0227 - accuracy: 0.9801\n",
      "Epoch 74/130\n",
      "29/29 [==============================] - 0s 784us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 75/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 76/130\n",
      "29/29 [==============================] - 0s 641us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 77/130\n",
      "29/29 [==============================] - 0s 749us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 78/130\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 79/130\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 80/130\n",
      "29/29 [==============================] - 0s 748us/step - loss: 0.0101 - accuracy: 0.9959\n",
      "Epoch 81/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 712us/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 82/130\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 83/130\n",
      "29/29 [==============================] - 0s 748us/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 84/130\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 85/130\n",
      "29/29 [==============================] - 0s 641us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 86/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 87/130\n",
      "29/29 [==============================] - 0s 641us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 88/130\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 89/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 90/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 91/130\n",
      "29/29 [==============================] - 0s 713us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 92/130\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 93/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 94/130\n",
      "29/29 [==============================] - 0s 641us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 95/130\n",
      "29/29 [==============================] - 0s 748us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 96/130\n",
      "29/29 [==============================] - 0s 817us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 97/130\n",
      "29/29 [==============================] - 0s 641us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 98/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 99/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 100/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 101/130\n",
      "29/29 [==============================] - 0s 677us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 102/130\n",
      "29/29 [==============================] - 0s 789us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 103/130\n",
      "29/29 [==============================] - 0s 719us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 104/130\n",
      "29/29 [==============================] - 0s 737us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 105/130\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 106/130\n",
      "29/29 [==============================] - 0s 764us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 107/130\n",
      "29/29 [==============================] - 0s 727us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 108/130\n",
      "29/29 [==============================] - 0s 748us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 109/130\n",
      "29/29 [==============================] - 0s 746us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 110/130\n",
      "29/29 [==============================] - 0s 773us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 111/130\n",
      "29/29 [==============================] - 0s 737us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 112/130\n",
      "29/29 [==============================] - 0s 711us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 113/130\n",
      "29/29 [==============================] - 0s 802us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 114/130\n",
      "29/29 [==============================] - 0s 707us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 115/130\n",
      "29/29 [==============================] - 0s 711us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 116/130\n",
      "29/29 [==============================] - 0s 872us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 117/130\n",
      "29/29 [==============================] - 0s 837us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 118/130\n",
      "29/29 [==============================] - 0s 898us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 119/130\n",
      "29/29 [==============================] - 0s 833us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 120/130\n",
      "29/29 [==============================] - 0s 853us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 121/130\n",
      "29/29 [==============================] - 0s 891us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 122/130\n",
      "29/29 [==============================] - 0s 820us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 123/130\n",
      "29/29 [==============================] - 0s 891us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 124/130\n",
      "29/29 [==============================] - 0s 852us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 125/130\n",
      "29/29 [==============================] - 0s 851us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 126/130\n",
      "29/29 [==============================] - 0s 834us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 127/130\n",
      "29/29 [==============================] - 0s 823us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 128/130\n",
      "29/29 [==============================] - 0s 831us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 129/130\n",
      "29/29 [==============================] - 0s 767us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 130/130\n",
      "29/29 [==============================] - 0s 710us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D63C7E2C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.8571\n",
      "\n",
      " Test Accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv(\"sonar.csv\", header = None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y_obj = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y , test_size = 0.3, random_state = seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim = 60, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs = 130, batch_size = 5)\n",
    "\n",
    "print(\"\\n Test Accuracy: %.4f\" %(model.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "# 모델 저장\n",
    "from keras.models import load_model\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6973823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "29/29 [==============================] - 1s 960us/step - loss: 0.2468 - accuracy: 0.4837\n",
      "Epoch 2/130\n",
      "29/29 [==============================] - 0s 792us/step - loss: 0.2384 - accuracy: 0.6013\n",
      "Epoch 3/130\n",
      "29/29 [==============================] - 0s 904us/step - loss: 0.2153 - accuracy: 0.6879\n",
      "Epoch 4/130\n",
      "29/29 [==============================] - 0s 921us/step - loss: 0.2156 - accuracy: 0.7034\n",
      "Epoch 5/130\n",
      "29/29 [==============================] - 0s 851us/step - loss: 0.1945 - accuracy: 0.7643\n",
      "Epoch 6/130\n",
      "29/29 [==============================] - 0s 910us/step - loss: 0.1900 - accuracy: 0.7571\n",
      "Epoch 7/130\n",
      "29/29 [==============================] - 0s 831us/step - loss: 0.1884 - accuracy: 0.7188\n",
      "Epoch 8/130\n",
      "29/29 [==============================] - 0s 784us/step - loss: 0.1708 - accuracy: 0.8209\n",
      "Epoch 9/130\n",
      "29/29 [==============================] - 0s 893us/step - loss: 0.1602 - accuracy: 0.7874\n",
      "Epoch 10/130\n",
      "29/29 [==============================] - 0s 756us/step - loss: 0.1594 - accuracy: 0.8317\n",
      "Epoch 11/130\n",
      "29/29 [==============================] - 0s 871us/step - loss: 0.1691 - accuracy: 0.7945\n",
      "Epoch 12/130\n",
      "29/29 [==============================] - 0s 804us/step - loss: 0.1416 - accuracy: 0.8258\n",
      "Epoch 13/130\n",
      "29/29 [==============================] - 0s 839us/step - loss: 0.1480 - accuracy: 0.7864\n",
      "Epoch 14/130\n",
      "29/29 [==============================] - 0s 925us/step - loss: 0.1470 - accuracy: 0.7765\n",
      "Epoch 15/130\n",
      "29/29 [==============================] - 0s 970us/step - loss: 0.1405 - accuracy: 0.8089\n",
      "Epoch 16/130\n",
      "29/29 [==============================] - 0s 887us/step - loss: 0.1321 - accuracy: 0.8124\n",
      "Epoch 17/130\n",
      "29/29 [==============================] - 0s 811us/step - loss: 0.1372 - accuracy: 0.8276\n",
      "Epoch 18/130\n",
      "29/29 [==============================] - 0s 819us/step - loss: 0.1198 - accuracy: 0.8456\n",
      "Epoch 19/130\n",
      "29/29 [==============================] - 0s 898us/step - loss: 0.1423 - accuracy: 0.8069\n",
      "Epoch 20/130\n",
      "29/29 [==============================] - 0s 828us/step - loss: 0.1233 - accuracy: 0.8632\n",
      "Epoch 21/130\n",
      "29/29 [==============================] - 0s 958us/step - loss: 0.1095 - accuracy: 0.8905\n",
      "Epoch 22/130\n",
      "29/29 [==============================] - 0s 881us/step - loss: 0.1183 - accuracy: 0.8588\n",
      "Epoch 23/130\n",
      "29/29 [==============================] - 0s 916us/step - loss: 0.1107 - accuracy: 0.8669\n",
      "Epoch 24/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.8887\n",
      "Epoch 25/130\n",
      "29/29 [==============================] - 0s 909us/step - loss: 0.1025 - accuracy: 0.8494\n",
      "Epoch 26/130\n",
      "29/29 [==============================] - 0s 834us/step - loss: 0.0962 - accuracy: 0.8472\n",
      "Epoch 27/130\n",
      "29/29 [==============================] - 0s 855us/step - loss: 0.0983 - accuracy: 0.8730\n",
      "Epoch 28/130\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.1062 - accuracy: 0.8712\n",
      "Epoch 29/130\n",
      "29/29 [==============================] - 0s 989us/step - loss: 0.0852 - accuracy: 0.8897\n",
      "Epoch 30/130\n",
      "29/29 [==============================] - 0s 925us/step - loss: 0.0823 - accuracy: 0.9166\n",
      "Epoch 31/130\n",
      "29/29 [==============================] - 0s 957us/step - loss: 0.0888 - accuracy: 0.9062\n",
      "Epoch 32/130\n",
      "29/29 [==============================] - 0s 850us/step - loss: 0.0802 - accuracy: 0.9318\n",
      "Epoch 33/130\n",
      "29/29 [==============================] - 0s 912us/step - loss: 0.0812 - accuracy: 0.8913\n",
      "Epoch 34/130\n",
      "29/29 [==============================] - 0s 965us/step - loss: 0.0861 - accuracy: 0.9122\n",
      "Epoch 35/130\n",
      "29/29 [==============================] - 0s 991us/step - loss: 0.0822 - accuracy: 0.8897\n",
      "Epoch 36/130\n",
      "29/29 [==============================] - 0s 918us/step - loss: 0.0724 - accuracy: 0.9093\n",
      "Epoch 37/130\n",
      "29/29 [==============================] - 0s 977us/step - loss: 0.0873 - accuracy: 0.8939\n",
      "Epoch 38/130\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.0631 - accuracy: 0.9486\n",
      "Epoch 39/130\n",
      "29/29 [==============================] - 0s 938us/step - loss: 0.0669 - accuracy: 0.9349\n",
      "Epoch 40/130\n",
      "29/29 [==============================] - 0s 903us/step - loss: 0.0592 - accuracy: 0.9574\n",
      "Epoch 41/130\n",
      "29/29 [==============================] - 0s 985us/step - loss: 0.0654 - accuracy: 0.9301\n",
      "Epoch 42/130\n",
      "29/29 [==============================] - 0s 939us/step - loss: 0.0598 - accuracy: 0.9631\n",
      "Epoch 43/130\n",
      "29/29 [==============================] - 0s 910us/step - loss: 0.0641 - accuracy: 0.9361\n",
      "Epoch 44/130\n",
      "29/29 [==============================] - 0s 808us/step - loss: 0.0575 - accuracy: 0.9467\n",
      "Epoch 45/130\n",
      "29/29 [==============================] - 0s 875us/step - loss: 0.0563 - accuracy: 0.9301\n",
      "Epoch 46/130\n",
      "29/29 [==============================] - 0s 952us/step - loss: 0.0515 - accuracy: 0.9637\n",
      "Epoch 47/130\n",
      "29/29 [==============================] - 0s 842us/step - loss: 0.0489 - accuracy: 0.9492\n",
      "Epoch 48/130\n",
      "29/29 [==============================] - 0s 923us/step - loss: 0.0492 - accuracy: 0.9336\n",
      "Epoch 49/130\n",
      "29/29 [==============================] - 0s 851us/step - loss: 0.0451 - accuracy: 0.9620\n",
      "Epoch 50/130\n",
      "29/29 [==============================] - 0s 798us/step - loss: 0.0429 - accuracy: 0.9847\n",
      "Epoch 51/130\n",
      "29/29 [==============================] - 0s 944us/step - loss: 0.0504 - accuracy: 0.9342\n",
      "Epoch 52/130\n",
      "29/29 [==============================] - 0s 817us/step - loss: 0.0417 - accuracy: 0.9731\n",
      "Epoch 53/130\n",
      "29/29 [==============================] - 0s 902us/step - loss: 0.0401 - accuracy: 0.9537\n",
      "Epoch 54/130\n",
      "29/29 [==============================] - 0s 958us/step - loss: 0.0297 - accuracy: 0.9883\n",
      "Epoch 55/130\n",
      "29/29 [==============================] - 0s 821us/step - loss: 0.0263 - accuracy: 0.9855\n",
      "Epoch 56/130\n",
      "29/29 [==============================] - 0s 957us/step - loss: 0.0378 - accuracy: 0.9935\n",
      "Epoch 57/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9926\n",
      "Epoch 58/130\n",
      "29/29 [==============================] - 0s 969us/step - loss: 0.0242 - accuracy: 0.9953\n",
      "Epoch 59/130\n",
      "29/29 [==============================] - 0s 924us/step - loss: 0.0273 - accuracy: 0.9993\n",
      "Epoch 60/130\n",
      "29/29 [==============================] - 0s 797us/step - loss: 0.0313 - accuracy: 0.9741\n",
      "Epoch 61/130\n",
      "29/29 [==============================] - 0s 894us/step - loss: 0.0284 - accuracy: 0.9829\n",
      "Epoch 62/130\n",
      "29/29 [==============================] - 0s 906us/step - loss: 0.0279 - accuracy: 0.9706\n",
      "Epoch 63/130\n",
      "29/29 [==============================] - 0s 907us/step - loss: 0.0271 - accuracy: 0.9685\n",
      "Epoch 64/130\n",
      "29/29 [==============================] - 0s 931us/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 65/130\n",
      "29/29 [==============================] - 0s 861us/step - loss: 0.0222 - accuracy: 0.9973\n",
      "Epoch 66/130\n",
      "29/29 [==============================] - 0s 851us/step - loss: 0.0262 - accuracy: 0.9746\n",
      "Epoch 67/130\n",
      "29/29 [==============================] - 0s 907us/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 68/130\n",
      "29/29 [==============================] - 0s 886us/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 69/130\n",
      "29/29 [==============================] - 0s 909us/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 70/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 71/130\n",
      "29/29 [==============================] - 0s 885us/step - loss: 0.0194 - accuracy: 0.9897\n",
      "Epoch 72/130\n",
      "29/29 [==============================] - 0s 820us/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 73/130\n",
      "29/29 [==============================] - 0s 927us/step - loss: 0.0227 - accuracy: 0.9801\n",
      "Epoch 74/130\n",
      "29/29 [==============================] - 0s 868us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 75/130\n",
      "29/29 [==============================] - 0s 802us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 76/130\n",
      "29/29 [==============================] - 0s 922us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 77/130\n",
      "29/29 [==============================] - 0s 818us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 78/130\n",
      "29/29 [==============================] - 0s 882us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 79/130\n",
      "29/29 [==============================] - 0s 840us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 80/130\n",
      "29/29 [==============================] - 0s 803us/step - loss: 0.0101 - accuracy: 0.9959\n",
      "Epoch 81/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 921us/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 82/130\n",
      "29/29 [==============================] - 0s 846us/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 83/130\n",
      "29/29 [==============================] - 0s 877us/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 84/130\n",
      "29/29 [==============================] - 0s 863us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 85/130\n",
      "29/29 [==============================] - 0s 947us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 86/130\n",
      "29/29 [==============================] - 0s 939us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 87/130\n",
      "29/29 [==============================] - 0s 825us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 88/130\n",
      "29/29 [==============================] - 0s 924us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 89/130\n",
      "29/29 [==============================] - 0s 867us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 90/130\n",
      "29/29 [==============================] - 0s 889us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 91/130\n",
      "29/29 [==============================] - 0s 863us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 92/130\n",
      "29/29 [==============================] - 0s 829us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 93/130\n",
      "29/29 [==============================] - 0s 933us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 94/130\n",
      "29/29 [==============================] - 0s 839us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 95/130\n",
      "29/29 [==============================] - 0s 859us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 96/130\n",
      "29/29 [==============================] - 0s 825us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 97/130\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 98/130\n",
      "29/29 [==============================] - 0s 846us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 99/130\n",
      "29/29 [==============================] - 0s 841us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 100/130\n",
      "29/29 [==============================] - 0s 936us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 101/130\n",
      "29/29 [==============================] - 0s 852us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 102/130\n",
      "29/29 [==============================] - 0s 813us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 103/130\n",
      "29/29 [==============================] - 0s 847us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 104/130\n",
      "29/29 [==============================] - 0s 850us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 105/130\n",
      "29/29 [==============================] - 0s 878us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 106/130\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 107/130\n",
      "29/29 [==============================] - 0s 846us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 108/130\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 109/130\n",
      "29/29 [==============================] - 0s 896us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 110/130\n",
      "29/29 [==============================] - 0s 844us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 111/130\n",
      "29/29 [==============================] - 0s 856us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 112/130\n",
      "29/29 [==============================] - 0s 864us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 113/130\n",
      "29/29 [==============================] - 0s 847us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 114/130\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 115/130\n",
      "29/29 [==============================] - 0s 836us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 116/130\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 117/130\n",
      "29/29 [==============================] - 0s 819us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 118/130\n",
      "29/29 [==============================] - 0s 891us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 119/130\n",
      "29/29 [==============================] - 0s 840us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 120/130\n",
      "29/29 [==============================] - 0s 829us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 121/130\n",
      "29/29 [==============================] - 0s 901us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 122/130\n",
      "29/29 [==============================] - 0s 827us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 123/130\n",
      "29/29 [==============================] - 0s 845us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 124/130\n",
      "29/29 [==============================] - 0s 808us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 125/130\n",
      "29/29 [==============================] - 0s 826us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 126/130\n",
      "29/29 [==============================] - 0s 878us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 127/130\n",
      "29/29 [==============================] - 0s 887us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 128/130\n",
      "29/29 [==============================] - 0s 853us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 129/130\n",
      "29/29 [==============================] - 0s 859us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 130/130\n",
      "29/29 [==============================] - 0s 858us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.8571\n",
      "\n",
      " Test Accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv(\"sonar.csv\", header = None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y_obj = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y , test_size = 0.3, random_state = seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim = 60, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs = 130, batch_size = 5)\n",
    "\n",
    "del model\n",
    "model = load_model('my_model.h5')\n",
    "\n",
    "print(\"\\n Test Accuracy: %.4f\" %(model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad65f0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 853us/step - loss: 0.2429 - accuracy: 0.5553\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 790us/step - loss: 0.2281 - accuracy: 0.6556\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 776us/step - loss: 0.2156 - accuracy: 0.7614\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 824us/step - loss: 0.2054 - accuracy: 0.7747\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 826us/step - loss: 0.1945 - accuracy: 0.7360\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 840us/step - loss: 0.1900 - accuracy: 0.7474\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 799us/step - loss: 0.1855 - accuracy: 0.7428\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.1733 - accuracy: 0.7558\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 873us/step - loss: 0.1666 - accuracy: 0.8050\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 930us/step - loss: 0.1453 - accuracy: 0.8428\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1453 - accuracy: 0.8070\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 944us/step - loss: 0.1472 - accuracy: 0.7992\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 921us/step - loss: 0.1309 - accuracy: 0.8007\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 949us/step - loss: 0.1330 - accuracy: 0.8131\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 955us/step - loss: 0.1244 - accuracy: 0.7990\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 952us/step - loss: 0.1188 - accuracy: 0.8570\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 915us/step - loss: 0.1157 - accuracy: 0.8216\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 929us/step - loss: 0.1277 - accuracy: 0.7925\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 792us/step - loss: 0.1334 - accuracy: 0.7982\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.1391 - accuracy: 0.8079\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 853us/step - loss: 0.0954 - accuracy: 0.8741\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.8097\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.1051 - accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 922us/step - loss: 0.1049 - accuracy: 0.8541\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 895us/step - loss: 0.0897 - accuracy: 0.8905\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 914us/step - loss: 0.0989 - accuracy: 0.8942\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 896us/step - loss: 0.1078 - accuracy: 0.8806\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 917us/step - loss: 0.0871 - accuracy: 0.8953\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 999us/step - loss: 0.1044 - accuracy: 0.8650\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 949us/step - loss: 0.0859 - accuracy: 0.9098\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 901us/step - loss: 0.0880 - accuracy: 0.8780\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0765 - accuracy: 0.8934\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 912us/step - loss: 0.0876 - accuracy: 0.8879\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 976us/step - loss: 0.0779 - accuracy: 0.8867\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 983us/step - loss: 0.0906 - accuracy: 0.8792\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 934us/step - loss: 0.0630 - accuracy: 0.9332\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 998us/step - loss: 0.0790 - accuracy: 0.8908\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.8982\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.0749 - accuracy: 0.8905\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 976us/step - loss: 0.0657 - accuracy: 0.9335\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 982us/step - loss: 0.0675 - accuracy: 0.9320\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 979us/step - loss: 0.0784 - accuracy: 0.9028\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 950us/step - loss: 0.0626 - accuracy: 0.9253\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9444\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 940us/step - loss: 0.0639 - accuracy: 0.9465\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 857us/step - loss: 0.0681 - accuracy: 0.9180\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 962us/step - loss: 0.0504 - accuracy: 0.9424\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 943us/step - loss: 0.0671 - accuracy: 0.9470\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 943us/step - loss: 0.0543 - accuracy: 0.9641\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 922us/step - loss: 0.0549 - accuracy: 0.9435\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 970us/step - loss: 0.0581 - accuracy: 0.9314\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9593\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 923us/step - loss: 0.0644 - accuracy: 0.9391\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 930us/step - loss: 0.0359 - accuracy: 0.9606\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 953us/step - loss: 0.0533 - accuracy: 0.9651\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.0489 - accuracy: 0.9612\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 936us/step - loss: 0.0572 - accuracy: 0.9448\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 907us/step - loss: 0.0522 - accuracy: 0.9544\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 969us/step - loss: 0.0479 - accuracy: 0.9664\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 957us/step - loss: 0.0406 - accuracy: 0.9644\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 939us/step - loss: 0.0350 - accuracy: 0.9789\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.0360 - accuracy: 0.9865\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 956us/step - loss: 0.0399 - accuracy: 0.9622\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.0413 - accuracy: 0.9711\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.0389 - accuracy: 0.9651\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 935us/step - loss: 0.0305 - accuracy: 0.9808\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 916us/step - loss: 0.0232 - accuracy: 0.9976\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0299 - accuracy: 0.9903\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 925us/step - loss: 0.0506 - accuracy: 0.9290\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 968us/step - loss: 0.0295 - accuracy: 0.9911\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 994us/step - loss: 0.0314 - accuracy: 0.9843\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 926us/step - loss: 0.0263 - accuracy: 0.9858\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 941us/step - loss: 0.0340 - accuracy: 0.9646\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 983us/step - loss: 0.0430 - accuracy: 0.9686\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 950us/step - loss: 0.0302 - accuracy: 0.9840\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.0337 - accuracy: 0.9806\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.0346 - accuracy: 0.9759\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 932us/step - loss: 0.0230 - accuracy: 0.9896\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9746\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 902us/step - loss: 0.0321 - accuracy: 0.9697\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 937us/step - loss: 0.0321 - accuracy: 0.9709\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 878us/step - loss: 0.0331 - accuracy: 0.9684\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.0184 - accuracy: 0.9941\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 847us/step - loss: 0.0260 - accuracy: 0.9805\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 899us/step - loss: 0.0131 - accuracy: 0.9948\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 899us/step - loss: 0.0247 - accuracy: 0.9766\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.0238 - accuracy: 0.9775\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0216 - accuracy: 0.9886\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.0146 - accuracy: 0.9865\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 867us/step - loss: 0.0249 - accuracy: 0.9825\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 912us/step - loss: 0.0105 - accuracy: 0.9983\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0204 - accuracy: 0.9859\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 880us/step - loss: 0.0204 - accuracy: 0.9849\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0193 - accuracy: 0.9858\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 913us/step - loss: 0.0171 - accuracy: 0.9914\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.0120 - accuracy: 0.9981\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 861us/step - loss: 0.0248 - accuracy: 0.9709\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 875us/step - loss: 0.0187 - accuracy: 0.9817\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.0142 - accuracy: 0.9746\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.2439 - accuracy: 0.7143\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 1ms/step - loss: 0.2538 - accuracy: 0.4714\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 807us/step - loss: 0.2389 - accuracy: 0.5737\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 810us/step - loss: 0.2370 - accuracy: 0.6237\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.2298 - accuracy: 0.6602\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.2175 - accuracy: 0.6697\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 902us/step - loss: 0.2197 - accuracy: 0.6609\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 847us/step - loss: 0.2076 - accuracy: 0.7313\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 850us/step - loss: 0.2009 - accuracy: 0.7059\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.1941 - accuracy: 0.6921\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 848us/step - loss: 0.1869 - accuracy: 0.7515\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 880us/step - loss: 0.1847 - accuracy: 0.7238\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 864us/step - loss: 0.1777 - accuracy: 0.7337\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.1790 - accuracy: 0.7756\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 873us/step - loss: 0.1647 - accuracy: 0.7355\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 904us/step - loss: 0.1671 - accuracy: 0.7620\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 870us/step - loss: 0.1636 - accuracy: 0.7404\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 858us/step - loss: 0.1574 - accuracy: 0.7460\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 892us/step - loss: 0.1437 - accuracy: 0.8364\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 854us/step - loss: 0.1542 - accuracy: 0.7589\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.1664 - accuracy: 0.7754\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 841us/step - loss: 0.1445 - accuracy: 0.8065\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 925us/step - loss: 0.1372 - accuracy: 0.8205\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.1456 - accuracy: 0.8187\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.1361 - accuracy: 0.8271\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.1385 - accuracy: 0.8050\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 861us/step - loss: 0.1191 - accuracy: 0.8562\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 870us/step - loss: 0.1193 - accuracy: 0.8452\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 906us/step - loss: 0.1124 - accuracy: 0.8563\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.1159 - accuracy: 0.8568\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.1294 - accuracy: 0.8135\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 877us/step - loss: 0.1267 - accuracy: 0.8243\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.1146 - accuracy: 0.8786\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 878us/step - loss: 0.1173 - accuracy: 0.8383\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.1083 - accuracy: 0.8505\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.1160 - accuracy: 0.8115\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.1068 - accuracy: 0.8619\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 870us/step - loss: 0.1075 - accuracy: 0.8801\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 917us/step - loss: 0.1088 - accuracy: 0.8338\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 846us/step - loss: 0.0975 - accuracy: 0.8694\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 912us/step - loss: 0.0980 - accuracy: 0.8955\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0985 - accuracy: 0.8763\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 846us/step - loss: 0.0997 - accuracy: 0.8692\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 906us/step - loss: 0.0931 - accuracy: 0.8858\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.0896 - accuracy: 0.8467\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0846 - accuracy: 0.9070\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 818us/step - loss: 0.1050 - accuracy: 0.8199\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 838us/step - loss: 0.0896 - accuracy: 0.8841\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 818us/step - loss: 0.0711 - accuracy: 0.9297\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 902us/step - loss: 0.1083 - accuracy: 0.8500\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 873us/step - loss: 0.0917 - accuracy: 0.8931\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.0906 - accuracy: 0.8789\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 859us/step - loss: 0.0823 - accuracy: 0.9168\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0910 - accuracy: 0.8952\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0674 - accuracy: 0.9238\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.0750 - accuracy: 0.9130\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 859us/step - loss: 0.0881 - accuracy: 0.8934\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 849us/step - loss: 0.0817 - accuracy: 0.8697\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.0913 - accuracy: 0.8908\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0748 - accuracy: 0.9332\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 875us/step - loss: 0.0676 - accuracy: 0.9227\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.0703 - accuracy: 0.9385\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.0997 - accuracy: 0.8595\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 900us/step - loss: 0.0659 - accuracy: 0.8981\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.0674 - accuracy: 0.9374\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 823us/step - loss: 0.0633 - accuracy: 0.9450\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 940us/step - loss: 0.0745 - accuracy: 0.8970\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0627 - accuracy: 0.9446\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.0546 - accuracy: 0.9649\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 842us/step - loss: 0.0636 - accuracy: 0.9295\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 916us/step - loss: 0.0758 - accuracy: 0.9027\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.0657 - accuracy: 0.9484\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 851us/step - loss: 0.0601 - accuracy: 0.9539\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0565 - accuracy: 0.9525\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 913us/step - loss: 0.0517 - accuracy: 0.9528\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.0596 - accuracy: 0.9412\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.0778 - accuracy: 0.8891\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 873us/step - loss: 0.0553 - accuracy: 0.9449\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 818us/step - loss: 0.0594 - accuracy: 0.9659\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 864us/step - loss: 0.0442 - accuracy: 0.9667\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.0558 - accuracy: 0.9603\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.0562 - accuracy: 0.9439\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 878us/step - loss: 0.0514 - accuracy: 0.9614\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0440 - accuracy: 0.9694\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 880us/step - loss: 0.0504 - accuracy: 0.9579\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.0401 - accuracy: 0.9751\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.0501 - accuracy: 0.9719\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 875us/step - loss: 0.0444 - accuracy: 0.9827\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 878us/step - loss: 0.0423 - accuracy: 0.9749\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 864us/step - loss: 0.0510 - accuracy: 0.9551\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 900us/step - loss: 0.0369 - accuracy: 0.9562\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.0481 - accuracy: 0.9667\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 902us/step - loss: 0.0357 - accuracy: 0.9727\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0382 - accuracy: 0.9707\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.0364 - accuracy: 0.9708\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9622\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.0474 - accuracy: 0.9806\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.0320 - accuracy: 0.9848\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.0419 - accuracy: 0.9652\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0326 - accuracy: 0.9843\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 872us/step - loss: 0.0347 - accuracy: 0.9696\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1338 - accuracy: 0.8095\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 998us/step - loss: 0.2443 - accuracy: 0.5591\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 842us/step - loss: 0.2409 - accuracy: 0.5544\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 835us/step - loss: 0.2400 - accuracy: 0.5344\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 837us/step - loss: 0.2312 - accuracy: 0.5469\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 867us/step - loss: 0.2233 - accuracy: 0.5924\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 870us/step - loss: 0.2268 - accuracy: 0.6192\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 913us/step - loss: 0.2198 - accuracy: 0.6208\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.2090 - accuracy: 0.7258\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.2043 - accuracy: 0.7075\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.1914 - accuracy: 0.7749\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 861us/step - loss: 0.1836 - accuracy: 0.7213\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 927us/step - loss: 0.1673 - accuracy: 0.8306\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.1722 - accuracy: 0.7566\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 896us/step - loss: 0.1622 - accuracy: 0.7655\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 877us/step - loss: 0.1493 - accuracy: 0.8093\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.1617 - accuracy: 0.7980\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 904us/step - loss: 0.1415 - accuracy: 0.8274\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.1301 - accuracy: 0.8567\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.1427 - accuracy: 0.8282\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.1484 - accuracy: 0.8033\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 807us/step - loss: 0.1523 - accuracy: 0.7599\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 814us/step - loss: 0.1221 - accuracy: 0.8782\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 812us/step - loss: 0.1245 - accuracy: 0.8319\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.1147 - accuracy: 0.8690\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 896us/step - loss: 0.1073 - accuracy: 0.8705\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 880us/step - loss: 0.1121 - accuracy: 0.8467\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.1044 - accuracy: 0.8910\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 852us/step - loss: 0.1212 - accuracy: 0.8347\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 921us/step - loss: 0.1141 - accuracy: 0.8487\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 927us/step - loss: 0.1023 - accuracy: 0.8949\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 865us/step - loss: 0.1088 - accuracy: 0.8745\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.1034 - accuracy: 0.8951\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.1014 - accuracy: 0.8870\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.0942 - accuracy: 0.9183\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 907us/step - loss: 0.0901 - accuracy: 0.9034\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.1027 - accuracy: 0.8674\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 857us/step - loss: 0.0811 - accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 842us/step - loss: 0.1313 - accuracy: 0.8362\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 862us/step - loss: 0.0817 - accuracy: 0.9031\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 873us/step - loss: 0.0867 - accuracy: 0.8962\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 857us/step - loss: 0.0834 - accuracy: 0.8851\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 853us/step - loss: 0.0885 - accuracy: 0.8933\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 877us/step - loss: 0.1119 - accuracy: 0.8241\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 872us/step - loss: 0.0906 - accuracy: 0.8817\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 877us/step - loss: 0.0849 - accuracy: 0.9177\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.0869 - accuracy: 0.8917\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0862 - accuracy: 0.9052\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.0771 - accuracy: 0.9216\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0928 - accuracy: 0.9040\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 925us/step - loss: 0.0602 - accuracy: 0.9313\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 852us/step - loss: 0.0752 - accuracy: 0.9319\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 906us/step - loss: 0.0806 - accuracy: 0.9136\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.0681 - accuracy: 0.9085\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 872us/step - loss: 0.0631 - accuracy: 0.9339\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 899us/step - loss: 0.0516 - accuracy: 0.9325\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.0754 - accuracy: 0.9401\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 914us/step - loss: 0.0558 - accuracy: 0.9376\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.0589 - accuracy: 0.9644\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 901us/step - loss: 0.0493 - accuracy: 0.9562\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.0526 - accuracy: 0.9643\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 899us/step - loss: 0.0453 - accuracy: 0.9501\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 910us/step - loss: 0.0454 - accuracy: 0.9740\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 918us/step - loss: 0.0523 - accuracy: 0.9540\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 913us/step - loss: 0.0550 - accuracy: 0.9536\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 878us/step - loss: 0.0605 - accuracy: 0.9370\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.0496 - accuracy: 0.9404\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 845us/step - loss: 0.0359 - accuracy: 0.9750\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 853us/step - loss: 0.0531 - accuracy: 0.9489\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 790us/step - loss: 0.0386 - accuracy: 0.9708\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 809us/step - loss: 0.0640 - accuracy: 0.9475\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.0372 - accuracy: 0.9659\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 844us/step - loss: 0.0438 - accuracy: 0.9521\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 852us/step - loss: 0.0474 - accuracy: 0.9532\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0335 - accuracy: 0.9736\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0359 - accuracy: 0.9882\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 892us/step - loss: 0.0403 - accuracy: 0.9709\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0341 - accuracy: 0.9769\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 917us/step - loss: 0.0330 - accuracy: 0.9649\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0397 - accuracy: 0.9701\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 847us/step - loss: 0.0357 - accuracy: 0.9720\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 865us/step - loss: 0.0246 - accuracy: 0.9882\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 920us/step - loss: 0.0529 - accuracy: 0.9662\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 880us/step - loss: 0.0382 - accuracy: 0.9576\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0289 - accuracy: 0.9866\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 744us/step - loss: 0.0270 - accuracy: 0.9775\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 815us/step - loss: 0.0299 - accuracy: 0.9840\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.0265 - accuracy: 0.9771\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 844us/step - loss: 0.0231 - accuracy: 0.9832\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 803us/step - loss: 0.0222 - accuracy: 0.9847\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 841us/step - loss: 0.0165 - accuracy: 0.9917\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 864us/step - loss: 0.0361 - accuracy: 0.9752\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 900us/step - loss: 0.0221 - accuracy: 0.9834\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0242 - accuracy: 0.9884\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.0325 - accuracy: 0.9694\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 858us/step - loss: 0.0247 - accuracy: 0.9791\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 799us/step - loss: 0.0278 - accuracy: 0.9890\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 803us/step - loss: 0.0163 - accuracy: 0.9915\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 820us/step - loss: 0.0337 - accuracy: 0.9689\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0230 - accuracy: 0.9913\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.0165 - accuracy: 0.9861\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1972 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 1ms/step - loss: 0.2612 - accuracy: 0.4624\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 918us/step - loss: 0.2397 - accuracy: 0.6336\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 862us/step - loss: 0.2364 - accuracy: 0.6458\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 962us/step - loss: 0.2277 - accuracy: 0.7351\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 982us/step - loss: 0.2148 - accuracy: 0.7533\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 856us/step - loss: 0.2149 - accuracy: 0.7093\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.1951 - accuracy: 0.7823\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 920us/step - loss: 0.1891 - accuracy: 0.7990\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.8045\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.1756 - accuracy: 0.8078\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.1712 - accuracy: 0.7693\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.1613 - accuracy: 0.8225\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.1485 - accuracy: 0.8149\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 910us/step - loss: 0.1552 - accuracy: 0.7634\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 928us/step - loss: 0.1446 - accuracy: 0.8380\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 943us/step - loss: 0.1396 - accuracy: 0.8328\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 943us/step - loss: 0.1324 - accuracy: 0.8218\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 955us/step - loss: 0.1163 - accuracy: 0.8937\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 964us/step - loss: 0.1198 - accuracy: 0.8579\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 937us/step - loss: 0.1388 - accuracy: 0.8410\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.1209 - accuracy: 0.8443\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.1110 - accuracy: 0.8647\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 862us/step - loss: 0.1084 - accuracy: 0.8788\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 777us/step - loss: 0.0958 - accuracy: 0.8954\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 850us/step - loss: 0.1108 - accuracy: 0.8690\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 953us/step - loss: 0.1006 - accuracy: 0.8766\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.8964\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.8979\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 990us/step - loss: 0.0929 - accuracy: 0.9362\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8226\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.1227 - accuracy: 0.8053\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 906us/step - loss: 0.0978 - accuracy: 0.8767\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 916us/step - loss: 0.0858 - accuracy: 0.9179\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 864us/step - loss: 0.0979 - accuracy: 0.8830\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 892us/step - loss: 0.0949 - accuracy: 0.8868\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 844us/step - loss: 0.0837 - accuracy: 0.8923\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 835us/step - loss: 0.0615 - accuracy: 0.9461\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0853 - accuracy: 0.8830\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 923us/step - loss: 0.0791 - accuracy: 0.9217\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0792 - accuracy: 0.9047\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0776 - accuracy: 0.9069\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 934us/step - loss: 0.0733 - accuracy: 0.9087\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 926us/step - loss: 0.0697 - accuracy: 0.9235\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.0737 - accuracy: 0.9048\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0762 - accuracy: 0.9122\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0669 - accuracy: 0.9342\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 952us/step - loss: 0.0588 - accuracy: 0.9511\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 999us/step - loss: 0.0653 - accuracy: 0.9129\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9242\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 997us/step - loss: 0.0612 - accuracy: 0.9337\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 845us/step - loss: 0.0575 - accuracy: 0.9299\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.0550 - accuracy: 0.9199\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 920us/step - loss: 0.0504 - accuracy: 0.9321\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 899us/step - loss: 0.0551 - accuracy: 0.9408\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 865us/step - loss: 0.0431 - accuracy: 0.9624\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.0705 - accuracy: 0.9119\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 906us/step - loss: 0.0476 - accuracy: 0.9652\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 824us/step - loss: 0.0541 - accuracy: 0.9588\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 865us/step - loss: 0.0469 - accuracy: 0.9533\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 896us/step - loss: 0.0455 - accuracy: 0.9372\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0405 - accuracy: 0.9672\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0411 - accuracy: 0.9654\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.0431 - accuracy: 0.9601\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 855us/step - loss: 0.0273 - accuracy: 0.9888\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.0359 - accuracy: 0.9670\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0335 - accuracy: 0.9829\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 892us/step - loss: 0.0261 - accuracy: 0.9841\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9844\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.0414 - accuracy: 0.9443\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.0353 - accuracy: 0.9567\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.0330 - accuracy: 0.9814\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.0357 - accuracy: 0.9648\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 906us/step - loss: 0.0247 - accuracy: 0.9889\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0259 - accuracy: 0.9833\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 921us/step - loss: 0.0232 - accuracy: 0.9971\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 901us/step - loss: 0.0272 - accuracy: 0.9884\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 904us/step - loss: 0.0233 - accuracy: 0.9840\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0219 - accuracy: 0.9939\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.0207 - accuracy: 0.9955\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.0190 - accuracy: 0.9906\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 924us/step - loss: 0.0188 - accuracy: 0.9959\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 873us/step - loss: 0.0185 - accuracy: 0.9947\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.0207 - accuracy: 0.9969\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 830us/step - loss: 0.0169 - accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 796us/step - loss: 0.0158 - accuracy: 0.9883\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0170 - accuracy: 0.9966\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0207 - accuracy: 0.9883\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 906us/step - loss: 0.0144 - accuracy: 0.9958\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.0175 - accuracy: 0.9932\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 798us/step - loss: 0.0119 - accuracy: 0.9981\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 870us/step - loss: 0.0142 - accuracy: 0.9933\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 892us/step - loss: 0.0140 - accuracy: 0.9983\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 935us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 910us/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 856us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 835us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 832us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 840us/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 936us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0620 - accuracy: 0.9048\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 1ms/step - loss: 0.2565 - accuracy: 0.4062\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 904us/step - loss: 0.2416 - accuracy: 0.6163\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.2337 - accuracy: 0.6586\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.2203 - accuracy: 0.7052\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.2113 - accuracy: 0.6834\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 895us/step - loss: 0.1986 - accuracy: 0.7942\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.1960 - accuracy: 0.7474\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 857us/step - loss: 0.1750 - accuracy: 0.8102\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.1642 - accuracy: 0.8125\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.1513 - accuracy: 0.8275\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 950us/step - loss: 0.1601 - accuracy: 0.7949\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 943us/step - loss: 0.1295 - accuracy: 0.8441\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 962us/step - loss: 0.1494 - accuracy: 0.8021\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.8008\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 847us/step - loss: 0.1250 - accuracy: 0.8488\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 859us/step - loss: 0.1288 - accuracy: 0.8620\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 836us/step - loss: 0.1265 - accuracy: 0.8446\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.1183 - accuracy: 0.8772\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 949us/step - loss: 0.1177 - accuracy: 0.8354\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 920us/step - loss: 0.1281 - accuracy: 0.8536\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 947us/step - loss: 0.1252 - accuracy: 0.8458\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.1072 - accuracy: 0.9051\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 962us/step - loss: 0.0957 - accuracy: 0.9074\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 955us/step - loss: 0.1065 - accuracy: 0.8514\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 927us/step - loss: 0.1105 - accuracy: 0.8698\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 937us/step - loss: 0.1017 - accuracy: 0.8703\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 944us/step - loss: 0.0914 - accuracy: 0.9056\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 954us/step - loss: 0.0786 - accuracy: 0.9123\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 915us/step - loss: 0.0786 - accuracy: 0.9211\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 961us/step - loss: 0.0932 - accuracy: 0.9137\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 948us/step - loss: 0.0745 - accuracy: 0.9129\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 940us/step - loss: 0.0770 - accuracy: 0.8915\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 918us/step - loss: 0.0806 - accuracy: 0.8811\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 949us/step - loss: 0.0721 - accuracy: 0.9439\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.0710 - accuracy: 0.9159\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 842us/step - loss: 0.0595 - accuracy: 0.9263\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0615 - accuracy: 0.9395\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 910us/step - loss: 0.0798 - accuracy: 0.9115\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 933us/step - loss: 0.0611 - accuracy: 0.9440\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 907us/step - loss: 0.0549 - accuracy: 0.9472\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 936us/step - loss: 0.0415 - accuracy: 0.9765\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 923us/step - loss: 0.0568 - accuracy: 0.9266\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.0685 - accuracy: 0.9396\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 925us/step - loss: 0.0537 - accuracy: 0.9446\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 927us/step - loss: 0.0456 - accuracy: 0.9625\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 929us/step - loss: 0.0526 - accuracy: 0.9467\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 939us/step - loss: 0.0452 - accuracy: 0.9847\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 925us/step - loss: 0.0430 - accuracy: 0.9654\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 961us/step - loss: 0.0441 - accuracy: 0.9682\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 923us/step - loss: 0.0358 - accuracy: 0.9745\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 945us/step - loss: 0.0438 - accuracy: 0.9477\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 938us/step - loss: 0.0347 - accuracy: 0.9855\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 878us/step - loss: 0.0391 - accuracy: 0.9792\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 943us/step - loss: 0.0335 - accuracy: 0.9841\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 901us/step - loss: 0.0318 - accuracy: 0.9804\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 966us/step - loss: 0.0261 - accuracy: 0.9936\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 953us/step - loss: 0.0209 - accuracy: 0.9988\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.0204 - accuracy: 0.9976\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 928us/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 941us/step - loss: 0.0287 - accuracy: 0.9883\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 954us/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 940us/step - loss: 0.0172 - accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 949us/step - loss: 0.0205 - accuracy: 0.9921\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 953us/step - loss: 0.0139 - accuracy: 0.9971\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 896us/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 956us/step - loss: 0.0162 - accuracy: 0.9971\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 921us/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 928us/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 904us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 912us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 939us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 934us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 920us/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 837us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 954us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 926us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 914us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 928us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 890us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 912us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 917us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 923us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 947us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 912us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 917us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 905us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 877us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1346 - accuracy: 0.8571\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 1ms/step - loss: 0.2515 - accuracy: 0.4463\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 760us/step - loss: 0.2432 - accuracy: 0.5608\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 843us/step - loss: 0.2265 - accuracy: 0.6432\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.2140 - accuracy: 0.7184\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 856us/step - loss: 0.1932 - accuracy: 0.7755\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 855us/step - loss: 0.1922 - accuracy: 0.7338\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.1775 - accuracy: 0.7504\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.1601 - accuracy: 0.8309\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 848us/step - loss: 0.1616 - accuracy: 0.7812\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 855us/step - loss: 0.1447 - accuracy: 0.8043\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 856us/step - loss: 0.1421 - accuracy: 0.8200\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.1351 - accuracy: 0.8491\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 857us/step - loss: 0.1409 - accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 900us/step - loss: 0.1348 - accuracy: 0.8071\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.1249 - accuracy: 0.8154\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.1267 - accuracy: 0.8824\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.1183 - accuracy: 0.8492\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 853us/step - loss: 0.1104 - accuracy: 0.8882\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.1096 - accuracy: 0.8713\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 878us/step - loss: 0.1301 - accuracy: 0.8057\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 880us/step - loss: 0.1490 - accuracy: 0.7706\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 921us/step - loss: 0.0953 - accuracy: 0.9071\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 864us/step - loss: 0.1150 - accuracy: 0.8565\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.0967 - accuracy: 0.8917\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.0965 - accuracy: 0.8805\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.0867 - accuracy: 0.9001\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.1050 - accuracy: 0.8647\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.1084 - accuracy: 0.9066\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0961 - accuracy: 0.9168\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 852us/step - loss: 0.0931 - accuracy: 0.8722\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0824 - accuracy: 0.8963\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.0686 - accuracy: 0.9427\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 839us/step - loss: 0.0763 - accuracy: 0.9107\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 896us/step - loss: 0.0848 - accuracy: 0.9295\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.0631 - accuracy: 0.9341\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 873us/step - loss: 0.0829 - accuracy: 0.9086\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9525\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.0881 - accuracy: 0.9154\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 875us/step - loss: 0.0717 - accuracy: 0.9374\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 857us/step - loss: 0.0639 - accuracy: 0.9540\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.0642 - accuracy: 0.9134\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 862us/step - loss: 0.0692 - accuracy: 0.9418\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 852us/step - loss: 0.0863 - accuracy: 0.8947\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 836us/step - loss: 0.0638 - accuracy: 0.9157\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 913us/step - loss: 0.0803 - accuracy: 0.9100\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 907us/step - loss: 0.0619 - accuracy: 0.9414\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 899us/step - loss: 0.0790 - accuracy: 0.9364\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.0568 - accuracy: 0.9490\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.0830 - accuracy: 0.9045\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 864us/step - loss: 0.0525 - accuracy: 0.9451\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 847us/step - loss: 0.0648 - accuracy: 0.9485\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 849us/step - loss: 0.0533 - accuracy: 0.9460\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.0522 - accuracy: 0.9655\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.0630 - accuracy: 0.9211\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 862us/step - loss: 0.0488 - accuracy: 0.9458\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 891us/step - loss: 0.0550 - accuracy: 0.9585\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 929us/step - loss: 0.0469 - accuracy: 0.9389\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 942us/step - loss: 0.0511 - accuracy: 0.9474\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 806us/step - loss: 0.0538 - accuracy: 0.9375\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 917us/step - loss: 0.0383 - accuracy: 0.9773\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0441 - accuracy: 0.9778\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0338 - accuracy: 0.9911\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 916us/step - loss: 0.0348 - accuracy: 0.9796\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 896us/step - loss: 0.0482 - accuracy: 0.9650\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 810us/step - loss: 0.0473 - accuracy: 0.9627\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 899us/step - loss: 0.0403 - accuracy: 0.9713\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.0341 - accuracy: 0.9754\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 858us/step - loss: 0.0352 - accuracy: 0.9750\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0326 - accuracy: 0.9907\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.0541 - accuracy: 0.9207\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 873us/step - loss: 0.0329 - accuracy: 0.9828\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.0306 - accuracy: 0.9888\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0279 - accuracy: 0.9797\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 819us/step - loss: 0.0404 - accuracy: 0.9712\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 811us/step - loss: 0.0412 - accuracy: 0.9812\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 906us/step - loss: 0.0366 - accuracy: 0.9864\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.0312 - accuracy: 0.9845\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 910us/step - loss: 0.0330 - accuracy: 0.9772\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 851us/step - loss: 0.0243 - accuracy: 0.9927\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 900us/step - loss: 0.0318 - accuracy: 0.9774\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.0358 - accuracy: 0.9770\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.0344 - accuracy: 0.9802\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 963us/step - loss: 0.0376 - accuracy: 0.9717\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 947us/step - loss: 0.0209 - accuracy: 0.9960\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 846us/step - loss: 0.0233 - accuracy: 0.9869\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 865us/step - loss: 0.0187 - accuracy: 0.9923\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.0232 - accuracy: 0.9878\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 844us/step - loss: 0.0162 - accuracy: 0.9953\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 922us/step - loss: 0.0218 - accuracy: 0.9865\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 875us/step - loss: 0.0106 - accuracy: 0.9989\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.0295 - accuracy: 0.9814\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.0142 - accuracy: 0.9989\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 915us/step - loss: 0.0222 - accuracy: 0.9891\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 831us/step - loss: 0.0189 - accuracy: 0.9896\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0212 - accuracy: 0.9876\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 851us/step - loss: 0.0144 - accuracy: 0.9924\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 910us/step - loss: 0.0151 - accuracy: 0.9922\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0213 - accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 818us/step - loss: 0.0168 - accuracy: 0.9885\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 864us/step - loss: 0.0107 - accuracy: 0.9965\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1501 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 842us/step - loss: 0.2377 - accuracy: 0.5645\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 854us/step - loss: 0.2319 - accuracy: 0.6440\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 819us/step - loss: 0.2214 - accuracy: 0.6459\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 859us/step - loss: 0.2092 - accuracy: 0.7356\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.2021 - accuracy: 0.7063\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 942us/step - loss: 0.2013 - accuracy: 0.7703\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 954us/step - loss: 0.1908 - accuracy: 0.7584\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 954us/step - loss: 0.1722 - accuracy: 0.8049\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 949us/step - loss: 0.1641 - accuracy: 0.7981\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 914us/step - loss: 0.1610 - accuracy: 0.7892\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 998us/step - loss: 0.1526 - accuracy: 0.8170\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 979us/step - loss: 0.1540 - accuracy: 0.7853\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.1498 - accuracy: 0.8103\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 918us/step - loss: 0.1410 - accuracy: 0.7710\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 914us/step - loss: 0.1340 - accuracy: 0.8536\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.1321 - accuracy: 0.8530\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 934us/step - loss: 0.1277 - accuracy: 0.8450\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 934us/step - loss: 0.1163 - accuracy: 0.8868\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 985us/step - loss: 0.1260 - accuracy: 0.8163\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 956us/step - loss: 0.1323 - accuracy: 0.8232\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.1303 - accuracy: 0.8375\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 913us/step - loss: 0.1172 - accuracy: 0.8492\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 964us/step - loss: 0.1115 - accuracy: 0.8768\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.0972 - accuracy: 0.8942\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 934us/step - loss: 0.1049 - accuracy: 0.8863\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.0936 - accuracy: 0.8796\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 943us/step - loss: 0.0954 - accuracy: 0.8811\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 918us/step - loss: 0.1059 - accuracy: 0.8811\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 855us/step - loss: 0.0872 - accuracy: 0.8988\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.0846 - accuracy: 0.9117\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 934us/step - loss: 0.1029 - accuracy: 0.8066\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0906 - accuracy: 0.8975\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 837us/step - loss: 0.0817 - accuracy: 0.8900\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 902us/step - loss: 0.0810 - accuracy: 0.8860\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 908us/step - loss: 0.1010 - accuracy: 0.8221\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0790 - accuracy: 0.8997\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.0705 - accuracy: 0.8909\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.0791 - accuracy: 0.9138\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 912us/step - loss: 0.0731 - accuracy: 0.9389\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.0832 - accuracy: 0.9000\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 914us/step - loss: 0.0730 - accuracy: 0.9002\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 901us/step - loss: 0.0799 - accuracy: 0.9000\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.0817 - accuracy: 0.9229\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0809 - accuracy: 0.8821\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 859us/step - loss: 0.0650 - accuracy: 0.9268\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.0657 - accuracy: 0.9182\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 821us/step - loss: 0.0709 - accuracy: 0.9384\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.0554 - accuracy: 0.9516\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0763 - accuracy: 0.9074\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0669 - accuracy: 0.8976\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 862us/step - loss: 0.0575 - accuracy: 0.9522\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 875us/step - loss: 0.0584 - accuracy: 0.9290\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 854us/step - loss: 0.0612 - accuracy: 0.9360\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 865us/step - loss: 0.0587 - accuracy: 0.9306\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.0510 - accuracy: 0.9483\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.0477 - accuracy: 0.9792\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.0363 - accuracy: 0.9723\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0518 - accuracy: 0.9655\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 904us/step - loss: 0.0558 - accuracy: 0.9331\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 859us/step - loss: 0.0429 - accuracy: 0.9701\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 872us/step - loss: 0.0435 - accuracy: 0.9588\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 905us/step - loss: 0.0359 - accuracy: 0.9857\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0343 - accuracy: 0.9840\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 836us/step - loss: 0.0362 - accuracy: 0.9723\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 892us/step - loss: 0.0383 - accuracy: 0.9737\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0373 - accuracy: 0.9743\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 820us/step - loss: 0.0255 - accuracy: 0.9827\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.0286 - accuracy: 0.9806\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 899us/step - loss: 0.0320 - accuracy: 0.9753\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 870us/step - loss: 0.0347 - accuracy: 0.9508\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 867us/step - loss: 0.0247 - accuracy: 0.9799\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.0300 - accuracy: 0.9790\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0246 - accuracy: 0.9977\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0216 - accuracy: 0.9963\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 877us/step - loss: 0.0252 - accuracy: 0.9835\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 882us/step - loss: 0.0298 - accuracy: 0.9788\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0306 - accuracy: 0.9720\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 853us/step - loss: 0.0235 - accuracy: 0.9957\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 880us/step - loss: 0.0237 - accuracy: 0.9886\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 918us/step - loss: 0.0219 - accuracy: 0.9933\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.0240 - accuracy: 0.9983\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 850us/step - loss: 0.0169 - accuracy: 0.9981\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 892us/step - loss: 0.0169 - accuracy: 0.9997\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.0188 - accuracy: 0.9878\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 905us/step - loss: 0.0168 - accuracy: 0.9973\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 924us/step - loss: 0.0259 - accuracy: 0.9771\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0199 - accuracy: 0.9780\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.0145 - accuracy: 0.9892\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 861us/step - loss: 0.0126 - accuracy: 0.9895\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.0104 - accuracy: 0.9968\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 880us/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0162 - accuracy: 0.9885\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 855us/step - loss: 0.0140 - accuracy: 0.9983\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 861us/step - loss: 0.0094 - accuracy: 0.9981\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 882us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 937us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0562 - accuracy: 0.8571\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.5197\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 818us/step - loss: 0.2255 - accuracy: 0.6594\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 834us/step - loss: 0.2171 - accuracy: 0.7501\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 877us/step - loss: 0.2006 - accuracy: 0.7233\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 877us/step - loss: 0.1886 - accuracy: 0.7463\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.1858 - accuracy: 0.7179\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.1667 - accuracy: 0.8143\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.1553 - accuracy: 0.7921\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 895us/step - loss: 0.1449 - accuracy: 0.8104\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.1479 - accuracy: 0.8421\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.1482 - accuracy: 0.7998\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 858us/step - loss: 0.1371 - accuracy: 0.8773\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.1367 - accuracy: 0.8208\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 917us/step - loss: 0.1389 - accuracy: 0.7991\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 861us/step - loss: 0.1423 - accuracy: 0.8092\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 910us/step - loss: 0.1191 - accuracy: 0.8602\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 924us/step - loss: 0.1199 - accuracy: 0.8410\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 882us/step - loss: 0.1096 - accuracy: 0.8676\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.1339 - accuracy: 0.7671\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.1307 - accuracy: 0.8551\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.1178 - accuracy: 0.8300\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 878us/step - loss: 0.1133 - accuracy: 0.8688\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.1018 - accuracy: 0.9086\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 896us/step - loss: 0.0985 - accuracy: 0.8984\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 855us/step - loss: 0.1111 - accuracy: 0.8784\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 899us/step - loss: 0.0802 - accuracy: 0.8978\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 908us/step - loss: 0.1027 - accuracy: 0.8857\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0789 - accuracy: 0.8949\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 864us/step - loss: 0.0913 - accuracy: 0.8846\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0843 - accuracy: 0.9229\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.0921 - accuracy: 0.9042\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0918 - accuracy: 0.9292\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 862us/step - loss: 0.0855 - accuracy: 0.8863\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.0758 - accuracy: 0.9199\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 851us/step - loss: 0.0869 - accuracy: 0.8887\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 882us/step - loss: 0.0862 - accuracy: 0.9046\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.0723 - accuracy: 0.9087\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.0620 - accuracy: 0.9232\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 921us/step - loss: 0.0643 - accuracy: 0.9445\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 851us/step - loss: 0.0731 - accuracy: 0.9303\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.0672 - accuracy: 0.9437\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 881us/step - loss: 0.0618 - accuracy: 0.9257\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 873us/step - loss: 0.0671 - accuracy: 0.9211\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.0777 - accuracy: 0.8832\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 905us/step - loss: 0.0666 - accuracy: 0.9026\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0589 - accuracy: 0.9279\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0567 - accuracy: 0.9386\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0653 - accuracy: 0.9285\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 843us/step - loss: 0.0780 - accuracy: 0.8962\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 820us/step - loss: 0.0625 - accuracy: 0.9240\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 851us/step - loss: 0.0421 - accuracy: 0.9543\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 836us/step - loss: 0.0632 - accuracy: 0.9370\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0523 - accuracy: 0.9411\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 890us/step - loss: 0.0441 - accuracy: 0.9689\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0410 - accuracy: 0.9532\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 900us/step - loss: 0.0656 - accuracy: 0.9308\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 845us/step - loss: 0.0444 - accuracy: 0.9474\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 806us/step - loss: 0.0792 - accuracy: 0.9252\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 794us/step - loss: 0.0412 - accuracy: 0.9663\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 923us/step - loss: 0.0588 - accuracy: 0.9402\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 892us/step - loss: 0.0394 - accuracy: 0.9543\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0658 - accuracy: 0.9462\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 890us/step - loss: 0.0414 - accuracy: 0.9445\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0383 - accuracy: 0.9691\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 913us/step - loss: 0.0409 - accuracy: 0.9639\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 890us/step - loss: 0.0319 - accuracy: 0.9746\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 914us/step - loss: 0.0366 - accuracy: 0.9619\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.0418 - accuracy: 0.9568\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 874us/step - loss: 0.0373 - accuracy: 0.9473\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 862us/step - loss: 0.0510 - accuracy: 0.9415\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0310 - accuracy: 0.9835\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0293 - accuracy: 0.9743\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.0266 - accuracy: 0.9925\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 853us/step - loss: 0.0303 - accuracy: 0.9730\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 872us/step - loss: 0.0367 - accuracy: 0.9668\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 854us/step - loss: 0.0565 - accuracy: 0.9454\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.0337 - accuracy: 0.9550\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.0270 - accuracy: 0.9906\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 821us/step - loss: 0.0218 - accuracy: 0.9823\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 872us/step - loss: 0.0370 - accuracy: 0.9656\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 850us/step - loss: 0.0411 - accuracy: 0.9631\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 892us/step - loss: 0.0262 - accuracy: 0.9781\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.0225 - accuracy: 0.9835\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 774us/step - loss: 0.0238 - accuracy: 0.9786\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.0211 - accuracy: 0.9857\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.0248 - accuracy: 0.9858\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.0188 - accuracy: 0.9891\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0280 - accuracy: 0.9834\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 837us/step - loss: 0.0217 - accuracy: 0.9860\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 900us/step - loss: 0.0220 - accuracy: 0.9885\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 901us/step - loss: 0.0232 - accuracy: 0.9876\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.0182 - accuracy: 0.9836\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 892us/step - loss: 0.0218 - accuracy: 0.9889\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 842us/step - loss: 0.0185 - accuracy: 0.9851\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0263 - accuracy: 0.9723\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.0258 - accuracy: 0.9837\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 905us/step - loss: 0.0200 - accuracy: 0.9847\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.0265 - accuracy: 0.9810\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 850us/step - loss: 0.0170 - accuracy: 0.9885\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 872us/step - loss: 0.0248 - accuracy: 0.9847\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1386 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 895us/step - loss: 0.2605 - accuracy: 0.4523\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 849us/step - loss: 0.2427 - accuracy: 0.5766\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 835us/step - loss: 0.2361 - accuracy: 0.6594\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 844us/step - loss: 0.2334 - accuracy: 0.6829\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 827us/step - loss: 0.2224 - accuracy: 0.7479\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 927us/step - loss: 0.2158 - accuracy: 0.6870\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 952us/step - loss: 0.2046 - accuracy: 0.6987\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 933us/step - loss: 0.1975 - accuracy: 0.7837\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 966us/step - loss: 0.1921 - accuracy: 0.7533\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 842us/step - loss: 0.1816 - accuracy: 0.7900\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 928us/step - loss: 0.1864 - accuracy: 0.6703\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.1665 - accuracy: 0.8042\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 949us/step - loss: 0.1560 - accuracy: 0.8102\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 954us/step - loss: 0.1489 - accuracy: 0.8276\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 918us/step - loss: 0.1496 - accuracy: 0.8343\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 917us/step - loss: 0.1443 - accuracy: 0.8456\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 815us/step - loss: 0.1408 - accuracy: 0.7826\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.1461 - accuracy: 0.8042\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 906us/step - loss: 0.1389 - accuracy: 0.8028\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.1437 - accuracy: 0.7907\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 930us/step - loss: 0.1327 - accuracy: 0.8002\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 931us/step - loss: 0.1104 - accuracy: 0.8708\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 918us/step - loss: 0.1268 - accuracy: 0.8306\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 926us/step - loss: 0.1269 - accuracy: 0.8547\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 934us/step - loss: 0.1196 - accuracy: 0.8410\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 895us/step - loss: 0.1159 - accuracy: 0.9067\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 965us/step - loss: 0.1125 - accuracy: 0.8801\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 948us/step - loss: 0.1321 - accuracy: 0.8688\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.1098 - accuracy: 0.8662\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 962us/step - loss: 0.1208 - accuracy: 0.8791\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 955us/step - loss: 0.1112 - accuracy: 0.8484\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 955us/step - loss: 0.1264 - accuracy: 0.8298\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 925us/step - loss: 0.1081 - accuracy: 0.8845\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 925us/step - loss: 0.1278 - accuracy: 0.8575\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 918us/step - loss: 0.1030 - accuracy: 0.8961\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 977us/step - loss: 0.1008 - accuracy: 0.8685\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 921us/step - loss: 0.0970 - accuracy: 0.8826\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 929us/step - loss: 0.1221 - accuracy: 0.8164\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 913us/step - loss: 0.1159 - accuracy: 0.8666\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 920us/step - loss: 0.1209 - accuracy: 0.8229\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 952us/step - loss: 0.0984 - accuracy: 0.8608\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 928us/step - loss: 0.1083 - accuracy: 0.8391\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 921us/step - loss: 0.0977 - accuracy: 0.8475\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 901us/step - loss: 0.0877 - accuracy: 0.9045\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 972us/step - loss: 0.0876 - accuracy: 0.9193\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 927us/step - loss: 0.0808 - accuracy: 0.9348\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 946us/step - loss: 0.0762 - accuracy: 0.9450\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 895us/step - loss: 0.0915 - accuracy: 0.8923\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.0916 - accuracy: 0.8916\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 916us/step - loss: 0.1046 - accuracy: 0.8859\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 922us/step - loss: 0.0775 - accuracy: 0.9389\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 904us/step - loss: 0.0719 - accuracy: 0.9205\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0863 - accuracy: 0.9326\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 939us/step - loss: 0.0766 - accuracy: 0.9114\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9029\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.1091 - accuracy: 0.8812\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.0652 - accuracy: 0.9455\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 817us/step - loss: 0.0704 - accuracy: 0.9279\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 846us/step - loss: 0.0912 - accuracy: 0.9182\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 855us/step - loss: 0.0721 - accuracy: 0.9266\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.0729 - accuracy: 0.9346\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 896us/step - loss: 0.0619 - accuracy: 0.9560\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 809us/step - loss: 0.0617 - accuracy: 0.9615\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.0527 - accuracy: 0.9570\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 826us/step - loss: 0.0669 - accuracy: 0.9220\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.0558 - accuracy: 0.9713\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0630 - accuracy: 0.9155\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.0641 - accuracy: 0.9497\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.0518 - accuracy: 0.9593\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 853us/step - loss: 0.0620 - accuracy: 0.9310\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 861us/step - loss: 0.0630 - accuracy: 0.9442\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 924us/step - loss: 0.0620 - accuracy: 0.9269\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 926us/step - loss: 0.0600 - accuracy: 0.9328\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 922us/step - loss: 0.0547 - accuracy: 0.9439\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.0659 - accuracy: 0.9280\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 796us/step - loss: 0.0485 - accuracy: 0.9383\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 912us/step - loss: 0.0619 - accuracy: 0.9342\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 922us/step - loss: 0.0416 - accuracy: 0.9626\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 903us/step - loss: 0.0553 - accuracy: 0.9401\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 902us/step - loss: 0.0442 - accuracy: 0.9601\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.0444 - accuracy: 0.9655\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.0423 - accuracy: 0.9630\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.0401 - accuracy: 0.9733\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.0355 - accuracy: 0.9738\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 899us/step - loss: 0.0376 - accuracy: 0.9670\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 865us/step - loss: 0.0353 - accuracy: 0.9750\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.0388 - accuracy: 0.9677\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 909us/step - loss: 0.0412 - accuracy: 0.9691\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0277 - accuracy: 0.9871\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0286 - accuracy: 0.9796\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 882us/step - loss: 0.0394 - accuracy: 0.9645\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 900us/step - loss: 0.0396 - accuracy: 0.9855\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 864us/step - loss: 0.0349 - accuracy: 0.9879\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 915us/step - loss: 0.0411 - accuracy: 0.9664\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.0318 - accuracy: 0.9695\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 907us/step - loss: 0.0314 - accuracy: 0.9792\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 842us/step - loss: 0.0238 - accuracy: 0.9864\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.0293 - accuracy: 0.9825\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.0273 - accuracy: 0.9779\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 861us/step - loss: 0.0268 - accuracy: 0.9666\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0946 - accuracy: 0.9500\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 1ms/step - loss: 0.2506 - accuracy: 0.5432\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 829us/step - loss: 0.2394 - accuracy: 0.5409\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 851us/step - loss: 0.2302 - accuracy: 0.6087\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 867us/step - loss: 0.2289 - accuracy: 0.6674\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 820us/step - loss: 0.2238 - accuracy: 0.6759\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 897us/step - loss: 0.2199 - accuracy: 0.6510\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 872us/step - loss: 0.2046 - accuracy: 0.7495\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 915us/step - loss: 0.2091 - accuracy: 0.6794\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 851us/step - loss: 0.1948 - accuracy: 0.6999\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 872us/step - loss: 0.1831 - accuracy: 0.8018\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 859us/step - loss: 0.1906 - accuracy: 0.6736\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 886us/step - loss: 0.1792 - accuracy: 0.7867\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.1689 - accuracy: 0.7766\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 859us/step - loss: 0.1456 - accuracy: 0.8095\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 961us/step - loss: 0.1721 - accuracy: 0.7566\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.1481 - accuracy: 0.8147\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 831us/step - loss: 0.1536 - accuracy: 0.7643\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.1473 - accuracy: 0.8111\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.1431 - accuracy: 0.8382\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 871us/step - loss: 0.1629 - accuracy: 0.7488\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.1233 - accuracy: 0.8292\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 929us/step - loss: 0.1182 - accuracy: 0.8549\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 867us/step - loss: 0.1236 - accuracy: 0.8574\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 853us/step - loss: 0.1266 - accuracy: 0.8043\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 857us/step - loss: 0.1132 - accuracy: 0.8490\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 917us/step - loss: 0.1175 - accuracy: 0.8302\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 885us/step - loss: 0.1122 - accuracy: 0.8448\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.1183 - accuracy: 0.8353\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 882us/step - loss: 0.1115 - accuracy: 0.8623\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 856us/step - loss: 0.1107 - accuracy: 0.8873\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 843us/step - loss: 0.1134 - accuracy: 0.8450\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 870us/step - loss: 0.1202 - accuracy: 0.8503\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 850us/step - loss: 0.1114 - accuracy: 0.8320\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 860us/step - loss: 0.1124 - accuracy: 0.8734\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 855us/step - loss: 0.0996 - accuracy: 0.8879\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 827us/step - loss: 0.1088 - accuracy: 0.8454\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.0910 - accuracy: 0.9091\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.0954 - accuracy: 0.8977\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 900us/step - loss: 0.0914 - accuracy: 0.8943\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 895us/step - loss: 0.0842 - accuracy: 0.9105\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0831 - accuracy: 0.9013\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0686 - accuracy: 0.9316\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 810us/step - loss: 0.0991 - accuracy: 0.8653\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 920us/step - loss: 0.0709 - accuracy: 0.9418\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 858us/step - loss: 0.0936 - accuracy: 0.8829\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.0942 - accuracy: 0.8574\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 901us/step - loss: 0.0711 - accuracy: 0.9320\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 863us/step - loss: 0.0791 - accuracy: 0.9361\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 839us/step - loss: 0.0957 - accuracy: 0.8902\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 859us/step - loss: 0.0899 - accuracy: 0.8901\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 891us/step - loss: 0.0880 - accuracy: 0.8900\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 916us/step - loss: 0.0676 - accuracy: 0.9285\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 905us/step - loss: 0.0808 - accuracy: 0.8931\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0718 - accuracy: 0.9010\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 888us/step - loss: 0.0626 - accuracy: 0.9232\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 879us/step - loss: 0.0687 - accuracy: 0.9185\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 856us/step - loss: 0.0602 - accuracy: 0.9202\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0664 - accuracy: 0.9332\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 910us/step - loss: 0.0570 - accuracy: 0.9275\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 919us/step - loss: 0.0676 - accuracy: 0.9218\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 842us/step - loss: 0.0604 - accuracy: 0.9506\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 895us/step - loss: 0.0508 - accuracy: 0.9326\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 878us/step - loss: 0.0607 - accuracy: 0.9489\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 866us/step - loss: 0.0625 - accuracy: 0.9252\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 894us/step - loss: 0.0529 - accuracy: 0.9582\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0590 - accuracy: 0.9413\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 933us/step - loss: 0.0475 - accuracy: 0.9678\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 911us/step - loss: 0.0419 - accuracy: 0.9693\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 810us/step - loss: 0.0544 - accuracy: 0.9224\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 869us/step - loss: 0.0726 - accuracy: 0.9309\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 853us/step - loss: 0.0474 - accuracy: 0.9563\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.0384 - accuracy: 0.9615\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 887us/step - loss: 0.0381 - accuracy: 0.9735\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 893us/step - loss: 0.0491 - accuracy: 0.9541\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 884us/step - loss: 0.0420 - accuracy: 0.9746\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 862us/step - loss: 0.0440 - accuracy: 0.9600\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 840us/step - loss: 0.0400 - accuracy: 0.9728\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 867us/step - loss: 0.0293 - accuracy: 0.9928\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 868us/step - loss: 0.0308 - accuracy: 0.9798\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.0526 - accuracy: 0.9595\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 907us/step - loss: 0.0414 - accuracy: 0.9550\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 877us/step - loss: 0.0351 - accuracy: 0.9881\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 896us/step - loss: 0.0331 - accuracy: 0.9841\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.0314 - accuracy: 0.9907\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 835us/step - loss: 0.0411 - accuracy: 0.9775\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 831us/step - loss: 0.0335 - accuracy: 0.9857\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 880us/step - loss: 0.0346 - accuracy: 0.9811\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 898us/step - loss: 0.0292 - accuracy: 0.9800\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 876us/step - loss: 0.0298 - accuracy: 0.9771\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 883us/step - loss: 0.0256 - accuracy: 0.9947\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 872us/step - loss: 0.0355 - accuracy: 0.9752\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 829us/step - loss: 0.0184 - accuracy: 0.9959\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 819us/step - loss: 0.0318 - accuracy: 0.9876\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 755us/step - loss: 0.0237 - accuracy: 0.9901\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 917us/step - loss: 0.0257 - accuracy: 0.9951\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 910us/step - loss: 0.0236 - accuracy: 0.9907\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 889us/step - loss: 0.0294 - accuracy: 0.9728\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 837us/step - loss: 0.0276 - accuracy: 0.9774\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 862us/step - loss: 0.0286 - accuracy: 0.9736\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 832us/step - loss: 0.0260 - accuracy: 0.9692\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1153 - accuracy: 0.8500\n",
      "\n",
      " 10 fold accuracy: ['0.7143', '0.8095', '0.7619', '0.9048', '0.8571', '0.7619', '0.8571', '0.7619', '0.9500', '0.8500']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"sonar.csv\", header = None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y_obj = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "n_fold = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = seed)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for train, test in skf.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim = 60, activation = 'relu'))\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'mean_squared_error',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics = ['accuracy'])\n",
    "    model.fit(X[train], Y[train], epochs = 100, batch_size = 5)\n",
    "    k_accuracy = \"%.4f\" %(model.evaluate(X[test], Y[test])[1])\n",
    "    accuracy.append(k_accuracy)\n",
    "\n",
    "print(\"\\n %.f fold accuracy:\" %n_fold, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b619dc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "33/33 [==============================] - 1s 960us/step - loss: 1.0185 - accuracy: 0.7309\n",
      "Epoch 2/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8739\n",
      "Epoch 3/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.9215\n",
      "Epoch 4/200\n",
      "33/33 [==============================] - 0s 996us/step - loss: 0.2313 - accuracy: 0.9249\n",
      "Epoch 5/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9269\n",
      "Epoch 6/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9265\n",
      "Epoch 7/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.9347\n",
      "Epoch 8/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.9301\n",
      "Epoch 9/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.9336\n",
      "Epoch 10/200\n",
      "33/33 [==============================] - 0s 929us/step - loss: 0.1796 - accuracy: 0.9404\n",
      "Epoch 11/200\n",
      "33/33 [==============================] - 0s 993us/step - loss: 0.1857 - accuracy: 0.9357\n",
      "Epoch 12/200\n",
      "33/33 [==============================] - 0s 980us/step - loss: 0.1809 - accuracy: 0.9381\n",
      "Epoch 13/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.9386\n",
      "Epoch 14/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9420\n",
      "Epoch 15/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9388\n",
      "Epoch 16/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9428\n",
      "Epoch 17/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9473\n",
      "Epoch 18/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9447\n",
      "Epoch 19/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9467\n",
      "Epoch 20/200\n",
      "33/33 [==============================] - 0s 950us/step - loss: 0.1452 - accuracy: 0.9471\n",
      "Epoch 21/200\n",
      "33/33 [==============================] - 0s 986us/step - loss: 0.1483 - accuracy: 0.9466\n",
      "Epoch 22/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9476\n",
      "Epoch 23/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9472\n",
      "Epoch 24/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9493\n",
      "Epoch 25/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9564\n",
      "Epoch 26/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9542\n",
      "Epoch 27/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9578\n",
      "Epoch 28/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9547\n",
      "Epoch 29/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9581\n",
      "Epoch 30/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9594\n",
      "Epoch 31/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9651\n",
      "Epoch 32/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9604\n",
      "Epoch 33/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9669\n",
      "Epoch 34/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9669\n",
      "Epoch 35/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9702\n",
      "Epoch 36/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9662\n",
      "Epoch 37/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9693\n",
      "Epoch 38/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9716\n",
      "Epoch 39/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.9671\n",
      "Epoch 40/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.9751\n",
      "Epoch 41/200\n",
      "33/33 [==============================] - 0s 987us/step - loss: 0.0985 - accuracy: 0.9687\n",
      "Epoch 42/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9706\n",
      "Epoch 43/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9695\n",
      "Epoch 44/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9766\n",
      "Epoch 45/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9749\n",
      "Epoch 46/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0789 - accuracy: 0.9729\n",
      "Epoch 47/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 0.9713\n",
      "Epoch 48/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9758\n",
      "Epoch 49/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9759\n",
      "Epoch 50/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9759\n",
      "Epoch 51/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9717\n",
      "Epoch 52/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9708\n",
      "Epoch 53/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9769\n",
      "Epoch 54/200\n",
      "33/33 [==============================] - 0s 997us/step - loss: 0.0701 - accuracy: 0.9760\n",
      "Epoch 55/200\n",
      "33/33 [==============================] - 0s 966us/step - loss: 0.0807 - accuracy: 0.9736\n",
      "Epoch 56/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 0.9777\n",
      "Epoch 57/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9753\n",
      "Epoch 58/200\n",
      "33/33 [==============================] - 0s 971us/step - loss: 0.0759 - accuracy: 0.9743\n",
      "Epoch 59/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9731\n",
      "Epoch 60/200\n",
      "33/33 [==============================] - 0s 998us/step - loss: 0.0897 - accuracy: 0.9701\n",
      "Epoch 61/200\n",
      "33/33 [==============================] - 0s 953us/step - loss: 0.0779 - accuracy: 0.9763\n",
      "Epoch 62/200\n",
      "33/33 [==============================] - 0s 966us/step - loss: 0.0688 - accuracy: 0.9794\n",
      "Epoch 63/200\n",
      "33/33 [==============================] - 0s 986us/step - loss: 0.0682 - accuracy: 0.9785\n",
      "Epoch 64/200\n",
      "33/33 [==============================] - 0s 973us/step - loss: 0.0589 - accuracy: 0.9824\n",
      "Epoch 65/200\n",
      "33/33 [==============================] - 0s 986us/step - loss: 0.0794 - accuracy: 0.9741\n",
      "Epoch 66/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9743\n",
      "Epoch 67/200\n",
      "33/33 [==============================] - 0s 979us/step - loss: 0.0644 - accuracy: 0.9782\n",
      "Epoch 68/200\n",
      "33/33 [==============================] - 0s 969us/step - loss: 0.0614 - accuracy: 0.9816\n",
      "Epoch 69/200\n",
      "33/33 [==============================] - 0s 968us/step - loss: 0.0805 - accuracy: 0.9759\n",
      "Epoch 70/200\n",
      "33/33 [==============================] - 0s 966us/step - loss: 0.0651 - accuracy: 0.9788\n",
      "Epoch 71/200\n",
      "33/33 [==============================] - 0s 964us/step - loss: 0.0661 - accuracy: 0.9794\n",
      "Epoch 72/200\n",
      "33/33 [==============================] - 0s 958us/step - loss: 0.0665 - accuracy: 0.9774\n",
      "Epoch 73/200\n",
      "33/33 [==============================] - 0s 958us/step - loss: 0.0643 - accuracy: 0.9802\n",
      "Epoch 74/200\n",
      "33/33 [==============================] - 0s 920us/step - loss: 0.0604 - accuracy: 0.9838\n",
      "Epoch 75/200\n",
      "33/33 [==============================] - 0s 997us/step - loss: 0.0610 - accuracy: 0.9790\n",
      "Epoch 76/200\n",
      "33/33 [==============================] - 0s 973us/step - loss: 0.0612 - accuracy: 0.9802\n",
      "Epoch 77/200\n",
      "33/33 [==============================] - 0s 954us/step - loss: 0.0633 - accuracy: 0.9770\n",
      "Epoch 78/200\n",
      "33/33 [==============================] - 0s 966us/step - loss: 0.0675 - accuracy: 0.9776\n",
      "Epoch 79/200\n",
      "33/33 [==============================] - 0s 981us/step - loss: 0.0569 - accuracy: 0.9814\n",
      "Epoch 80/200\n",
      "33/33 [==============================] - 0s 931us/step - loss: 0.0781 - accuracy: 0.9732\n",
      "Epoch 81/200\n",
      "33/33 [==============================] - 0s 988us/step - loss: 0.0601 - accuracy: 0.9809\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 963us/step - loss: 0.0643 - accuracy: 0.9837\n",
      "Epoch 83/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9793\n",
      "Epoch 84/200\n",
      "33/33 [==============================] - 0s 927us/step - loss: 0.0673 - accuracy: 0.9787\n",
      "Epoch 85/200\n",
      "33/33 [==============================] - 0s 935us/step - loss: 0.0567 - accuracy: 0.9837\n",
      "Epoch 86/200\n",
      "33/33 [==============================] - 0s 967us/step - loss: 0.0628 - accuracy: 0.9815\n",
      "Epoch 87/200\n",
      "33/33 [==============================] - 0s 949us/step - loss: 0.0582 - accuracy: 0.9832\n",
      "Epoch 88/200\n",
      "33/33 [==============================] - 0s 930us/step - loss: 0.0596 - accuracy: 0.9812\n",
      "Epoch 89/200\n",
      "33/33 [==============================] - 0s 954us/step - loss: 0.0581 - accuracy: 0.9834\n",
      "Epoch 90/200\n",
      "33/33 [==============================] - 0s 955us/step - loss: 0.0699 - accuracy: 0.9780\n",
      "Epoch 91/200\n",
      "33/33 [==============================] - 0s 922us/step - loss: 0.0586 - accuracy: 0.9811\n",
      "Epoch 92/200\n",
      "33/33 [==============================] - 0s 950us/step - loss: 0.0613 - accuracy: 0.9816\n",
      "Epoch 93/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9827\n",
      "Epoch 94/200\n",
      "33/33 [==============================] - 0s 988us/step - loss: 0.0595 - accuracy: 0.9823\n",
      "Epoch 95/200\n",
      "33/33 [==============================] - 0s 990us/step - loss: 0.0669 - accuracy: 0.9800\n",
      "Epoch 96/200\n",
      "33/33 [==============================] - 0s 976us/step - loss: 0.0726 - accuracy: 0.9775\n",
      "Epoch 97/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9820\n",
      "Epoch 98/200\n",
      "33/33 [==============================] - 0s 975us/step - loss: 0.0634 - accuracy: 0.9791\n",
      "Epoch 99/200\n",
      "33/33 [==============================] - 0s 978us/step - loss: 0.0533 - accuracy: 0.9836\n",
      "Epoch 100/200\n",
      "33/33 [==============================] - 0s 908us/step - loss: 0.0684 - accuracy: 0.9799\n",
      "Epoch 101/200\n",
      "33/33 [==============================] - 0s 891us/step - loss: 0.0637 - accuracy: 0.9818\n",
      "Epoch 102/200\n",
      "33/33 [==============================] - 0s 968us/step - loss: 0.0637 - accuracy: 0.9792\n",
      "Epoch 103/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.0524 - accuracy: 0.9832\n",
      "Epoch 104/200\n",
      "33/33 [==============================] - 0s 958us/step - loss: 0.0713 - accuracy: 0.9765\n",
      "Epoch 105/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9827\n",
      "Epoch 106/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9822\n",
      "Epoch 107/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0540 - accuracy: 0.9841\n",
      "Epoch 108/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9825\n",
      "Epoch 109/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9825\n",
      "Epoch 110/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9807\n",
      "Epoch 111/200\n",
      "33/33 [==============================] - 0s 993us/step - loss: 0.0553 - accuracy: 0.9829\n",
      "Epoch 112/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9784\n",
      "Epoch 113/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9845\n",
      "Epoch 114/200\n",
      "33/33 [==============================] - 0s 998us/step - loss: 0.0582 - accuracy: 0.9795\n",
      "Epoch 115/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9786\n",
      "Epoch 116/200\n",
      "33/33 [==============================] - 0s 993us/step - loss: 0.0610 - accuracy: 0.9839\n",
      "Epoch 117/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9855\n",
      "Epoch 118/200\n",
      "33/33 [==============================] - 0s 964us/step - loss: 0.0665 - accuracy: 0.9816\n",
      "Epoch 119/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9844\n",
      "Epoch 120/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9789\n",
      "Epoch 121/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9794\n",
      "Epoch 122/200\n",
      "33/33 [==============================] - 0s 955us/step - loss: 0.0533 - accuracy: 0.9834\n",
      "Epoch 123/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9817\n",
      "Epoch 124/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0539 - accuracy: 0.9836\n",
      "Epoch 125/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9816\n",
      "Epoch 126/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9850\n",
      "Epoch 127/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9881\n",
      "Epoch 128/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9832\n",
      "Epoch 129/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0494 - accuracy: 0.9843\n",
      "Epoch 130/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9846\n",
      "Epoch 131/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9810\n",
      "Epoch 132/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9809\n",
      "Epoch 133/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0494 - accuracy: 0.9840\n",
      "Epoch 134/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9872\n",
      "Epoch 135/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9803\n",
      "Epoch 136/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0537 - accuracy: 0.9820\n",
      "Epoch 137/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9847\n",
      "Epoch 138/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9830\n",
      "Epoch 139/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9820\n",
      "Epoch 140/200\n",
      "33/33 [==============================] - 0s 988us/step - loss: 0.0586 - accuracy: 0.9825\n",
      "Epoch 141/200\n",
      "33/33 [==============================] - 0s 985us/step - loss: 0.0569 - accuracy: 0.9837\n",
      "Epoch 142/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0462 - accuracy: 0.9851\n",
      "Epoch 143/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9844\n",
      "Epoch 144/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9839\n",
      "Epoch 145/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9847\n",
      "Epoch 146/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0569 - accuracy: 0.9824\n",
      "Epoch 147/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9813\n",
      "Epoch 148/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.9827\n",
      "Epoch 149/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0539 - accuracy: 0.9856\n",
      "Epoch 150/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9838\n",
      "Epoch 151/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9832\n",
      "Epoch 152/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0542 - accuracy: 0.9820\n",
      "Epoch 153/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9844\n",
      "Epoch 154/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9825\n",
      "Epoch 155/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9824\n",
      "Epoch 156/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9865\n",
      "Epoch 157/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9843\n",
      "Epoch 158/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9814\n",
      "Epoch 159/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9856\n",
      "Epoch 160/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9821\n",
      "Epoch 161/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9849\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9839\n",
      "Epoch 163/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9849\n",
      "Epoch 164/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9829\n",
      "Epoch 165/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9813\n",
      "Epoch 166/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9868\n",
      "Epoch 167/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9850\n",
      "Epoch 168/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9821\n",
      "Epoch 169/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 0.9819\n",
      "Epoch 170/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9821\n",
      "Epoch 171/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9828\n",
      "Epoch 172/200\n",
      "33/33 [==============================] - 0s 998us/step - loss: 0.0484 - accuracy: 0.9859\n",
      "Epoch 173/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9853\n",
      "Epoch 174/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9795\n",
      "Epoch 175/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9873\n",
      "Epoch 176/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0460 - accuracy: 0.9853\n",
      "Epoch 177/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9815\n",
      "Epoch 178/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9852\n",
      "Epoch 179/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9828\n",
      "Epoch 180/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9861\n",
      "Epoch 181/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9835\n",
      "Epoch 182/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9842\n",
      "Epoch 183/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9833\n",
      "Epoch 184/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.9811\n",
      "Epoch 185/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9820\n",
      "Epoch 186/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9838\n",
      "Epoch 187/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9863\n",
      "Epoch 188/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9851\n",
      "Epoch 189/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9827\n",
      "Epoch 190/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9841\n",
      "Epoch 191/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9875\n",
      "Epoch 192/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9851\n",
      "Epoch 193/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9826\n",
      "Epoch 194/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9868\n",
      "Epoch 195/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9844\n",
      "Epoch 196/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9841\n",
      "Epoch 197/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0545 - accuracy: 0.9845\n",
      "Epoch 198/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9851\n",
      "Epoch 199/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9876\n",
      "Epoch 200/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9829\n",
      "204/204 [==============================] - 0s 679us/step - loss: 0.0470 - accuracy: 0.9861\n",
      "\n",
      " Accuracy: 0.9861\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df_pre = pd.read_csv(\"wine.csv\", header = None)\n",
    "df = df_pre.sample(frac = 1)\n",
    "dataset = df.values\n",
    "X = dataset[:,0:12].astype(float)\n",
    "Y = dataset[:,12]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 12, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X, Y, epochs = 200, batch_size = 200)\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" %(model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84b6d962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3500\n",
      "2/2 [==============================] - 1s 230ms/step - loss: 2.0445 - accuracy: 0.7266 - val_loss: 1.3696 - val_accuracy: 0.7547\n",
      "Epoch 2/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6065 - accuracy: 0.7193 - val_loss: 0.9768 - val_accuracy: 0.7547\n",
      "Epoch 3/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1012 - accuracy: 0.7286 - val_loss: 0.6556 - val_accuracy: 0.7547\n",
      "Epoch 4/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7096 - accuracy: 0.7269 - val_loss: 0.7205 - val_accuracy: 0.6429\n",
      "Epoch 5/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7508 - accuracy: 0.5977 - val_loss: 0.8499 - val_accuracy: 0.4472\n",
      "Epoch 6/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8011 - accuracy: 0.5145 - val_loss: 0.5612 - val_accuracy: 0.7236\n",
      "Epoch 7/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5679 - accuracy: 0.7158 - val_loss: 0.4968 - val_accuracy: 0.7516\n",
      "Epoch 8/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5622 - accuracy: 0.7179 - val_loss: 0.5096 - val_accuracy: 0.7578\n",
      "Epoch 9/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5893 - accuracy: 0.7222 - val_loss: 0.5104 - val_accuracy: 0.7578\n",
      "Epoch 10/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5966 - accuracy: 0.7202 - val_loss: 0.4879 - val_accuracy: 0.7578\n",
      "Epoch 11/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5613 - accuracy: 0.7289 - val_loss: 0.4497 - val_accuracy: 0.7609\n",
      "Epoch 12/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5234 - accuracy: 0.7307 - val_loss: 0.4129 - val_accuracy: 0.7609\n",
      "Epoch 13/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4705 - accuracy: 0.7375 - val_loss: 0.4008 - val_accuracy: 0.7764\n",
      "Epoch 14/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4449 - accuracy: 0.7760 - val_loss: 0.4156 - val_accuracy: 0.7702\n",
      "Epoch 15/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4361 - accuracy: 0.7861 - val_loss: 0.4201 - val_accuracy: 0.7857\n",
      "Epoch 16/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4271 - accuracy: 0.8175 - val_loss: 0.3954 - val_accuracy: 0.8106\n",
      "Epoch 17/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4073 - accuracy: 0.8364 - val_loss: 0.3660 - val_accuracy: 0.8230\n",
      "Epoch 18/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3943 - accuracy: 0.8402 - val_loss: 0.3474 - val_accuracy: 0.8478\n",
      "Epoch 19/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3821 - accuracy: 0.8557 - val_loss: 0.3369 - val_accuracy: 0.8540\n",
      "Epoch 20/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3842 - accuracy: 0.8517 - val_loss: 0.3289 - val_accuracy: 0.8602\n",
      "Epoch 21/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3511 - accuracy: 0.8627 - val_loss: 0.3216 - val_accuracy: 0.8634\n",
      "Epoch 22/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3622 - accuracy: 0.8733 - val_loss: 0.3175 - val_accuracy: 0.8789\n",
      "Epoch 23/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3477 - accuracy: 0.8861 - val_loss: 0.3187 - val_accuracy: 0.8851\n",
      "Epoch 24/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3499 - accuracy: 0.9013 - val_loss: 0.3209 - val_accuracy: 0.8882\n",
      "Epoch 25/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3470 - accuracy: 0.8980 - val_loss: 0.3151 - val_accuracy: 0.8944\n",
      "Epoch 26/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3378 - accuracy: 0.9037 - val_loss: 0.3033 - val_accuracy: 0.8944\n",
      "Epoch 27/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3274 - accuracy: 0.9074 - val_loss: 0.2917 - val_accuracy: 0.8944\n",
      "Epoch 28/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3208 - accuracy: 0.9091 - val_loss: 0.2836 - val_accuracy: 0.8913\n",
      "Epoch 29/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3248 - accuracy: 0.9037 - val_loss: 0.2780 - val_accuracy: 0.8913\n",
      "Epoch 30/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3242 - accuracy: 0.9051 - val_loss: 0.2736 - val_accuracy: 0.8975\n",
      "Epoch 31/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3048 - accuracy: 0.9091 - val_loss: 0.2703 - val_accuracy: 0.8975\n",
      "Epoch 32/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3101 - accuracy: 0.9074 - val_loss: 0.2690 - val_accuracy: 0.9037\n",
      "Epoch 33/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3063 - accuracy: 0.9098 - val_loss: 0.2697 - val_accuracy: 0.9099\n",
      "Epoch 34/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3047 - accuracy: 0.9108 - val_loss: 0.2690 - val_accuracy: 0.9068\n",
      "Epoch 35/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2882 - accuracy: 0.9195 - val_loss: 0.2655 - val_accuracy: 0.9099\n",
      "Epoch 36/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3000 - accuracy: 0.9162 - val_loss: 0.2614 - val_accuracy: 0.9130\n",
      "Epoch 37/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2929 - accuracy: 0.9125 - val_loss: 0.2554 - val_accuracy: 0.9099\n",
      "Epoch 38/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2805 - accuracy: 0.9138 - val_loss: 0.2507 - val_accuracy: 0.9068\n",
      "Epoch 39/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2901 - accuracy: 0.9131 - val_loss: 0.2483 - val_accuracy: 0.9099\n",
      "Epoch 40/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2828 - accuracy: 0.9151 - val_loss: 0.2459 - val_accuracy: 0.9099\n",
      "Epoch 41/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2905 - accuracy: 0.9091 - val_loss: 0.2440 - val_accuracy: 0.9130\n",
      "Epoch 42/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2709 - accuracy: 0.9135 - val_loss: 0.2423 - val_accuracy: 0.9130\n",
      "Epoch 43/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2781 - accuracy: 0.9128 - val_loss: 0.2418 - val_accuracy: 0.9161\n",
      "Epoch 44/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2772 - accuracy: 0.9169 - val_loss: 0.2411 - val_accuracy: 0.9161\n",
      "Epoch 45/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2821 - accuracy: 0.9145 - val_loss: 0.2395 - val_accuracy: 0.9161\n",
      "Epoch 46/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2657 - accuracy: 0.9165 - val_loss: 0.2372 - val_accuracy: 0.9161\n",
      "Epoch 47/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2743 - accuracy: 0.9132 - val_loss: 0.2358 - val_accuracy: 0.9193\n",
      "Epoch 48/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2706 - accuracy: 0.9165 - val_loss: 0.2333 - val_accuracy: 0.9161\n",
      "Epoch 49/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2648 - accuracy: 0.9202 - val_loss: 0.2293 - val_accuracy: 0.9099\n",
      "Epoch 50/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2677 - accuracy: 0.9179 - val_loss: 0.2257 - val_accuracy: 0.9130\n",
      "Epoch 51/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2665 - accuracy: 0.9186 - val_loss: 0.2232 - val_accuracy: 0.9068\n",
      "Epoch 52/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2504 - accuracy: 0.9233 - val_loss: 0.2225 - val_accuracy: 0.9037\n",
      "Epoch 53/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2563 - accuracy: 0.9263 - val_loss: 0.2238 - val_accuracy: 0.9068\n",
      "Epoch 54/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2556 - accuracy: 0.9222 - val_loss: 0.2249 - val_accuracy: 0.9068\n",
      "Epoch 55/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2586 - accuracy: 0.9202 - val_loss: 0.2245 - val_accuracy: 0.9037\n",
      "Epoch 56/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2583 - accuracy: 0.9199 - val_loss: 0.2224 - val_accuracy: 0.9068\n",
      "Epoch 57/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2581 - accuracy: 0.9202 - val_loss: 0.2208 - val_accuracy: 0.9037\n",
      "Epoch 58/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2498 - accuracy: 0.9233 - val_loss: 0.2204 - val_accuracy: 0.9037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2574 - accuracy: 0.9230 - val_loss: 0.2214 - val_accuracy: 0.9037\n",
      "Epoch 60/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2594 - accuracy: 0.9176 - val_loss: 0.2212 - val_accuracy: 0.9037\n",
      "Epoch 61/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2575 - accuracy: 0.9189 - val_loss: 0.2193 - val_accuracy: 0.9037\n",
      "Epoch 62/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2582 - accuracy: 0.9216 - val_loss: 0.2175 - val_accuracy: 0.9068\n",
      "Epoch 63/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2568 - accuracy: 0.9223 - val_loss: 0.2162 - val_accuracy: 0.9068\n",
      "Epoch 64/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2586 - accuracy: 0.9210 - val_loss: 0.2153 - val_accuracy: 0.9068\n",
      "Epoch 65/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2553 - accuracy: 0.9216 - val_loss: 0.2145 - val_accuracy: 0.9099\n",
      "Epoch 66/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2530 - accuracy: 0.9213 - val_loss: 0.2145 - val_accuracy: 0.9099\n",
      "Epoch 67/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2432 - accuracy: 0.9233 - val_loss: 0.2153 - val_accuracy: 0.9099\n",
      "Epoch 68/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2501 - accuracy: 0.9209 - val_loss: 0.2179 - val_accuracy: 0.9068\n",
      "Epoch 69/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2476 - accuracy: 0.9236 - val_loss: 0.2210 - val_accuracy: 0.9099\n",
      "Epoch 70/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2543 - accuracy: 0.9210 - val_loss: 0.2223 - val_accuracy: 0.9099\n",
      "Epoch 71/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2455 - accuracy: 0.9246 - val_loss: 0.2211 - val_accuracy: 0.9099\n",
      "Epoch 72/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2430 - accuracy: 0.9236 - val_loss: 0.2191 - val_accuracy: 0.9068\n",
      "Epoch 73/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2387 - accuracy: 0.9256 - val_loss: 0.2169 - val_accuracy: 0.9068\n",
      "Epoch 74/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2449 - accuracy: 0.9250 - val_loss: 0.2152 - val_accuracy: 0.9099\n",
      "Epoch 75/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2422 - accuracy: 0.9219 - val_loss: 0.2144 - val_accuracy: 0.9099\n",
      "Epoch 76/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2555 - accuracy: 0.9179 - val_loss: 0.2146 - val_accuracy: 0.9099\n",
      "Epoch 77/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2382 - accuracy: 0.9239 - val_loss: 0.2146 - val_accuracy: 0.9099\n",
      "Epoch 78/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2438 - accuracy: 0.9243 - val_loss: 0.2155 - val_accuracy: 0.9068\n",
      "Epoch 79/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2390 - accuracy: 0.9230 - val_loss: 0.2158 - val_accuracy: 0.9130\n",
      "Epoch 80/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2367 - accuracy: 0.9260 - val_loss: 0.2166 - val_accuracy: 0.9099\n",
      "Epoch 81/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2363 - accuracy: 0.9273 - val_loss: 0.2176 - val_accuracy: 0.9099\n",
      "Epoch 82/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2441 - accuracy: 0.9226 - val_loss: 0.2189 - val_accuracy: 0.9068\n",
      "Epoch 83/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2424 - accuracy: 0.9219 - val_loss: 0.2157 - val_accuracy: 0.9099\n",
      "Epoch 84/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2417 - accuracy: 0.9210 - val_loss: 0.2118 - val_accuracy: 0.9130\n",
      "Epoch 85/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2391 - accuracy: 0.9243 - val_loss: 0.2094 - val_accuracy: 0.9068\n",
      "Epoch 86/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2450 - accuracy: 0.9233 - val_loss: 0.2082 - val_accuracy: 0.9130\n",
      "Epoch 87/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2359 - accuracy: 0.9219 - val_loss: 0.2077 - val_accuracy: 0.9161\n",
      "Epoch 88/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2424 - accuracy: 0.9226 - val_loss: 0.2080 - val_accuracy: 0.9161\n",
      "Epoch 89/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2393 - accuracy: 0.9213 - val_loss: 0.2090 - val_accuracy: 0.9099\n",
      "Epoch 90/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2340 - accuracy: 0.9246 - val_loss: 0.2121 - val_accuracy: 0.9130\n",
      "Epoch 91/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2380 - accuracy: 0.9243 - val_loss: 0.2168 - val_accuracy: 0.9099\n",
      "Epoch 92/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2314 - accuracy: 0.9230 - val_loss: 0.2187 - val_accuracy: 0.9099\n",
      "Epoch 93/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2367 - accuracy: 0.9193 - val_loss: 0.2162 - val_accuracy: 0.9099\n",
      "Epoch 94/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2360 - accuracy: 0.9233 - val_loss: 0.2107 - val_accuracy: 0.9099\n",
      "Epoch 95/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2233 - accuracy: 0.9283 - val_loss: 0.2076 - val_accuracy: 0.9130\n",
      "Epoch 96/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2353 - accuracy: 0.9260 - val_loss: 0.2074 - val_accuracy: 0.9099\n",
      "Epoch 97/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2340 - accuracy: 0.9246 - val_loss: 0.2082 - val_accuracy: 0.9130\n",
      "Epoch 98/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2340 - accuracy: 0.9220 - val_loss: 0.2097 - val_accuracy: 0.9099\n",
      "Epoch 99/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2254 - accuracy: 0.9257 - val_loss: 0.2106 - val_accuracy: 0.9130\n",
      "Epoch 100/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2189 - accuracy: 0.9277 - val_loss: 0.2117 - val_accuracy: 0.9130\n",
      "Epoch 101/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2378 - accuracy: 0.9243 - val_loss: 0.2124 - val_accuracy: 0.9130\n",
      "Epoch 102/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2333 - accuracy: 0.9250 - val_loss: 0.2095 - val_accuracy: 0.9130\n",
      "Epoch 103/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2333 - accuracy: 0.9250 - val_loss: 0.2068 - val_accuracy: 0.9130\n",
      "Epoch 104/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2206 - accuracy: 0.9283 - val_loss: 0.2057 - val_accuracy: 0.9130\n",
      "Epoch 105/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2282 - accuracy: 0.9270 - val_loss: 0.2068 - val_accuracy: 0.9099\n",
      "Epoch 106/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2273 - accuracy: 0.9263 - val_loss: 0.2059 - val_accuracy: 0.9161\n",
      "Epoch 107/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2263 - accuracy: 0.9250 - val_loss: 0.2040 - val_accuracy: 0.9130\n",
      "Epoch 108/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2236 - accuracy: 0.9250 - val_loss: 0.2033 - val_accuracy: 0.9161\n",
      "Epoch 109/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2271 - accuracy: 0.9257 - val_loss: 0.2045 - val_accuracy: 0.9161\n",
      "Epoch 110/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2318 - accuracy: 0.9230 - val_loss: 0.2059 - val_accuracy: 0.9161\n",
      "Epoch 111/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2221 - accuracy: 0.9283 - val_loss: 0.2064 - val_accuracy: 0.9161\n",
      "Epoch 112/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2163 - accuracy: 0.9297 - val_loss: 0.2075 - val_accuracy: 0.9130\n",
      "Epoch 113/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2274 - accuracy: 0.9260 - val_loss: 0.2088 - val_accuracy: 0.9161\n",
      "Epoch 114/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2282 - accuracy: 0.9280 - val_loss: 0.2066 - val_accuracy: 0.9161\n",
      "Epoch 115/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2243 - accuracy: 0.9253 - val_loss: 0.2031 - val_accuracy: 0.9130\n",
      "Epoch 116/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2244 - accuracy: 0.9267 - val_loss: 0.2006 - val_accuracy: 0.9130\n",
      "Epoch 117/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2212 - accuracy: 0.9287 - val_loss: 0.1997 - val_accuracy: 0.9130\n",
      "Epoch 118/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2220 - accuracy: 0.9267 - val_loss: 0.2000 - val_accuracy: 0.9130\n",
      "Epoch 119/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2282 - accuracy: 0.9260 - val_loss: 0.2003 - val_accuracy: 0.9130\n",
      "Epoch 120/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2255 - accuracy: 0.9260 - val_loss: 0.2002 - val_accuracy: 0.9161\n",
      "Epoch 121/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2260 - accuracy: 0.9273 - val_loss: 0.1998 - val_accuracy: 0.9161\n",
      "Epoch 122/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2216 - accuracy: 0.9267 - val_loss: 0.1997 - val_accuracy: 0.9161\n",
      "Epoch 123/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2261 - accuracy: 0.9280 - val_loss: 0.2008 - val_accuracy: 0.9161\n",
      "Epoch 124/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2205 - accuracy: 0.9273 - val_loss: 0.2018 - val_accuracy: 0.9130\n",
      "Epoch 125/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2213 - accuracy: 0.9267 - val_loss: 0.2025 - val_accuracy: 0.9130\n",
      "Epoch 126/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2204 - accuracy: 0.9273 - val_loss: 0.2020 - val_accuracy: 0.9161\n",
      "Epoch 127/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2168 - accuracy: 0.9273 - val_loss: 0.2005 - val_accuracy: 0.9161\n",
      "Epoch 128/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2096 - accuracy: 0.9307 - val_loss: 0.1994 - val_accuracy: 0.9161\n",
      "Epoch 129/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2159 - accuracy: 0.9260 - val_loss: 0.2005 - val_accuracy: 0.9161\n",
      "Epoch 130/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2227 - accuracy: 0.9247 - val_loss: 0.2009 - val_accuracy: 0.9161\n",
      "Epoch 131/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2128 - accuracy: 0.9287 - val_loss: 0.1988 - val_accuracy: 0.9161\n",
      "Epoch 132/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2150 - accuracy: 0.9273 - val_loss: 0.1967 - val_accuracy: 0.9193\n",
      "Epoch 133/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2123 - accuracy: 0.9280 - val_loss: 0.1964 - val_accuracy: 0.9161\n",
      "Epoch 134/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2175 - accuracy: 0.9267 - val_loss: 0.1971 - val_accuracy: 0.9161\n",
      "Epoch 135/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2165 - accuracy: 0.9273 - val_loss: 0.1975 - val_accuracy: 0.9161\n",
      "Epoch 136/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2129 - accuracy: 0.9307 - val_loss: 0.1967 - val_accuracy: 0.9161\n",
      "Epoch 137/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2139 - accuracy: 0.9293 - val_loss: 0.1950 - val_accuracy: 0.9161\n",
      "Epoch 138/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2142 - accuracy: 0.9250 - val_loss: 0.1940 - val_accuracy: 0.9193\n",
      "Epoch 139/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2231 - accuracy: 0.9237 - val_loss: 0.1939 - val_accuracy: 0.9193\n",
      "Epoch 140/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2086 - accuracy: 0.9283 - val_loss: 0.1946 - val_accuracy: 0.9161\n",
      "Epoch 141/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2195 - accuracy: 0.9267 - val_loss: 0.1984 - val_accuracy: 0.9130\n",
      "Epoch 142/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2138 - accuracy: 0.9287 - val_loss: 0.2019 - val_accuracy: 0.9193\n",
      "Epoch 143/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2153 - accuracy: 0.9277 - val_loss: 0.2015 - val_accuracy: 0.9193\n",
      "Epoch 144/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2091 - accuracy: 0.9283 - val_loss: 0.1967 - val_accuracy: 0.9193\n",
      "Epoch 145/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2078 - accuracy: 0.9293 - val_loss: 0.1937 - val_accuracy: 0.9161\n",
      "Epoch 146/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2146 - accuracy: 0.9260 - val_loss: 0.1923 - val_accuracy: 0.9193\n",
      "Epoch 147/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2116 - accuracy: 0.9273 - val_loss: 0.1919 - val_accuracy: 0.9255\n",
      "Epoch 148/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2049 - accuracy: 0.9283 - val_loss: 0.1934 - val_accuracy: 0.9255\n",
      "Epoch 149/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2106 - accuracy: 0.9237 - val_loss: 0.1972 - val_accuracy: 0.9193\n",
      "Epoch 150/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2106 - accuracy: 0.9273 - val_loss: 0.1990 - val_accuracy: 0.9161\n",
      "Epoch 151/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2050 - accuracy: 0.9280 - val_loss: 0.1991 - val_accuracy: 0.9193\n",
      "Epoch 152/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2069 - accuracy: 0.9283 - val_loss: 0.1991 - val_accuracy: 0.9193\n",
      "Epoch 153/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2041 - accuracy: 0.9287 - val_loss: 0.1977 - val_accuracy: 0.9193\n",
      "Epoch 154/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2035 - accuracy: 0.9263 - val_loss: 0.1983 - val_accuracy: 0.9193\n",
      "Epoch 155/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2157 - accuracy: 0.9223 - val_loss: 0.1978 - val_accuracy: 0.9193\n",
      "Epoch 156/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2089 - accuracy: 0.9273 - val_loss: 0.1919 - val_accuracy: 0.9255\n",
      "Epoch 157/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2015 - accuracy: 0.9324 - val_loss: 0.1883 - val_accuracy: 0.9255\n",
      "Epoch 158/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2117 - accuracy: 0.9196 - val_loss: 0.1880 - val_accuracy: 0.9255\n",
      "Epoch 159/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2098 - accuracy: 0.9186 - val_loss: 0.1894 - val_accuracy: 0.9255\n",
      "Epoch 160/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2039 - accuracy: 0.9310 - val_loss: 0.1939 - val_accuracy: 0.9161\n",
      "Epoch 161/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2034 - accuracy: 0.9293 - val_loss: 0.1973 - val_accuracy: 0.9193\n",
      "Epoch 162/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2026 - accuracy: 0.9280 - val_loss: 0.1955 - val_accuracy: 0.9193\n",
      "Epoch 163/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2012 - accuracy: 0.9300 - val_loss: 0.1921 - val_accuracy: 0.9193\n",
      "Epoch 164/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2012 - accuracy: 0.9280 - val_loss: 0.1901 - val_accuracy: 0.9286\n",
      "Epoch 165/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2044 - accuracy: 0.9277 - val_loss: 0.1892 - val_accuracy: 0.9255\n",
      "Epoch 166/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1978 - accuracy: 0.9324 - val_loss: 0.1899 - val_accuracy: 0.9286\n",
      "Epoch 167/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1971 - accuracy: 0.9310 - val_loss: 0.1936 - val_accuracy: 0.9224\n",
      "Epoch 168/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2020 - accuracy: 0.9273 - val_loss: 0.1966 - val_accuracy: 0.9224\n",
      "Epoch 169/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2068 - accuracy: 0.9257 - val_loss: 0.1923 - val_accuracy: 0.9224\n",
      "Epoch 170/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1958 - accuracy: 0.9300 - val_loss: 0.1896 - val_accuracy: 0.9224\n",
      "Epoch 171/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1950 - accuracy: 0.9293 - val_loss: 0.1900 - val_accuracy: 0.9224\n",
      "Epoch 172/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1936 - accuracy: 0.9287 - val_loss: 0.1941 - val_accuracy: 0.9224\n",
      "Epoch 173/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2020 - accuracy: 0.9301 - val_loss: 0.1973 - val_accuracy: 0.9224\n",
      "Epoch 174/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2024 - accuracy: 0.9294 - val_loss: 0.1918 - val_accuracy: 0.9286\n",
      "Epoch 175/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1992 - accuracy: 0.9260 - val_loss: 0.1858 - val_accuracy: 0.9286\n",
      "Epoch 176/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2002 - accuracy: 0.9260 - val_loss: 0.1830 - val_accuracy: 0.9255\n",
      "Epoch 177/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1971 - accuracy: 0.9273 - val_loss: 0.1830 - val_accuracy: 0.9255\n",
      "Epoch 178/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1998 - accuracy: 0.9290 - val_loss: 0.1856 - val_accuracy: 0.9286\n",
      "Epoch 179/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1931 - accuracy: 0.9300 - val_loss: 0.1903 - val_accuracy: 0.9255\n",
      "Epoch 180/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2001 - accuracy: 0.9277 - val_loss: 0.1939 - val_accuracy: 0.9224\n",
      "Epoch 181/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2048 - accuracy: 0.9308 - val_loss: 0.1888 - val_accuracy: 0.9255\n",
      "Epoch 182/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1930 - accuracy: 0.9313 - val_loss: 0.1834 - val_accuracy: 0.9286\n",
      "Epoch 183/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2007 - accuracy: 0.9273 - val_loss: 0.1811 - val_accuracy: 0.9286\n",
      "Epoch 184/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1920 - accuracy: 0.9304 - val_loss: 0.1816 - val_accuracy: 0.9286\n",
      "Epoch 185/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1964 - accuracy: 0.9273 - val_loss: 0.1860 - val_accuracy: 0.9224\n",
      "Epoch 186/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1990 - accuracy: 0.9307 - val_loss: 0.1904 - val_accuracy: 0.9255\n",
      "Epoch 187/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1955 - accuracy: 0.9345 - val_loss: 0.1867 - val_accuracy: 0.9317\n",
      "Epoch 188/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1926 - accuracy: 0.9321 - val_loss: 0.1806 - val_accuracy: 0.9286\n",
      "Epoch 189/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1943 - accuracy: 0.9277 - val_loss: 0.1791 - val_accuracy: 0.9317\n",
      "Epoch 190/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1928 - accuracy: 0.9230 - val_loss: 0.1797 - val_accuracy: 0.9286\n",
      "Epoch 191/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1832 - accuracy: 0.9333 - val_loss: 0.1851 - val_accuracy: 0.9317\n",
      "Epoch 192/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1911 - accuracy: 0.9290 - val_loss: 0.1937 - val_accuracy: 0.9348\n",
      "Epoch 193/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1915 - accuracy: 0.9378 - val_loss: 0.1895 - val_accuracy: 0.9379\n",
      "Epoch 194/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1911 - accuracy: 0.9351 - val_loss: 0.1818 - val_accuracy: 0.9286\n",
      "Epoch 195/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1900 - accuracy: 0.9331 - val_loss: 0.1778 - val_accuracy: 0.9317\n",
      "Epoch 196/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1847 - accuracy: 0.9331 - val_loss: 0.1769 - val_accuracy: 0.9317\n",
      "Epoch 197/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1833 - accuracy: 0.9327 - val_loss: 0.1810 - val_accuracy: 0.9348\n",
      "Epoch 198/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1863 - accuracy: 0.9368 - val_loss: 0.1873 - val_accuracy: 0.9410\n",
      "Epoch 199/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1939 - accuracy: 0.9348 - val_loss: 0.1849 - val_accuracy: 0.9348\n",
      "Epoch 200/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1880 - accuracy: 0.9348 - val_loss: 0.1780 - val_accuracy: 0.9348\n",
      "Epoch 201/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1888 - accuracy: 0.9324 - val_loss: 0.1757 - val_accuracy: 0.9348\n",
      "Epoch 202/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1863 - accuracy: 0.9341 - val_loss: 0.1748 - val_accuracy: 0.9379\n",
      "Epoch 203/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1856 - accuracy: 0.9334 - val_loss: 0.1761 - val_accuracy: 0.9348\n",
      "Epoch 204/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1911 - accuracy: 0.9348 - val_loss: 0.1802 - val_accuracy: 0.9379\n",
      "Epoch 205/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1847 - accuracy: 0.9381 - val_loss: 0.1793 - val_accuracy: 0.9379\n",
      "Epoch 206/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1900 - accuracy: 0.9348 - val_loss: 0.1765 - val_accuracy: 0.9348\n",
      "Epoch 207/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1845 - accuracy: 0.9375 - val_loss: 0.1731 - val_accuracy: 0.9379\n",
      "Epoch 208/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1866 - accuracy: 0.9324 - val_loss: 0.1719 - val_accuracy: 0.9379\n",
      "Epoch 209/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1833 - accuracy: 0.9314 - val_loss: 0.1730 - val_accuracy: 0.9379\n",
      "Epoch 210/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1901 - accuracy: 0.9325 - val_loss: 0.1751 - val_accuracy: 0.9348\n",
      "Epoch 211/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1857 - accuracy: 0.9361 - val_loss: 0.1744 - val_accuracy: 0.9379\n",
      "Epoch 212/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1835 - accuracy: 0.9392 - val_loss: 0.1726 - val_accuracy: 0.9348\n",
      "Epoch 213/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1837 - accuracy: 0.9395 - val_loss: 0.1713 - val_accuracy: 0.9348\n",
      "Epoch 214/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1776 - accuracy: 0.9405 - val_loss: 0.1726 - val_accuracy: 0.9348\n",
      "Epoch 215/3500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1741 - accuracy: 0.9452 - val_loss: 0.1794 - val_accuracy: 0.9410\n",
      "Epoch 216/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1797 - accuracy: 0.9392 - val_loss: 0.1883 - val_accuracy: 0.9441\n",
      "Epoch 217/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1878 - accuracy: 0.9436 - val_loss: 0.1816 - val_accuracy: 0.9410\n",
      "Epoch 218/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1807 - accuracy: 0.9409 - val_loss: 0.1704 - val_accuracy: 0.9441\n",
      "Epoch 219/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1803 - accuracy: 0.9405 - val_loss: 0.1669 - val_accuracy: 0.9379\n",
      "Epoch 220/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1849 - accuracy: 0.9345 - val_loss: 0.1661 - val_accuracy: 0.9410\n",
      "Epoch 221/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1838 - accuracy: 0.9358 - val_loss: 0.1663 - val_accuracy: 0.9441\n",
      "Epoch 222/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1775 - accuracy: 0.9395 - val_loss: 0.1719 - val_accuracy: 0.9410\n",
      "Epoch 223/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1808 - accuracy: 0.9412 - val_loss: 0.1816 - val_accuracy: 0.9441\n",
      "Epoch 224/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1847 - accuracy: 0.9426 - val_loss: 0.1761 - val_accuracy: 0.9441\n",
      "Epoch 225/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1785 - accuracy: 0.9456 - val_loss: 0.1663 - val_accuracy: 0.9472\n",
      "Epoch 226/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1781 - accuracy: 0.9409 - val_loss: 0.1649 - val_accuracy: 0.9379\n",
      "Epoch 227/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1810 - accuracy: 0.9337 - val_loss: 0.1658 - val_accuracy: 0.9379\n",
      "Epoch 228/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1805 - accuracy: 0.9354 - val_loss: 0.1701 - val_accuracy: 0.9472\n",
      "Epoch 229/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1699 - accuracy: 0.9456 - val_loss: 0.1770 - val_accuracy: 0.9441\n",
      "Epoch 230/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1755 - accuracy: 0.9493 - val_loss: 0.1779 - val_accuracy: 0.9441\n",
      "Epoch 231/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1767 - accuracy: 0.9466 - val_loss: 0.1686 - val_accuracy: 0.9472\n",
      "Epoch 232/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1728 - accuracy: 0.9463 - val_loss: 0.1629 - val_accuracy: 0.9472\n",
      "Epoch 233/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1745 - accuracy: 0.9415 - val_loss: 0.1620 - val_accuracy: 0.9441\n",
      "Epoch 234/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1696 - accuracy: 0.9398 - val_loss: 0.1647 - val_accuracy: 0.9472\n",
      "Epoch 235/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1767 - accuracy: 0.9439 - val_loss: 0.1732 - val_accuracy: 0.9503\n",
      "Epoch 236/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1733 - accuracy: 0.9503 - val_loss: 0.1717 - val_accuracy: 0.9503\n",
      "Epoch 237/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1708 - accuracy: 0.9480 - val_loss: 0.1652 - val_accuracy: 0.9441\n",
      "Epoch 238/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1703 - accuracy: 0.9489 - val_loss: 0.1627 - val_accuracy: 0.9472\n",
      "Epoch 239/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1729 - accuracy: 0.9473 - val_loss: 0.1637 - val_accuracy: 0.9441\n",
      "Epoch 240/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1785 - accuracy: 0.9440 - val_loss: 0.1646 - val_accuracy: 0.9472\n",
      "Epoch 241/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1716 - accuracy: 0.9473 - val_loss: 0.1623 - val_accuracy: 0.9472\n",
      "Epoch 242/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1726 - accuracy: 0.9473 - val_loss: 0.1602 - val_accuracy: 0.9441\n",
      "Epoch 243/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1722 - accuracy: 0.9460 - val_loss: 0.1601 - val_accuracy: 0.9441\n",
      "Epoch 244/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1763 - accuracy: 0.9470 - val_loss: 0.1622 - val_accuracy: 0.9503\n",
      "Epoch 245/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1666 - accuracy: 0.9523 - val_loss: 0.1631 - val_accuracy: 0.9503\n",
      "Epoch 246/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1654 - accuracy: 0.9503 - val_loss: 0.1656 - val_accuracy: 0.9503\n",
      "Epoch 247/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1713 - accuracy: 0.9507 - val_loss: 0.1648 - val_accuracy: 0.9503\n",
      "Epoch 248/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1702 - accuracy: 0.9483 - val_loss: 0.1580 - val_accuracy: 0.9472\n",
      "Epoch 249/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1641 - accuracy: 0.9479 - val_loss: 0.1564 - val_accuracy: 0.9472\n",
      "Epoch 250/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1762 - accuracy: 0.9389 - val_loss: 0.1575 - val_accuracy: 0.9472\n",
      "Epoch 251/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1653 - accuracy: 0.9496 - val_loss: 0.1579 - val_accuracy: 0.9472\n",
      "Epoch 252/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1678 - accuracy: 0.9480 - val_loss: 0.1569 - val_accuracy: 0.9441\n",
      "Epoch 253/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1642 - accuracy: 0.9507 - val_loss: 0.1555 - val_accuracy: 0.9472\n",
      "Epoch 254/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1633 - accuracy: 0.9513 - val_loss: 0.1551 - val_accuracy: 0.9472\n",
      "Epoch 255/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1719 - accuracy: 0.9473 - val_loss: 0.1559 - val_accuracy: 0.9441\n",
      "Epoch 256/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1617 - accuracy: 0.9513 - val_loss: 0.1572 - val_accuracy: 0.9503\n",
      "Epoch 257/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1635 - accuracy: 0.9500 - val_loss: 0.1584 - val_accuracy: 0.9503\n",
      "Epoch 258/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1593 - accuracy: 0.9544 - val_loss: 0.1584 - val_accuracy: 0.9534\n",
      "Epoch 259/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1585 - accuracy: 0.9513 - val_loss: 0.1605 - val_accuracy: 0.9534\n",
      "Epoch 260/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1639 - accuracy: 0.9510 - val_loss: 0.1586 - val_accuracy: 0.9534\n",
      "Epoch 261/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1600 - accuracy: 0.9507 - val_loss: 0.1532 - val_accuracy: 0.9472\n",
      "Epoch 262/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1594 - accuracy: 0.9483 - val_loss: 0.1516 - val_accuracy: 0.9472\n",
      "Epoch 263/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1618 - accuracy: 0.9490 - val_loss: 0.1526 - val_accuracy: 0.9472\n",
      "Epoch 264/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1624 - accuracy: 0.9500 - val_loss: 0.1553 - val_accuracy: 0.9534\n",
      "Epoch 265/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1614 - accuracy: 0.9500 - val_loss: 0.1559 - val_accuracy: 0.9565\n",
      "Epoch 266/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1603 - accuracy: 0.9513 - val_loss: 0.1528 - val_accuracy: 0.9472\n",
      "Epoch 267/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1585 - accuracy: 0.9507 - val_loss: 0.1510 - val_accuracy: 0.9472\n",
      "Epoch 268/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1530 - accuracy: 0.9503 - val_loss: 0.1528 - val_accuracy: 0.9472\n",
      "Epoch 269/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1581 - accuracy: 0.9483 - val_loss: 0.1587 - val_accuracy: 0.9565\n",
      "Epoch 270/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1578 - accuracy: 0.9554 - val_loss: 0.1583 - val_accuracy: 0.9565\n",
      "Epoch 271/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1552 - accuracy: 0.9544 - val_loss: 0.1533 - val_accuracy: 0.9565\n",
      "Epoch 272/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1505 - accuracy: 0.9533 - val_loss: 0.1515 - val_accuracy: 0.9565\n",
      "Epoch 273/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1500 - accuracy: 0.9520 - val_loss: 0.1516 - val_accuracy: 0.9565\n",
      "Epoch 274/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1528 - accuracy: 0.9524 - val_loss: 0.1524 - val_accuracy: 0.9565\n",
      "Epoch 275/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1546 - accuracy: 0.9530 - val_loss: 0.1511 - val_accuracy: 0.9565\n",
      "Epoch 276/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1563 - accuracy: 0.9493 - val_loss: 0.1492 - val_accuracy: 0.9503\n",
      "Epoch 277/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1553 - accuracy: 0.9507 - val_loss: 0.1491 - val_accuracy: 0.9565\n",
      "Epoch 278/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1469 - accuracy: 0.9533 - val_loss: 0.1530 - val_accuracy: 0.9534\n",
      "Epoch 279/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1569 - accuracy: 0.9520 - val_loss: 0.1546 - val_accuracy: 0.9534\n",
      "Epoch 280/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1554 - accuracy: 0.9520 - val_loss: 0.1459 - val_accuracy: 0.9503\n",
      "Epoch 281/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1511 - accuracy: 0.9516 - val_loss: 0.1443 - val_accuracy: 0.9472\n",
      "Epoch 282/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1525 - accuracy: 0.9513 - val_loss: 0.1498 - val_accuracy: 0.9565\n",
      "Epoch 283/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1552 - accuracy: 0.9504 - val_loss: 0.1574 - val_accuracy: 0.9534\n",
      "Epoch 284/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1555 - accuracy: 0.9540 - val_loss: 0.1475 - val_accuracy: 0.9596\n",
      "Epoch 285/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1520 - accuracy: 0.9500 - val_loss: 0.1440 - val_accuracy: 0.9472\n",
      "Epoch 286/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1508 - accuracy: 0.9500 - val_loss: 0.1475 - val_accuracy: 0.9565\n",
      "Epoch 287/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1467 - accuracy: 0.9554 - val_loss: 0.1528 - val_accuracy: 0.9565\n",
      "Epoch 288/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1500 - accuracy: 0.9534 - val_loss: 0.1483 - val_accuracy: 0.9565\n",
      "Epoch 289/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1497 - accuracy: 0.9517 - val_loss: 0.1432 - val_accuracy: 0.9503\n",
      "Epoch 290/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1417 - accuracy: 0.9533 - val_loss: 0.1443 - val_accuracy: 0.9565\n",
      "Epoch 291/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1461 - accuracy: 0.9530 - val_loss: 0.1506 - val_accuracy: 0.9565\n",
      "Epoch 292/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1453 - accuracy: 0.9547 - val_loss: 0.1501 - val_accuracy: 0.9565\n",
      "Epoch 293/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1454 - accuracy: 0.9530 - val_loss: 0.1430 - val_accuracy: 0.9503\n",
      "Epoch 294/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1461 - accuracy: 0.9507 - val_loss: 0.1426 - val_accuracy: 0.9503\n",
      "Epoch 295/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1466 - accuracy: 0.9513 - val_loss: 0.1450 - val_accuracy: 0.9596\n",
      "Epoch 296/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1453 - accuracy: 0.9527 - val_loss: 0.1475 - val_accuracy: 0.9565\n",
      "Epoch 297/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1443 - accuracy: 0.9540 - val_loss: 0.1451 - val_accuracy: 0.9565\n",
      "Epoch 298/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1487 - accuracy: 0.9510 - val_loss: 0.1400 - val_accuracy: 0.9534\n",
      "Epoch 299/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1458 - accuracy: 0.9517 - val_loss: 0.1394 - val_accuracy: 0.9503\n",
      "Epoch 300/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1472 - accuracy: 0.9524 - val_loss: 0.1436 - val_accuracy: 0.9565\n",
      "Epoch 301/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1491 - accuracy: 0.9537 - val_loss: 0.1477 - val_accuracy: 0.9565\n",
      "Epoch 302/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1441 - accuracy: 0.9564 - val_loss: 0.1405 - val_accuracy: 0.9596\n",
      "Epoch 303/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1412 - accuracy: 0.9550 - val_loss: 0.1391 - val_accuracy: 0.9596\n",
      "Epoch 304/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1452 - accuracy: 0.9510 - val_loss: 0.1426 - val_accuracy: 0.9565\n",
      "Epoch 305/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1422 - accuracy: 0.9557 - val_loss: 0.1446 - val_accuracy: 0.9565\n",
      "Epoch 306/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1430 - accuracy: 0.9557 - val_loss: 0.1410 - val_accuracy: 0.9596\n",
      "Epoch 307/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1398 - accuracy: 0.9537 - val_loss: 0.1415 - val_accuracy: 0.9596\n",
      "Epoch 308/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1378 - accuracy: 0.9530 - val_loss: 0.1468 - val_accuracy: 0.9565\n",
      "Epoch 309/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1485 - accuracy: 0.9531 - val_loss: 0.1440 - val_accuracy: 0.9565\n",
      "Epoch 310/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1420 - accuracy: 0.9557 - val_loss: 0.1367 - val_accuracy: 0.9503\n",
      "Epoch 311/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1439 - accuracy: 0.9517 - val_loss: 0.1364 - val_accuracy: 0.9503\n",
      "Epoch 312/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1419 - accuracy: 0.9507 - val_loss: 0.1436 - val_accuracy: 0.9565\n",
      "Epoch 313/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1459 - accuracy: 0.9598 - val_loss: 0.1532 - val_accuracy: 0.9565\n",
      "Epoch 314/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1428 - accuracy: 0.9645 - val_loss: 0.1382 - val_accuracy: 0.9596\n",
      "Epoch 315/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1371 - accuracy: 0.9567 - val_loss: 0.1352 - val_accuracy: 0.9503\n",
      "Epoch 316/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1451 - accuracy: 0.9507 - val_loss: 0.1373 - val_accuracy: 0.9596\n",
      "Epoch 317/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1354 - accuracy: 0.9524 - val_loss: 0.1445 - val_accuracy: 0.9565\n",
      "Epoch 318/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1344 - accuracy: 0.9608 - val_loss: 0.1482 - val_accuracy: 0.9565\n",
      "Epoch 319/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1415 - accuracy: 0.9611 - val_loss: 0.1394 - val_accuracy: 0.9596\n",
      "Epoch 320/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1379 - accuracy: 0.9537 - val_loss: 0.1350 - val_accuracy: 0.9534\n",
      "Epoch 321/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1398 - accuracy: 0.9530 - val_loss: 0.1351 - val_accuracy: 0.9596\n",
      "Epoch 322/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1331 - accuracy: 0.9537 - val_loss: 0.1380 - val_accuracy: 0.9596\n",
      "Epoch 323/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1403 - accuracy: 0.9534 - val_loss: 0.1421 - val_accuracy: 0.9565\n",
      "Epoch 324/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1355 - accuracy: 0.9622 - val_loss: 0.1374 - val_accuracy: 0.9596\n",
      "Epoch 325/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1365 - accuracy: 0.9557 - val_loss: 0.1333 - val_accuracy: 0.9596\n",
      "Epoch 326/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1407 - accuracy: 0.9504 - val_loss: 0.1330 - val_accuracy: 0.9596\n",
      "Epoch 327/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1354 - accuracy: 0.9530 - val_loss: 0.1332 - val_accuracy: 0.9596\n",
      "Epoch 328/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1339 - accuracy: 0.9530 - val_loss: 0.1376 - val_accuracy: 0.9596\n",
      "Epoch 329/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1408 - accuracy: 0.9568 - val_loss: 0.1399 - val_accuracy: 0.9596\n",
      "Epoch 330/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1390 - accuracy: 0.9625 - val_loss: 0.1320 - val_accuracy: 0.9596\n",
      "Epoch 331/3500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1317 - accuracy: 0.9544 - val_loss: 0.1311 - val_accuracy: 0.9627\n",
      "Epoch 332/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1305 - accuracy: 0.9537 - val_loss: 0.1372 - val_accuracy: 0.9596\n",
      "Epoch 333/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1378 - accuracy: 0.9605 - val_loss: 0.1429 - val_accuracy: 0.9596\n",
      "Epoch 334/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1331 - accuracy: 0.9675 - val_loss: 0.1352 - val_accuracy: 0.9565\n",
      "Epoch 335/3500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1316 - accuracy: 0.9601 - val_loss: 0.1315 - val_accuracy: 0.9596\n",
      "Epoch 336/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1357 - accuracy: 0.9517 - val_loss: 0.1314 - val_accuracy: 0.9596\n",
      "Epoch 337/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1276 - accuracy: 0.9530 - val_loss: 0.1368 - val_accuracy: 0.9596\n",
      "Epoch 338/3500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1299 - accuracy: 0.9645 - val_loss: 0.1429 - val_accuracy: 0.9596\n",
      "Epoch 339/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1330 - accuracy: 0.9689 - val_loss: 0.1345 - val_accuracy: 0.9596\n",
      "Epoch 340/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1326 - accuracy: 0.9578 - val_loss: 0.1305 - val_accuracy: 0.9596\n",
      "Epoch 341/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1270 - accuracy: 0.9544 - val_loss: 0.1317 - val_accuracy: 0.9596\n",
      "Epoch 342/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1312 - accuracy: 0.9595 - val_loss: 0.1372 - val_accuracy: 0.9596\n",
      "Epoch 343/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1340 - accuracy: 0.9632 - val_loss: 0.1338 - val_accuracy: 0.9596\n",
      "Epoch 344/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1280 - accuracy: 0.9622 - val_loss: 0.1287 - val_accuracy: 0.9596\n",
      "Epoch 345/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1330 - accuracy: 0.9544 - val_loss: 0.1283 - val_accuracy: 0.9596\n",
      "Epoch 346/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1297 - accuracy: 0.9564 - val_loss: 0.1306 - val_accuracy: 0.9627\n",
      "Epoch 347/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1257 - accuracy: 0.9635 - val_loss: 0.1407 - val_accuracy: 0.9534\n",
      "Epoch 348/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1312 - accuracy: 0.9726 - val_loss: 0.1370 - val_accuracy: 0.9596\n",
      "Epoch 349/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1233 - accuracy: 0.9706 - val_loss: 0.1264 - val_accuracy: 0.9627\n",
      "Epoch 350/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1256 - accuracy: 0.9577 - val_loss: 0.1262 - val_accuracy: 0.9627\n",
      "Epoch 351/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1214 - accuracy: 0.9554 - val_loss: 0.1385 - val_accuracy: 0.9596\n",
      "Epoch 352/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1370 - accuracy: 0.9652 - val_loss: 0.1461 - val_accuracy: 0.9565\n",
      "Epoch 353/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1388 - accuracy: 0.9706 - val_loss: 0.1269 - val_accuracy: 0.9627\n",
      "Epoch 354/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1305 - accuracy: 0.9524 - val_loss: 0.1260 - val_accuracy: 0.9534\n",
      "Epoch 355/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1352 - accuracy: 0.9504 - val_loss: 0.1270 - val_accuracy: 0.9627\n",
      "Epoch 356/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1270 - accuracy: 0.9611 - val_loss: 0.1361 - val_accuracy: 0.9596\n",
      "Epoch 357/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1236 - accuracy: 0.9699 - val_loss: 0.1287 - val_accuracy: 0.9627\n",
      "Epoch 358/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1297 - accuracy: 0.9602 - val_loss: 0.1249 - val_accuracy: 0.9627\n",
      "Epoch 359/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1275 - accuracy: 0.9551 - val_loss: 0.1245 - val_accuracy: 0.9627\n",
      "Epoch 360/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1299 - accuracy: 0.9554 - val_loss: 0.1283 - val_accuracy: 0.9627\n",
      "Epoch 361/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1209 - accuracy: 0.9665 - val_loss: 0.1346 - val_accuracy: 0.9565\n",
      "Epoch 362/3500\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1241 - accuracy: 0.9736 - val_loss: 0.1285 - val_accuracy: 0.9627\n",
      "Epoch 363/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1250 - accuracy: 0.9669 - val_loss: 0.1247 - val_accuracy: 0.9658\n",
      "Epoch 364/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1213 - accuracy: 0.9628 - val_loss: 0.1293 - val_accuracy: 0.9627\n",
      "Epoch 365/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1207 - accuracy: 0.9682 - val_loss: 0.1424 - val_accuracy: 0.9565\n",
      "Epoch 366/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1290 - accuracy: 0.9733 - val_loss: 0.1301 - val_accuracy: 0.9627\n",
      "Epoch 367/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1204 - accuracy: 0.9679 - val_loss: 0.1232 - val_accuracy: 0.9627\n",
      "Epoch 368/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1246 - accuracy: 0.9551 - val_loss: 0.1236 - val_accuracy: 0.9627\n",
      "Epoch 369/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1210 - accuracy: 0.9540 - val_loss: 0.1298 - val_accuracy: 0.9627\n",
      "Epoch 370/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1278 - accuracy: 0.9645 - val_loss: 0.1361 - val_accuracy: 0.9627\n",
      "Epoch 371/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1265 - accuracy: 0.9686 - val_loss: 0.1257 - val_accuracy: 0.9627\n",
      "Epoch 372/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1197 - accuracy: 0.9635 - val_loss: 0.1250 - val_accuracy: 0.9627\n",
      "Epoch 373/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1220 - accuracy: 0.9622 - val_loss: 0.1314 - val_accuracy: 0.9596\n",
      "Epoch 374/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1218 - accuracy: 0.9706 - val_loss: 0.1278 - val_accuracy: 0.9627\n",
      "Epoch 375/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1214 - accuracy: 0.9689 - val_loss: 0.1234 - val_accuracy: 0.9627\n",
      "Epoch 376/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1265 - accuracy: 0.9598 - val_loss: 0.1226 - val_accuracy: 0.9627\n",
      "Epoch 377/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1208 - accuracy: 0.9625 - val_loss: 0.1245 - val_accuracy: 0.9627\n",
      "Epoch 378/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1204 - accuracy: 0.9675 - val_loss: 0.1276 - val_accuracy: 0.9627\n",
      "Epoch 379/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1155 - accuracy: 0.9699 - val_loss: 0.1253 - val_accuracy: 0.9627\n",
      "Epoch 380/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1218 - accuracy: 0.9649 - val_loss: 0.1233 - val_accuracy: 0.9627\n",
      "Epoch 381/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1175 - accuracy: 0.9655 - val_loss: 0.1244 - val_accuracy: 0.9627\n",
      "Epoch 382/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1239 - accuracy: 0.9659 - val_loss: 0.1266 - val_accuracy: 0.9627\n",
      "Epoch 383/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1221 - accuracy: 0.9655 - val_loss: 0.1224 - val_accuracy: 0.9627\n",
      "Epoch 384/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1148 - accuracy: 0.9645 - val_loss: 0.1212 - val_accuracy: 0.9627\n",
      "Epoch 385/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1145 - accuracy: 0.9618 - val_loss: 0.1277 - val_accuracy: 0.9627\n",
      "Epoch 386/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1099 - accuracy: 0.9739 - val_loss: 0.1366 - val_accuracy: 0.9596\n",
      "Epoch 387/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1192 - accuracy: 0.9730 - val_loss: 0.1275 - val_accuracy: 0.9627\n",
      "Epoch 388/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1176 - accuracy: 0.9702 - val_loss: 0.1214 - val_accuracy: 0.9627\n",
      "Epoch 389/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1214 - accuracy: 0.9598 - val_loss: 0.1211 - val_accuracy: 0.9627\n",
      "Epoch 390/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1148 - accuracy: 0.9625 - val_loss: 0.1232 - val_accuracy: 0.9627\n",
      "Epoch 391/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1200 - accuracy: 0.9659 - val_loss: 0.1242 - val_accuracy: 0.9627\n",
      "Epoch 392/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1111 - accuracy: 0.9682 - val_loss: 0.1217 - val_accuracy: 0.9627\n",
      "Epoch 393/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1130 - accuracy: 0.9679 - val_loss: 0.1224 - val_accuracy: 0.9627\n",
      "Epoch 394/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1144 - accuracy: 0.9662 - val_loss: 0.1241 - val_accuracy: 0.9627\n",
      "Epoch 395/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1142 - accuracy: 0.9679 - val_loss: 0.1227 - val_accuracy: 0.9627\n",
      "Epoch 396/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1137 - accuracy: 0.9679 - val_loss: 0.1232 - val_accuracy: 0.9627\n",
      "Epoch 397/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1131 - accuracy: 0.9682 - val_loss: 0.1266 - val_accuracy: 0.9627\n",
      "Epoch 398/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1213 - accuracy: 0.9686 - val_loss: 0.1242 - val_accuracy: 0.9627\n",
      "Epoch 399/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1106 - accuracy: 0.9699 - val_loss: 0.1194 - val_accuracy: 0.9627\n",
      "Epoch 400/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1133 - accuracy: 0.9648 - val_loss: 0.1197 - val_accuracy: 0.9627\n",
      "Epoch 401/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1143 - accuracy: 0.9679 - val_loss: 0.1278 - val_accuracy: 0.9596\n",
      "Epoch 402/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1179 - accuracy: 0.9716 - val_loss: 0.1244 - val_accuracy: 0.9627\n",
      "Epoch 403/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1140 - accuracy: 0.9736 - val_loss: 0.1186 - val_accuracy: 0.9627\n",
      "Epoch 404/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1151 - accuracy: 0.9645 - val_loss: 0.1182 - val_accuracy: 0.9627\n",
      "Epoch 405/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1164 - accuracy: 0.9605 - val_loss: 0.1194 - val_accuracy: 0.9627\n",
      "Epoch 406/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1195 - accuracy: 0.9625 - val_loss: 0.1222 - val_accuracy: 0.9627\n",
      "Epoch 407/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1096 - accuracy: 0.9713 - val_loss: 0.1194 - val_accuracy: 0.9627\n",
      "Epoch 408/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1106 - accuracy: 0.9675 - val_loss: 0.1201 - val_accuracy: 0.9627\n",
      "Epoch 409/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1103 - accuracy: 0.9709 - val_loss: 0.1288 - val_accuracy: 0.9627\n",
      "Epoch 410/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1175 - accuracy: 0.9716 - val_loss: 0.1302 - val_accuracy: 0.9596\n",
      "Epoch 411/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1166 - accuracy: 0.9710 - val_loss: 0.1176 - val_accuracy: 0.9627\n",
      "Epoch 412/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1155 - accuracy: 0.9639 - val_loss: 0.1170 - val_accuracy: 0.9627\n",
      "Epoch 413/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1118 - accuracy: 0.9615 - val_loss: 0.1199 - val_accuracy: 0.9627\n",
      "Epoch 414/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1133 - accuracy: 0.9693 - val_loss: 0.1319 - val_accuracy: 0.9596\n",
      "Epoch 415/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1122 - accuracy: 0.9743 - val_loss: 0.1224 - val_accuracy: 0.9627\n",
      "Epoch 416/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1072 - accuracy: 0.9743 - val_loss: 0.1172 - val_accuracy: 0.9627\n",
      "Epoch 417/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1118 - accuracy: 0.9662 - val_loss: 0.1197 - val_accuracy: 0.9627\n",
      "Epoch 418/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1144 - accuracy: 0.9672 - val_loss: 0.1236 - val_accuracy: 0.9627\n",
      "Epoch 419/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1142 - accuracy: 0.9706 - val_loss: 0.1212 - val_accuracy: 0.9627\n",
      "Epoch 420/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1124 - accuracy: 0.9699 - val_loss: 0.1187 - val_accuracy: 0.9627\n",
      "Epoch 421/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1135 - accuracy: 0.9676 - val_loss: 0.1170 - val_accuracy: 0.9627\n",
      "Epoch 422/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1134 - accuracy: 0.9672 - val_loss: 0.1164 - val_accuracy: 0.9627\n",
      "Epoch 423/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1096 - accuracy: 0.9655 - val_loss: 0.1184 - val_accuracy: 0.9627\n",
      "Epoch 424/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1165 - accuracy: 0.9669 - val_loss: 0.1208 - val_accuracy: 0.9627\n",
      "Epoch 425/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1110 - accuracy: 0.9723 - val_loss: 0.1186 - val_accuracy: 0.9627\n",
      "Epoch 426/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1051 - accuracy: 0.9696 - val_loss: 0.1179 - val_accuracy: 0.9627\n",
      "Epoch 427/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1104 - accuracy: 0.9689 - val_loss: 0.1184 - val_accuracy: 0.9627\n",
      "Epoch 428/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1037 - accuracy: 0.9716 - val_loss: 0.1231 - val_accuracy: 0.9627\n",
      "Epoch 429/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1129 - accuracy: 0.9733 - val_loss: 0.1223 - val_accuracy: 0.9627\n",
      "Epoch 430/3500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1087 - accuracy: 0.9699 - val_loss: 0.1172 - val_accuracy: 0.9627\n",
      "Epoch 431/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1109 - accuracy: 0.9655 - val_loss: 0.1171 - val_accuracy: 0.9627\n",
      "Epoch 432/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1098 - accuracy: 0.9679 - val_loss: 0.1167 - val_accuracy: 0.9627\n",
      "Epoch 433/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1062 - accuracy: 0.9696 - val_loss: 0.1179 - val_accuracy: 0.9627\n",
      "Epoch 434/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1046 - accuracy: 0.9730 - val_loss: 0.1198 - val_accuracy: 0.9627\n",
      "Epoch 435/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1101 - accuracy: 0.9716 - val_loss: 0.1153 - val_accuracy: 0.9627\n",
      "Epoch 436/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1110 - accuracy: 0.9666 - val_loss: 0.1135 - val_accuracy: 0.9627\n",
      "Epoch 437/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1089 - accuracy: 0.9649 - val_loss: 0.1137 - val_accuracy: 0.9627\n",
      "Epoch 438/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1095 - accuracy: 0.9689 - val_loss: 0.1166 - val_accuracy: 0.9627\n",
      "Epoch 439/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1092 - accuracy: 0.9730 - val_loss: 0.1172 - val_accuracy: 0.9627\n",
      "Epoch 440/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1061 - accuracy: 0.9726 - val_loss: 0.1139 - val_accuracy: 0.9627\n",
      "Epoch 441/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1088 - accuracy: 0.9672 - val_loss: 0.1150 - val_accuracy: 0.9627\n",
      "Epoch 442/3500\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1061 - accuracy: 0.9689 - val_loss: 0.1175 - val_accuracy: 0.9627\n",
      "Epoch 443/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1039 - accuracy: 0.9730 - val_loss: 0.1175 - val_accuracy: 0.9627\n",
      "Epoch 444/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1073 - accuracy: 0.9710 - val_loss: 0.1151 - val_accuracy: 0.9627\n",
      "Epoch 445/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1064 - accuracy: 0.9689 - val_loss: 0.1128 - val_accuracy: 0.9627\n",
      "Epoch 446/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1068 - accuracy: 0.9659 - val_loss: 0.1127 - val_accuracy: 0.9627\n",
      "Epoch 447/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1105 - accuracy: 0.9632 - val_loss: 0.1154 - val_accuracy: 0.9627\n",
      "Epoch 448/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1022 - accuracy: 0.9743 - val_loss: 0.1200 - val_accuracy: 0.9627\n",
      "Epoch 449/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1079 - accuracy: 0.9716 - val_loss: 0.1164 - val_accuracy: 0.9627\n",
      "Epoch 450/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1016 - accuracy: 0.9709 - val_loss: 0.1132 - val_accuracy: 0.9627\n",
      "Epoch 451/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1063 - accuracy: 0.9679 - val_loss: 0.1133 - val_accuracy: 0.9627\n",
      "Epoch 452/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1032 - accuracy: 0.9692 - val_loss: 0.1158 - val_accuracy: 0.9627\n",
      "Epoch 453/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1045 - accuracy: 0.9723 - val_loss: 0.1188 - val_accuracy: 0.9627\n",
      "Epoch 454/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1010 - accuracy: 0.9736 - val_loss: 0.1152 - val_accuracy: 0.9627\n",
      "Epoch 455/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0986 - accuracy: 0.9743 - val_loss: 0.1125 - val_accuracy: 0.9627\n",
      "Epoch 456/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1031 - accuracy: 0.9723 - val_loss: 0.1127 - val_accuracy: 0.9627\n",
      "Epoch 457/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1066 - accuracy: 0.9706 - val_loss: 0.1130 - val_accuracy: 0.9627\n",
      "Epoch 458/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1061 - accuracy: 0.9693 - val_loss: 0.1111 - val_accuracy: 0.9627\n",
      "Epoch 459/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1018 - accuracy: 0.9669 - val_loss: 0.1117 - val_accuracy: 0.9627\n",
      "Epoch 460/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1067 - accuracy: 0.9716 - val_loss: 0.1191 - val_accuracy: 0.9658\n",
      "Epoch 461/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1082 - accuracy: 0.9693 - val_loss: 0.1134 - val_accuracy: 0.9627\n",
      "Epoch 462/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1030 - accuracy: 0.9719 - val_loss: 0.1106 - val_accuracy: 0.9627\n",
      "Epoch 463/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1089 - accuracy: 0.9659 - val_loss: 0.1110 - val_accuracy: 0.9627\n",
      "Epoch 464/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1051 - accuracy: 0.9693 - val_loss: 0.1130 - val_accuracy: 0.9627\n",
      "Epoch 465/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1032 - accuracy: 0.9723 - val_loss: 0.1145 - val_accuracy: 0.9627\n",
      "Epoch 466/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0986 - accuracy: 0.9736 - val_loss: 0.1139 - val_accuracy: 0.9627\n",
      "Epoch 467/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1041 - accuracy: 0.9723 - val_loss: 0.1130 - val_accuracy: 0.9627\n",
      "Epoch 468/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1054 - accuracy: 0.9723 - val_loss: 0.1115 - val_accuracy: 0.9627\n",
      "Epoch 469/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0990 - accuracy: 0.9713 - val_loss: 0.1122 - val_accuracy: 0.9627\n",
      "Epoch 470/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1065 - accuracy: 0.9703 - val_loss: 0.1158 - val_accuracy: 0.9627\n",
      "Epoch 471/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1002 - accuracy: 0.9716 - val_loss: 0.1138 - val_accuracy: 0.9627\n",
      "Epoch 472/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0997 - accuracy: 0.9736 - val_loss: 0.1110 - val_accuracy: 0.9627\n",
      "Epoch 473/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1024 - accuracy: 0.9686 - val_loss: 0.1105 - val_accuracy: 0.9627\n",
      "Epoch 474/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1041 - accuracy: 0.9669 - val_loss: 0.1121 - val_accuracy: 0.9627\n",
      "Epoch 475/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0969 - accuracy: 0.9736 - val_loss: 0.1141 - val_accuracy: 0.9627\n",
      "Epoch 476/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1009 - accuracy: 0.9716 - val_loss: 0.1144 - val_accuracy: 0.9658\n",
      "Epoch 477/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1041 - accuracy: 0.9710 - val_loss: 0.1100 - val_accuracy: 0.9627\n",
      "Epoch 478/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1051 - accuracy: 0.9710 - val_loss: 0.1089 - val_accuracy: 0.9627\n",
      "Epoch 479/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1023 - accuracy: 0.9692 - val_loss: 0.1091 - val_accuracy: 0.9627\n",
      "Epoch 480/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0976 - accuracy: 0.9726 - val_loss: 0.1147 - val_accuracy: 0.9658\n",
      "Epoch 481/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1009 - accuracy: 0.9733 - val_loss: 0.1147 - val_accuracy: 0.9658\n",
      "Epoch 482/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1029 - accuracy: 0.9723 - val_loss: 0.1085 - val_accuracy: 0.9627\n",
      "Epoch 483/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1015 - accuracy: 0.9679 - val_loss: 0.1081 - val_accuracy: 0.9627\n",
      "Epoch 484/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1035 - accuracy: 0.9659 - val_loss: 0.1121 - val_accuracy: 0.9627\n",
      "Epoch 485/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0987 - accuracy: 0.9723 - val_loss: 0.1111 - val_accuracy: 0.9627\n",
      "Epoch 486/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0954 - accuracy: 0.9743 - val_loss: 0.1080 - val_accuracy: 0.9627\n",
      "Epoch 487/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1004 - accuracy: 0.9699 - val_loss: 0.1092 - val_accuracy: 0.9627\n",
      "Epoch 488/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0998 - accuracy: 0.9706 - val_loss: 0.1114 - val_accuracy: 0.9658\n",
      "Epoch 489/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0978 - accuracy: 0.9706 - val_loss: 0.1080 - val_accuracy: 0.9627\n",
      "Epoch 490/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1005 - accuracy: 0.9706 - val_loss: 0.1080 - val_accuracy: 0.9627\n",
      "Epoch 491/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0965 - accuracy: 0.9692 - val_loss: 0.1086 - val_accuracy: 0.9627\n",
      "Epoch 492/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0995 - accuracy: 0.9706 - val_loss: 0.1158 - val_accuracy: 0.9627\n",
      "Epoch 493/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1010 - accuracy: 0.9733 - val_loss: 0.1094 - val_accuracy: 0.9627\n",
      "Epoch 494/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0939 - accuracy: 0.9736 - val_loss: 0.1066 - val_accuracy: 0.9689\n",
      "Epoch 495/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1044 - accuracy: 0.9666 - val_loss: 0.1064 - val_accuracy: 0.9627\n",
      "Epoch 496/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1008 - accuracy: 0.9666 - val_loss: 0.1105 - val_accuracy: 0.9658\n",
      "Epoch 497/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1020 - accuracy: 0.9710 - val_loss: 0.1124 - val_accuracy: 0.9658\n",
      "Epoch 498/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0942 - accuracy: 0.9750 - val_loss: 0.1078 - val_accuracy: 0.9627\n",
      "Epoch 499/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1021 - accuracy: 0.9679 - val_loss: 0.1074 - val_accuracy: 0.9627\n",
      "Epoch 500/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0995 - accuracy: 0.9716 - val_loss: 0.1064 - val_accuracy: 0.9627\n",
      "Epoch 501/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0953 - accuracy: 0.9686 - val_loss: 0.1069 - val_accuracy: 0.9627\n",
      "Epoch 502/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0894 - accuracy: 0.9750 - val_loss: 0.1126 - val_accuracy: 0.9658\n",
      "Epoch 503/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0895 - accuracy: 0.9756 - val_loss: 0.1156 - val_accuracy: 0.9627\n",
      "Epoch 504/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0938 - accuracy: 0.9763 - val_loss: 0.1103 - val_accuracy: 0.9627\n",
      "Epoch 505/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0982 - accuracy: 0.9682 - val_loss: 0.1103 - val_accuracy: 0.9627\n",
      "Epoch 506/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1000 - accuracy: 0.9672 - val_loss: 0.1118 - val_accuracy: 0.9596\n",
      "Epoch 507/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1024 - accuracy: 0.9652 - val_loss: 0.1097 - val_accuracy: 0.9627\n",
      "Epoch 508/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0994 - accuracy: 0.9686 - val_loss: 0.1070 - val_accuracy: 0.9627\n",
      "Epoch 509/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0968 - accuracy: 0.9706 - val_loss: 0.1071 - val_accuracy: 0.9627\n",
      "Epoch 510/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0976 - accuracy: 0.9699 - val_loss: 0.1066 - val_accuracy: 0.9627\n",
      "Epoch 511/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.1071 - val_accuracy: 0.9627\n",
      "Epoch 512/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0983 - accuracy: 0.9706 - val_loss: 0.1081 - val_accuracy: 0.9627\n",
      "Epoch 513/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0925 - accuracy: 0.9726 - val_loss: 0.1095 - val_accuracy: 0.9658\n",
      "Epoch 514/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0927 - accuracy: 0.9730 - val_loss: 0.1118 - val_accuracy: 0.9658\n",
      "Epoch 515/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0945 - accuracy: 0.9723 - val_loss: 0.1082 - val_accuracy: 0.9627\n",
      "Epoch 516/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0935 - accuracy: 0.9713 - val_loss: 0.1066 - val_accuracy: 0.9658\n",
      "Epoch 517/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0977 - accuracy: 0.9679 - val_loss: 0.1088 - val_accuracy: 0.9627\n",
      "Epoch 518/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0960 - accuracy: 0.9713 - val_loss: 0.1120 - val_accuracy: 0.9658\n",
      "Epoch 519/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0900 - accuracy: 0.9750 - val_loss: 0.1075 - val_accuracy: 0.9658\n",
      "Epoch 520/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0950 - accuracy: 0.9706 - val_loss: 0.1057 - val_accuracy: 0.9627\n",
      "Epoch 521/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0938 - accuracy: 0.9699 - val_loss: 0.1076 - val_accuracy: 0.9658\n",
      "Epoch 522/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0961 - accuracy: 0.9710 - val_loss: 0.1110 - val_accuracy: 0.9627\n",
      "Epoch 523/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0972 - accuracy: 0.9746 - val_loss: 0.1072 - val_accuracy: 0.9658\n",
      "Epoch 524/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0895 - accuracy: 0.9713 - val_loss: 0.1050 - val_accuracy: 0.9627\n",
      "Epoch 525/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0939 - accuracy: 0.9730 - val_loss: 0.1055 - val_accuracy: 0.9627\n",
      "Epoch 526/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0911 - accuracy: 0.9730 - val_loss: 0.1084 - val_accuracy: 0.9658\n",
      "Epoch 527/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0906 - accuracy: 0.9730 - val_loss: 0.1069 - val_accuracy: 0.9658\n",
      "Epoch 528/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0951 - accuracy: 0.9706 - val_loss: 0.1056 - val_accuracy: 0.9627\n",
      "Epoch 529/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0912 - accuracy: 0.9706 - val_loss: 0.1073 - val_accuracy: 0.9658\n",
      "Epoch 530/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0931 - accuracy: 0.9710 - val_loss: 0.1063 - val_accuracy: 0.9658\n",
      "Epoch 531/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0908 - accuracy: 0.9706 - val_loss: 0.1040 - val_accuracy: 0.9658\n",
      "Epoch 532/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0931 - accuracy: 0.9716 - val_loss: 0.1045 - val_accuracy: 0.9627\n",
      "Epoch 533/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0925 - accuracy: 0.9699 - val_loss: 0.1060 - val_accuracy: 0.9658\n",
      "Epoch 534/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0953 - accuracy: 0.9743 - val_loss: 0.1056 - val_accuracy: 0.9658\n",
      "Epoch 535/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0872 - accuracy: 0.9726 - val_loss: 0.1041 - val_accuracy: 0.9627\n",
      "Epoch 536/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0944 - accuracy: 0.9693 - val_loss: 0.1060 - val_accuracy: 0.9658\n",
      "Epoch 537/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0928 - accuracy: 0.9784 - val_loss: 0.1054 - val_accuracy: 0.9658\n",
      "Epoch 538/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0894 - accuracy: 0.9740 - val_loss: 0.1034 - val_accuracy: 0.9627\n",
      "Epoch 539/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0955 - accuracy: 0.9699 - val_loss: 0.1037 - val_accuracy: 0.9627\n",
      "Epoch 540/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0901 - accuracy: 0.9719 - val_loss: 0.1067 - val_accuracy: 0.9658\n",
      "Epoch 541/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0930 - accuracy: 0.9774 - val_loss: 0.1124 - val_accuracy: 0.9627\n",
      "Epoch 542/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0943 - accuracy: 0.9743 - val_loss: 0.1036 - val_accuracy: 0.9627\n",
      "Epoch 543/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0913 - accuracy: 0.9723 - val_loss: 0.1031 - val_accuracy: 0.9689\n",
      "Epoch 544/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0916 - accuracy: 0.9672 - val_loss: 0.1041 - val_accuracy: 0.9627\n",
      "Epoch 545/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0908 - accuracy: 0.9726 - val_loss: 0.1119 - val_accuracy: 0.9627\n",
      "Epoch 546/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0895 - accuracy: 0.9763 - val_loss: 0.1056 - val_accuracy: 0.9658\n",
      "Epoch 547/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0936 - accuracy: 0.9686 - val_loss: 0.1026 - val_accuracy: 0.9689\n",
      "Epoch 548/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0920 - accuracy: 0.9686 - val_loss: 0.1024 - val_accuracy: 0.9689\n",
      "Epoch 549/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0897 - accuracy: 0.9706 - val_loss: 0.1107 - val_accuracy: 0.9627\n",
      "Epoch 550/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0928 - accuracy: 0.9757 - val_loss: 0.1118 - val_accuracy: 0.9627\n",
      "Epoch 551/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0909 - accuracy: 0.9723 - val_loss: 0.1021 - val_accuracy: 0.9689\n",
      "Epoch 552/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0925 - accuracy: 0.9689 - val_loss: 0.1026 - val_accuracy: 0.9689\n",
      "Epoch 553/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0914 - accuracy: 0.9702 - val_loss: 0.1053 - val_accuracy: 0.9658\n",
      "Epoch 554/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0898 - accuracy: 0.9750 - val_loss: 0.1093 - val_accuracy: 0.9627\n",
      "Epoch 555/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0923 - accuracy: 0.9750 - val_loss: 0.1030 - val_accuracy: 0.9627\n",
      "Epoch 556/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0923 - accuracy: 0.9710 - val_loss: 0.1017 - val_accuracy: 0.9658\n",
      "Epoch 557/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0881 - accuracy: 0.9719 - val_loss: 0.1046 - val_accuracy: 0.9658\n",
      "Epoch 558/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0876 - accuracy: 0.9750 - val_loss: 0.1089 - val_accuracy: 0.9627\n",
      "Epoch 559/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0902 - accuracy: 0.9777 - val_loss: 0.1028 - val_accuracy: 0.9658\n",
      "Epoch 560/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0865 - accuracy: 0.9730 - val_loss: 0.1015 - val_accuracy: 0.9689\n",
      "Epoch 561/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0896 - accuracy: 0.9706 - val_loss: 0.1031 - val_accuracy: 0.9627\n",
      "Epoch 562/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0869 - accuracy: 0.9706 - val_loss: 0.1082 - val_accuracy: 0.9627\n",
      "Epoch 563/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0899 - accuracy: 0.9737 - val_loss: 0.1055 - val_accuracy: 0.9658\n",
      "Epoch 564/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0886 - accuracy: 0.9746 - val_loss: 0.1025 - val_accuracy: 0.9658\n",
      "Epoch 565/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0920 - accuracy: 0.9703 - val_loss: 0.1019 - val_accuracy: 0.9658\n",
      "Epoch 566/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0873 - accuracy: 0.9706 - val_loss: 0.1028 - val_accuracy: 0.9627\n",
      "Epoch 567/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0890 - accuracy: 0.9726 - val_loss: 0.1061 - val_accuracy: 0.9627\n",
      "Epoch 568/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0900 - accuracy: 0.9770 - val_loss: 0.1058 - val_accuracy: 0.9627\n",
      "Epoch 569/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0881 - accuracy: 0.9774 - val_loss: 0.1023 - val_accuracy: 0.9627\n",
      "Epoch 570/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0854 - accuracy: 0.9743 - val_loss: 0.1017 - val_accuracy: 0.9627\n",
      "Epoch 571/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0905 - accuracy: 0.9716 - val_loss: 0.1035 - val_accuracy: 0.9627\n",
      "Epoch 572/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0845 - accuracy: 0.9763 - val_loss: 0.1061 - val_accuracy: 0.9627\n",
      "Epoch 573/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0838 - accuracy: 0.9774 - val_loss: 0.1070 - val_accuracy: 0.9627\n",
      "Epoch 574/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0909 - accuracy: 0.9754 - val_loss: 0.1024 - val_accuracy: 0.9658\n",
      "Epoch 575/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0852 - accuracy: 0.9750 - val_loss: 0.1000 - val_accuracy: 0.9658\n",
      "Epoch 576/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0866 - accuracy: 0.9699 - val_loss: 0.1030 - val_accuracy: 0.9658\n",
      "Epoch 577/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0850 - accuracy: 0.9733 - val_loss: 0.1090 - val_accuracy: 0.9596\n",
      "Epoch 578/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0924 - accuracy: 0.9730 - val_loss: 0.1005 - val_accuracy: 0.9658\n",
      "Epoch 579/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0811 - accuracy: 0.9743 - val_loss: 0.0998 - val_accuracy: 0.9689\n",
      "Epoch 580/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0919 - accuracy: 0.9669 - val_loss: 0.1026 - val_accuracy: 0.9627\n",
      "Epoch 581/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0832 - accuracy: 0.9757 - val_loss: 0.1086 - val_accuracy: 0.9627\n",
      "Epoch 582/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0884 - accuracy: 0.9750 - val_loss: 0.1052 - val_accuracy: 0.9627\n",
      "Epoch 583/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0886 - accuracy: 0.9754 - val_loss: 0.1003 - val_accuracy: 0.9658\n",
      "Epoch 584/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0807 - accuracy: 0.9712 - val_loss: 0.1002 - val_accuracy: 0.9658\n",
      "Epoch 585/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0800 - accuracy: 0.9746 - val_loss: 0.1171 - val_accuracy: 0.9627\n",
      "Epoch 586/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0909 - accuracy: 0.9770 - val_loss: 0.1140 - val_accuracy: 0.9627\n",
      "Epoch 587/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0920 - accuracy: 0.9726 - val_loss: 0.1004 - val_accuracy: 0.9689\n",
      "Epoch 588/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0899 - accuracy: 0.9675 - val_loss: 0.1008 - val_accuracy: 0.9689\n",
      "Epoch 589/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0923 - accuracy: 0.9666 - val_loss: 0.1074 - val_accuracy: 0.9596\n",
      "Epoch 590/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0884 - accuracy: 0.9737 - val_loss: 0.1158 - val_accuracy: 0.9596\n",
      "Epoch 591/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0926 - accuracy: 0.9737 - val_loss: 0.1000 - val_accuracy: 0.9658\n",
      "Epoch 592/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0827 - accuracy: 0.9753 - val_loss: 0.1017 - val_accuracy: 0.9689\n",
      "Epoch 593/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0945 - accuracy: 0.9642 - val_loss: 0.0999 - val_accuracy: 0.9658\n",
      "Epoch 594/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0822 - accuracy: 0.9736 - val_loss: 0.1091 - val_accuracy: 0.9658\n",
      "Epoch 595/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0853 - accuracy: 0.9757 - val_loss: 0.1099 - val_accuracy: 0.9658\n",
      "Epoch 596/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0860 - accuracy: 0.9757 - val_loss: 0.0993 - val_accuracy: 0.9658\n",
      "Epoch 597/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0804 - accuracy: 0.9739 - val_loss: 0.0989 - val_accuracy: 0.9689\n",
      "Epoch 598/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0826 - accuracy: 0.9713 - val_loss: 0.1052 - val_accuracy: 0.9627\n",
      "Epoch 599/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0816 - accuracy: 0.9753 - val_loss: 0.1099 - val_accuracy: 0.9627\n",
      "Epoch 600/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0838 - accuracy: 0.9763 - val_loss: 0.0990 - val_accuracy: 0.9689\n",
      "Epoch 601/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0871 - accuracy: 0.9720 - val_loss: 0.0988 - val_accuracy: 0.9689\n",
      "Epoch 602/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0832 - accuracy: 0.9696 - val_loss: 0.1006 - val_accuracy: 0.9689\n",
      "Epoch 603/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0784 - accuracy: 0.9790 - val_loss: 0.1170 - val_accuracy: 0.9627\n",
      "Epoch 604/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0889 - accuracy: 0.9757 - val_loss: 0.1045 - val_accuracy: 0.9627\n",
      "Epoch 605/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0831 - accuracy: 0.9757 - val_loss: 0.0981 - val_accuracy: 0.9689\n",
      "Epoch 606/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0773 - accuracy: 0.9736 - val_loss: 0.0986 - val_accuracy: 0.9658\n",
      "Epoch 607/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0816 - accuracy: 0.9767 - val_loss: 0.1036 - val_accuracy: 0.9627\n",
      "Epoch 608/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0823 - accuracy: 0.9740 - val_loss: 0.1025 - val_accuracy: 0.9627\n",
      "Epoch 609/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0807 - accuracy: 0.9746 - val_loss: 0.1001 - val_accuracy: 0.9658\n",
      "Epoch 610/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0812 - accuracy: 0.9767 - val_loss: 0.1002 - val_accuracy: 0.9658\n",
      "Epoch 611/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0776 - accuracy: 0.9787 - val_loss: 0.0999 - val_accuracy: 0.9658\n",
      "Epoch 612/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0794 - accuracy: 0.9774 - val_loss: 0.0998 - val_accuracy: 0.9658\n",
      "Epoch 613/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0832 - accuracy: 0.9760 - val_loss: 0.0991 - val_accuracy: 0.9658\n",
      "Epoch 614/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0751 - accuracy: 0.9787 - val_loss: 0.0998 - val_accuracy: 0.9658\n",
      "Epoch 615/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0800 - accuracy: 0.9767 - val_loss: 0.1028 - val_accuracy: 0.9627\n",
      "Epoch 616/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0786 - accuracy: 0.9763 - val_loss: 0.1031 - val_accuracy: 0.9658\n",
      "Epoch 617/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0798 - accuracy: 0.9757 - val_loss: 0.1012 - val_accuracy: 0.9658\n",
      "Epoch 618/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0787 - accuracy: 0.9774 - val_loss: 0.1022 - val_accuracy: 0.9627\n",
      "Epoch 619/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0851 - accuracy: 0.9743 - val_loss: 0.1021 - val_accuracy: 0.9658\n",
      "Epoch 620/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0807 - accuracy: 0.9757 - val_loss: 0.0979 - val_accuracy: 0.9658\n",
      "Epoch 621/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0782 - accuracy: 0.9760 - val_loss: 0.0995 - val_accuracy: 0.9658\n",
      "Epoch 622/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0822 - accuracy: 0.9754 - val_loss: 0.1068 - val_accuracy: 0.9658\n",
      "Epoch 623/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0820 - accuracy: 0.9746 - val_loss: 0.1012 - val_accuracy: 0.9627\n",
      "Epoch 624/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0743 - accuracy: 0.9770 - val_loss: 0.0995 - val_accuracy: 0.9658\n",
      "Epoch 625/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0783 - accuracy: 0.9780 - val_loss: 0.0999 - val_accuracy: 0.9658\n",
      "Epoch 626/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0755 - accuracy: 0.9777 - val_loss: 0.1006 - val_accuracy: 0.9658\n",
      "Epoch 627/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0797 - accuracy: 0.9750 - val_loss: 0.1018 - val_accuracy: 0.9658\n",
      "Epoch 628/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0768 - accuracy: 0.9750 - val_loss: 0.0995 - val_accuracy: 0.9658\n",
      "Epoch 629/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0799 - accuracy: 0.9760 - val_loss: 0.0977 - val_accuracy: 0.9658\n",
      "Epoch 630/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0750 - accuracy: 0.9780 - val_loss: 0.0984 - val_accuracy: 0.9658\n",
      "Epoch 631/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0757 - accuracy: 0.9787 - val_loss: 0.1026 - val_accuracy: 0.9627\n",
      "Epoch 632/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0821 - accuracy: 0.9720 - val_loss: 0.0985 - val_accuracy: 0.9658\n",
      "Epoch 633/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0754 - accuracy: 0.9797 - val_loss: 0.0967 - val_accuracy: 0.9658\n",
      "Epoch 634/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0777 - accuracy: 0.9750 - val_loss: 0.0996 - val_accuracy: 0.9658\n",
      "Epoch 635/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0726 - accuracy: 0.9787 - val_loss: 0.1070 - val_accuracy: 0.9627\n",
      "Epoch 636/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0807 - accuracy: 0.9723 - val_loss: 0.1031 - val_accuracy: 0.9596\n",
      "Epoch 637/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0805 - accuracy: 0.9743 - val_loss: 0.0968 - val_accuracy: 0.9689\n",
      "Epoch 638/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0809 - accuracy: 0.9696 - val_loss: 0.0983 - val_accuracy: 0.9720\n",
      "Epoch 639/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0837 - accuracy: 0.9686 - val_loss: 0.0976 - val_accuracy: 0.9658\n",
      "Epoch 640/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0744 - accuracy: 0.9774 - val_loss: 0.1199 - val_accuracy: 0.9720\n",
      "Epoch 641/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0881 - accuracy: 0.9736 - val_loss: 0.1029 - val_accuracy: 0.9627\n",
      "Epoch 642/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0803 - accuracy: 0.9726 - val_loss: 0.0987 - val_accuracy: 0.9720\n",
      "Epoch 643/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0903 - accuracy: 0.9659 - val_loss: 0.0984 - val_accuracy: 0.9720\n",
      "Epoch 644/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0847 - accuracy: 0.9672 - val_loss: 0.0996 - val_accuracy: 0.9658\n",
      "Epoch 645/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0778 - accuracy: 0.9750 - val_loss: 0.1155 - val_accuracy: 0.9689\n",
      "Epoch 646/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0857 - accuracy: 0.9733 - val_loss: 0.0991 - val_accuracy: 0.9627\n",
      "Epoch 647/3500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0729 - accuracy: 0.9774 - val_loss: 0.0959 - val_accuracy: 0.9658\n",
      "Epoch 648/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0759 - accuracy: 0.9767 - val_loss: 0.0976 - val_accuracy: 0.9658\n",
      "Epoch 649/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0776 - accuracy: 0.9777 - val_loss: 0.1023 - val_accuracy: 0.9658\n",
      "Epoch 650/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0745 - accuracy: 0.9740 - val_loss: 0.1014 - val_accuracy: 0.9627\n",
      "Epoch 651/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0754 - accuracy: 0.9763 - val_loss: 0.0995 - val_accuracy: 0.9627\n",
      "Epoch 652/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0695 - accuracy: 0.9794 - val_loss: 0.0994 - val_accuracy: 0.9658\n",
      "Epoch 653/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0759 - accuracy: 0.9760 - val_loss: 0.1002 - val_accuracy: 0.9627\n",
      "Epoch 654/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0765 - accuracy: 0.9767 - val_loss: 0.0965 - val_accuracy: 0.9658\n",
      "Epoch 655/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0737 - accuracy: 0.9784 - val_loss: 0.0953 - val_accuracy: 0.9627\n",
      "Epoch 656/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0766 - accuracy: 0.9790 - val_loss: 0.0957 - val_accuracy: 0.9658\n",
      "Epoch 657/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0778 - accuracy: 0.9777 - val_loss: 0.0968 - val_accuracy: 0.9658\n",
      "Epoch 658/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0754 - accuracy: 0.9777 - val_loss: 0.0985 - val_accuracy: 0.9689\n",
      "Epoch 659/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0757 - accuracy: 0.9790 - val_loss: 0.0999 - val_accuracy: 0.9658\n",
      "Epoch 660/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0771 - accuracy: 0.9763 - val_loss: 0.0991 - val_accuracy: 0.9658\n",
      "Epoch 661/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0773 - accuracy: 0.9794 - val_loss: 0.0958 - val_accuracy: 0.9658\n",
      "Epoch 662/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0759 - accuracy: 0.9790 - val_loss: 0.0952 - val_accuracy: 0.9658\n",
      "Epoch 663/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0701 - accuracy: 0.9787 - val_loss: 0.0966 - val_accuracy: 0.9658\n",
      "Epoch 664/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0719 - accuracy: 0.9790 - val_loss: 0.0995 - val_accuracy: 0.9627\n",
      "Epoch 665/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0721 - accuracy: 0.9780 - val_loss: 0.1003 - val_accuracy: 0.9658\n",
      "Epoch 666/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0762 - accuracy: 0.9760 - val_loss: 0.0966 - val_accuracy: 0.9658\n",
      "Epoch 667/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0736 - accuracy: 0.9777 - val_loss: 0.0950 - val_accuracy: 0.9627\n",
      "Epoch 668/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0774 - accuracy: 0.9737 - val_loss: 0.0960 - val_accuracy: 0.9658\n",
      "Epoch 669/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0708 - accuracy: 0.9797 - val_loss: 0.0976 - val_accuracy: 0.9658\n",
      "Epoch 670/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0721 - accuracy: 0.9767 - val_loss: 0.1005 - val_accuracy: 0.9658\n",
      "Epoch 671/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0723 - accuracy: 0.9790 - val_loss: 0.0995 - val_accuracy: 0.9658\n",
      "Epoch 672/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0762 - accuracy: 0.9760 - val_loss: 0.0961 - val_accuracy: 0.9658\n",
      "Epoch 673/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0735 - accuracy: 0.9784 - val_loss: 0.0953 - val_accuracy: 0.9627\n",
      "Epoch 674/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0722 - accuracy: 0.9780 - val_loss: 0.0968 - val_accuracy: 0.9658\n",
      "Epoch 675/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0714 - accuracy: 0.9780 - val_loss: 0.0960 - val_accuracy: 0.9658\n",
      "Epoch 676/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0694 - accuracy: 0.9797 - val_loss: 0.0973 - val_accuracy: 0.9658\n",
      "Epoch 677/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0719 - accuracy: 0.9780 - val_loss: 0.0995 - val_accuracy: 0.9658\n",
      "Epoch 678/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0726 - accuracy: 0.9767 - val_loss: 0.0956 - val_accuracy: 0.9658\n",
      "Epoch 679/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0725 - accuracy: 0.9770 - val_loss: 0.0940 - val_accuracy: 0.9658\n",
      "Epoch 680/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0702 - accuracy: 0.9787 - val_loss: 0.0952 - val_accuracy: 0.9627\n",
      "Epoch 681/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0733 - accuracy: 0.9784 - val_loss: 0.0959 - val_accuracy: 0.9627\n",
      "Epoch 682/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0725 - accuracy: 0.9777 - val_loss: 0.0947 - val_accuracy: 0.9658\n",
      "Epoch 683/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0683 - accuracy: 0.9804 - val_loss: 0.1005 - val_accuracy: 0.9720\n",
      "Epoch 684/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0739 - accuracy: 0.9733 - val_loss: 0.1043 - val_accuracy: 0.9720\n",
      "Epoch 685/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0762 - accuracy: 0.9743 - val_loss: 0.0933 - val_accuracy: 0.9658\n",
      "Epoch 686/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0724 - accuracy: 0.9777 - val_loss: 0.0947 - val_accuracy: 0.9720\n",
      "Epoch 687/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0719 - accuracy: 0.9739 - val_loss: 0.0941 - val_accuracy: 0.9689\n",
      "Epoch 688/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0746 - accuracy: 0.9770 - val_loss: 0.1120 - val_accuracy: 0.9689\n",
      "Epoch 689/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0756 - accuracy: 0.9713 - val_loss: 0.0951 - val_accuracy: 0.9658\n",
      "Epoch 690/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0715 - accuracy: 0.9760 - val_loss: 0.0950 - val_accuracy: 0.9720\n",
      "Epoch 691/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0739 - accuracy: 0.9716 - val_loss: 0.0934 - val_accuracy: 0.9658\n",
      "Epoch 692/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0712 - accuracy: 0.9757 - val_loss: 0.1100 - val_accuracy: 0.9720\n",
      "Epoch 693/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0800 - accuracy: 0.9726 - val_loss: 0.0970 - val_accuracy: 0.9689\n",
      "Epoch 694/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0705 - accuracy: 0.9760 - val_loss: 0.0948 - val_accuracy: 0.9720\n",
      "Epoch 695/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0741 - accuracy: 0.9702 - val_loss: 0.0936 - val_accuracy: 0.9720\n",
      "Epoch 696/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0736 - accuracy: 0.9730 - val_loss: 0.1015 - val_accuracy: 0.9689\n",
      "Epoch 697/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0762 - accuracy: 0.9730 - val_loss: 0.1035 - val_accuracy: 0.9689\n",
      "Epoch 698/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0739 - accuracy: 0.9743 - val_loss: 0.0926 - val_accuracy: 0.9720\n",
      "Epoch 699/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0700 - accuracy: 0.9753 - val_loss: 0.0925 - val_accuracy: 0.9720\n",
      "Epoch 700/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0686 - accuracy: 0.9757 - val_loss: 0.1035 - val_accuracy: 0.9720\n",
      "Epoch 701/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0736 - accuracy: 0.9750 - val_loss: 0.1028 - val_accuracy: 0.9689\n",
      "Epoch 702/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0744 - accuracy: 0.9757 - val_loss: 0.0943 - val_accuracy: 0.9658\n",
      "Epoch 703/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0654 - accuracy: 0.9804 - val_loss: 0.0941 - val_accuracy: 0.9627\n",
      "Epoch 704/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0717 - accuracy: 0.9754 - val_loss: 0.0938 - val_accuracy: 0.9689\n",
      "Epoch 705/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0677 - accuracy: 0.9767 - val_loss: 0.0946 - val_accuracy: 0.9658\n",
      "Epoch 706/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0679 - accuracy: 0.9767 - val_loss: 0.0972 - val_accuracy: 0.9689\n",
      "Epoch 707/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0658 - accuracy: 0.9787 - val_loss: 0.0983 - val_accuracy: 0.9658\n",
      "Epoch 708/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0667 - accuracy: 0.9774 - val_loss: 0.0969 - val_accuracy: 0.9689\n",
      "Epoch 709/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0701 - accuracy: 0.9754 - val_loss: 0.0941 - val_accuracy: 0.9627\n",
      "Epoch 710/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0684 - accuracy: 0.9750 - val_loss: 0.0950 - val_accuracy: 0.9627\n",
      "Epoch 711/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0704 - accuracy: 0.9730 - val_loss: 0.0983 - val_accuracy: 0.9627\n",
      "Epoch 712/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0731 - accuracy: 0.9743 - val_loss: 0.0974 - val_accuracy: 0.9627\n",
      "Epoch 713/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0698 - accuracy: 0.9774 - val_loss: 0.0975 - val_accuracy: 0.9689\n",
      "Epoch 714/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0684 - accuracy: 0.9757 - val_loss: 0.0966 - val_accuracy: 0.9689\n",
      "Epoch 715/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0690 - accuracy: 0.9760 - val_loss: 0.0938 - val_accuracy: 0.9689\n",
      "Epoch 716/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0685 - accuracy: 0.9777 - val_loss: 0.0944 - val_accuracy: 0.9689\n",
      "Epoch 717/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0681 - accuracy: 0.9767 - val_loss: 0.0964 - val_accuracy: 0.9689\n",
      "Epoch 718/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0696 - accuracy: 0.9750 - val_loss: 0.0957 - val_accuracy: 0.9689\n",
      "Epoch 719/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0639 - accuracy: 0.9787 - val_loss: 0.0941 - val_accuracy: 0.9689\n",
      "Epoch 720/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0613 - accuracy: 0.9810 - val_loss: 0.0971 - val_accuracy: 0.9658\n",
      "Epoch 721/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0695 - accuracy: 0.9760 - val_loss: 0.0988 - val_accuracy: 0.9720\n",
      "Epoch 722/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0655 - accuracy: 0.9770 - val_loss: 0.0968 - val_accuracy: 0.9689\n",
      "Epoch 723/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0674 - accuracy: 0.9757 - val_loss: 0.0965 - val_accuracy: 0.9689\n",
      "Epoch 724/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0654 - accuracy: 0.9757 - val_loss: 0.0943 - val_accuracy: 0.9689\n",
      "Epoch 725/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0657 - accuracy: 0.9767 - val_loss: 0.0938 - val_accuracy: 0.9658\n",
      "Epoch 726/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0658 - accuracy: 0.9797 - val_loss: 0.0937 - val_accuracy: 0.9658\n",
      "Epoch 727/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0609 - accuracy: 0.9817 - val_loss: 0.0963 - val_accuracy: 0.9689\n",
      "Epoch 728/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0711 - accuracy: 0.9760 - val_loss: 0.0963 - val_accuracy: 0.9689\n",
      "Epoch 729/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.0927 - val_accuracy: 0.9658\n",
      "Epoch 730/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0697 - accuracy: 0.9743 - val_loss: 0.0926 - val_accuracy: 0.9658\n",
      "Epoch 731/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0717 - accuracy: 0.9730 - val_loss: 0.0933 - val_accuracy: 0.9689\n",
      "Epoch 732/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0675 - accuracy: 0.9760 - val_loss: 0.0958 - val_accuracy: 0.9720\n",
      "Epoch 733/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0636 - accuracy: 0.9763 - val_loss: 0.0975 - val_accuracy: 0.9720\n",
      "Epoch 734/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0624 - accuracy: 0.9777 - val_loss: 0.0942 - val_accuracy: 0.9720\n",
      "Epoch 735/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0655 - accuracy: 0.9780 - val_loss: 0.0923 - val_accuracy: 0.9689\n",
      "Epoch 736/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0686 - accuracy: 0.9770 - val_loss: 0.0927 - val_accuracy: 0.9689\n",
      "Epoch 737/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0653 - accuracy: 0.9774 - val_loss: 0.0930 - val_accuracy: 0.9720\n",
      "Epoch 738/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0634 - accuracy: 0.9790 - val_loss: 0.0927 - val_accuracy: 0.9720\n",
      "Epoch 739/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0642 - accuracy: 0.9797 - val_loss: 0.0955 - val_accuracy: 0.9752\n",
      "Epoch 740/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0618 - accuracy: 0.9770 - val_loss: 0.0973 - val_accuracy: 0.9720\n",
      "Epoch 741/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0663 - accuracy: 0.9757 - val_loss: 0.0933 - val_accuracy: 0.9720\n",
      "Epoch 742/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0667 - accuracy: 0.9767 - val_loss: 0.0916 - val_accuracy: 0.9720\n",
      "Epoch 743/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0668 - accuracy: 0.9790 - val_loss: 0.0922 - val_accuracy: 0.9689\n",
      "Epoch 744/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0638 - accuracy: 0.9797 - val_loss: 0.0941 - val_accuracy: 0.9689\n",
      "Epoch 745/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0646 - accuracy: 0.9774 - val_loss: 0.0965 - val_accuracy: 0.9689\n",
      "Epoch 746/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0657 - accuracy: 0.9757 - val_loss: 0.0992 - val_accuracy: 0.9689\n",
      "Epoch 747/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0667 - accuracy: 0.9757 - val_loss: 0.0943 - val_accuracy: 0.9689\n",
      "Epoch 748/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0653 - accuracy: 0.9760 - val_loss: 0.0939 - val_accuracy: 0.9689\n",
      "Epoch 749/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0650 - accuracy: 0.9740 - val_loss: 0.0967 - val_accuracy: 0.9720\n",
      "Epoch 750/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0656 - accuracy: 0.9750 - val_loss: 0.0955 - val_accuracy: 0.9720\n",
      "Epoch 751/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0646 - accuracy: 0.9760 - val_loss: 0.0930 - val_accuracy: 0.9689\n",
      "Epoch 752/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0631 - accuracy: 0.9767 - val_loss: 0.0932 - val_accuracy: 0.9720\n",
      "Epoch 753/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0619 - accuracy: 0.9790 - val_loss: 0.1008 - val_accuracy: 0.9720\n",
      "Epoch 754/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0672 - accuracy: 0.9770 - val_loss: 0.0975 - val_accuracy: 0.9720\n",
      "Epoch 755/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0654 - accuracy: 0.9753 - val_loss: 0.0915 - val_accuracy: 0.9658\n",
      "Epoch 756/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0662 - accuracy: 0.9790 - val_loss: 0.0927 - val_accuracy: 0.9689\n",
      "Epoch 757/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0651 - accuracy: 0.9801 - val_loss: 0.0974 - val_accuracy: 0.9720\n",
      "Epoch 758/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0652 - accuracy: 0.9774 - val_loss: 0.0932 - val_accuracy: 0.9720\n",
      "Epoch 759/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 0.0916 - val_accuracy: 0.9720\n",
      "Epoch 760/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0625 - accuracy: 0.9780 - val_loss: 0.0919 - val_accuracy: 0.9720\n",
      "Epoch 761/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0583 - accuracy: 0.9787 - val_loss: 0.0954 - val_accuracy: 0.9720\n",
      "Epoch 762/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0621 - accuracy: 0.9774 - val_loss: 0.0950 - val_accuracy: 0.9689\n",
      "Epoch 763/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0617 - accuracy: 0.9797 - val_loss: 0.0930 - val_accuracy: 0.9720\n",
      "Epoch 764/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0581 - accuracy: 0.9780 - val_loss: 0.0968 - val_accuracy: 0.9720\n",
      "Epoch 765/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0621 - accuracy: 0.9763 - val_loss: 0.0982 - val_accuracy: 0.9752\n",
      "Epoch 766/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0655 - accuracy: 0.9737 - val_loss: 0.0917 - val_accuracy: 0.9720\n",
      "Epoch 767/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0656 - accuracy: 0.9801 - val_loss: 0.0921 - val_accuracy: 0.9689\n",
      "Epoch 768/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0687 - accuracy: 0.9767 - val_loss: 0.0923 - val_accuracy: 0.9720\n",
      "Epoch 769/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0606 - accuracy: 0.9797 - val_loss: 0.0994 - val_accuracy: 0.9752\n",
      "Epoch 770/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0606 - accuracy: 0.9760 - val_loss: 0.1000 - val_accuracy: 0.9752\n",
      "Epoch 771/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0632 - accuracy: 0.9740 - val_loss: 0.0925 - val_accuracy: 0.9658\n",
      "Epoch 772/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0629 - accuracy: 0.9774 - val_loss: 0.0933 - val_accuracy: 0.9720\n",
      "Epoch 773/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0661 - accuracy: 0.9746 - val_loss: 0.0949 - val_accuracy: 0.9689\n",
      "Epoch 774/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0651 - accuracy: 0.9767 - val_loss: 0.1040 - val_accuracy: 0.9689\n",
      "Epoch 775/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0638 - accuracy: 0.9780 - val_loss: 0.0922 - val_accuracy: 0.9658\n",
      "Epoch 776/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0629 - accuracy: 0.9746 - val_loss: 0.0950 - val_accuracy: 0.9658\n",
      "Epoch 777/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0739 - accuracy: 0.9710 - val_loss: 0.0929 - val_accuracy: 0.9720\n",
      "Epoch 778/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0602 - accuracy: 0.9787 - val_loss: 0.0978 - val_accuracy: 0.9783\n",
      "Epoch 779/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0691 - accuracy: 0.9767 - val_loss: 0.0950 - val_accuracy: 0.9783\n",
      "Epoch 780/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0621 - accuracy: 0.9801 - val_loss: 0.0911 - val_accuracy: 0.9658\n",
      "Epoch 781/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0641 - accuracy: 0.9774 - val_loss: 0.0910 - val_accuracy: 0.9689\n",
      "Epoch 782/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0637 - accuracy: 0.9787 - val_loss: 0.0968 - val_accuracy: 0.9720\n",
      "Epoch 783/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0653 - accuracy: 0.9777 - val_loss: 0.0996 - val_accuracy: 0.9689\n",
      "Epoch 784/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0669 - accuracy: 0.9754 - val_loss: 0.0919 - val_accuracy: 0.9689\n",
      "Epoch 785/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0624 - accuracy: 0.9814 - val_loss: 0.0917 - val_accuracy: 0.9720\n",
      "Epoch 786/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0575 - accuracy: 0.9797 - val_loss: 0.1012 - val_accuracy: 0.9752\n",
      "Epoch 787/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0683 - accuracy: 0.9730 - val_loss: 0.0969 - val_accuracy: 0.9720\n",
      "Epoch 788/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0611 - accuracy: 0.9784 - val_loss: 0.0912 - val_accuracy: 0.9689\n",
      "Epoch 789/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0621 - accuracy: 0.9784 - val_loss: 0.0921 - val_accuracy: 0.9689\n",
      "Epoch 790/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0627 - accuracy: 0.9760 - val_loss: 0.0920 - val_accuracy: 0.9720\n",
      "Epoch 791/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0595 - accuracy: 0.9784 - val_loss: 0.1014 - val_accuracy: 0.9814\n",
      "Epoch 792/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0661 - accuracy: 0.9726 - val_loss: 0.0908 - val_accuracy: 0.9720\n",
      "Epoch 793/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0618 - accuracy: 0.9787 - val_loss: 0.0941 - val_accuracy: 0.9720\n",
      "Epoch 794/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0695 - accuracy: 0.9757 - val_loss: 0.0922 - val_accuracy: 0.9689\n",
      "Epoch 795/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0677 - accuracy: 0.9743 - val_loss: 0.0955 - val_accuracy: 0.9720\n",
      "Epoch 796/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0606 - accuracy: 0.9767 - val_loss: 0.0954 - val_accuracy: 0.9720\n",
      "Epoch 797/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0600 - accuracy: 0.9784 - val_loss: 0.0911 - val_accuracy: 0.9720\n",
      "Epoch 798/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0629 - accuracy: 0.9787 - val_loss: 0.0909 - val_accuracy: 0.9689\n",
      "Epoch 799/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0594 - accuracy: 0.9814 - val_loss: 0.0912 - val_accuracy: 0.9720\n",
      "Epoch 800/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0581 - accuracy: 0.9790 - val_loss: 0.0959 - val_accuracy: 0.9783\n",
      "Epoch 801/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0632 - accuracy: 0.9754 - val_loss: 0.0987 - val_accuracy: 0.9814\n",
      "Epoch 802/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0632 - accuracy: 0.9767 - val_loss: 0.0919 - val_accuracy: 0.9720\n",
      "Epoch 803/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0578 - accuracy: 0.9790 - val_loss: 0.0916 - val_accuracy: 0.9720\n",
      "Epoch 804/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0614 - accuracy: 0.9794 - val_loss: 0.0939 - val_accuracy: 0.9689\n",
      "Epoch 805/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0580 - accuracy: 0.9807 - val_loss: 0.0939 - val_accuracy: 0.9689\n",
      "Epoch 806/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0609 - accuracy: 0.9770 - val_loss: 0.0911 - val_accuracy: 0.9720\n",
      "Epoch 807/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0576 - accuracy: 0.9797 - val_loss: 0.0911 - val_accuracy: 0.9720\n",
      "Epoch 808/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0624 - accuracy: 0.9794 - val_loss: 0.0964 - val_accuracy: 0.9752\n",
      "Epoch 809/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0586 - accuracy: 0.9780 - val_loss: 0.0932 - val_accuracy: 0.9689\n",
      "Epoch 810/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0566 - accuracy: 0.9807 - val_loss: 0.0908 - val_accuracy: 0.9720\n",
      "Epoch 811/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0613 - accuracy: 0.9787 - val_loss: 0.0910 - val_accuracy: 0.9658\n",
      "Epoch 812/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0598 - accuracy: 0.9767 - val_loss: 0.0911 - val_accuracy: 0.9689\n",
      "Epoch 813/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0591 - accuracy: 0.9787 - val_loss: 0.0935 - val_accuracy: 0.9752\n",
      "Epoch 814/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0525 - accuracy: 0.9804 - val_loss: 0.0948 - val_accuracy: 0.9752\n",
      "Epoch 815/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0591 - accuracy: 0.9790 - val_loss: 0.0952 - val_accuracy: 0.9752\n",
      "Epoch 816/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0608 - accuracy: 0.9777 - val_loss: 0.0935 - val_accuracy: 0.9720\n",
      "Epoch 817/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0622 - accuracy: 0.9794 - val_loss: 0.0914 - val_accuracy: 0.9720\n",
      "Epoch 818/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0612 - accuracy: 0.9777 - val_loss: 0.0913 - val_accuracy: 0.9720\n",
      "Epoch 819/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0566 - accuracy: 0.9801 - val_loss: 0.0935 - val_accuracy: 0.9720\n",
      "Epoch 820/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0579 - accuracy: 0.9784 - val_loss: 0.0933 - val_accuracy: 0.9689\n",
      "Epoch 821/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0546 - accuracy: 0.9801 - val_loss: 0.0916 - val_accuracy: 0.9689\n",
      "Epoch 822/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0555 - accuracy: 0.9814 - val_loss: 0.0919 - val_accuracy: 0.9689\n",
      "Epoch 823/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0595 - accuracy: 0.9794 - val_loss: 0.0963 - val_accuracy: 0.9720\n",
      "Epoch 824/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0609 - accuracy: 0.9770 - val_loss: 0.0944 - val_accuracy: 0.9689\n",
      "Epoch 825/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0584 - accuracy: 0.9784 - val_loss: 0.0920 - val_accuracy: 0.9689\n",
      "Epoch 826/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0571 - accuracy: 0.9774 - val_loss: 0.0919 - val_accuracy: 0.9720\n",
      "Epoch 827/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0597 - accuracy: 0.9770 - val_loss: 0.0954 - val_accuracy: 0.9752\n",
      "Epoch 828/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0588 - accuracy: 0.9767 - val_loss: 0.0977 - val_accuracy: 0.9783\n",
      "Epoch 829/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0607 - accuracy: 0.9760 - val_loss: 0.0929 - val_accuracy: 0.9720\n",
      "Epoch 830/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0565 - accuracy: 0.9807 - val_loss: 0.0920 - val_accuracy: 0.9720\n",
      "Epoch 831/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0536 - accuracy: 0.9831 - val_loss: 0.0942 - val_accuracy: 0.9689\n",
      "Epoch 832/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0568 - accuracy: 0.9814 - val_loss: 0.0952 - val_accuracy: 0.9689\n",
      "Epoch 833/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0616 - accuracy: 0.9781 - val_loss: 0.0919 - val_accuracy: 0.9720\n",
      "Epoch 834/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0547 - accuracy: 0.9801 - val_loss: 0.0913 - val_accuracy: 0.9720\n",
      "Epoch 835/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0522 - accuracy: 0.9804 - val_loss: 0.0953 - val_accuracy: 0.9814\n",
      "Epoch 836/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0585 - accuracy: 0.9774 - val_loss: 0.0943 - val_accuracy: 0.9752\n",
      "Epoch 837/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0620 - accuracy: 0.9760 - val_loss: 0.0916 - val_accuracy: 0.9720\n",
      "Epoch 838/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0596 - accuracy: 0.9817 - val_loss: 0.0910 - val_accuracy: 0.9720\n",
      "Epoch 839/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0986 - val_accuracy: 0.9814\n",
      "Epoch 840/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0583 - accuracy: 0.9784 - val_loss: 0.0985 - val_accuracy: 0.9783\n",
      "Epoch 841/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0590 - accuracy: 0.9801 - val_loss: 0.0921 - val_accuracy: 0.9658\n",
      "Epoch 842/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0599 - accuracy: 0.9754 - val_loss: 0.0929 - val_accuracy: 0.9658\n",
      "Epoch 843/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0626 - accuracy: 0.9767 - val_loss: 0.0916 - val_accuracy: 0.9689\n",
      "Epoch 844/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0552 - accuracy: 0.9814 - val_loss: 0.0996 - val_accuracy: 0.9814\n",
      "Epoch 845/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0577 - accuracy: 0.9767 - val_loss: 0.0913 - val_accuracy: 0.9720\n",
      "Epoch 846/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0556 - accuracy: 0.9804 - val_loss: 0.0913 - val_accuracy: 0.9720\n",
      "Epoch 847/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0566 - accuracy: 0.9831 - val_loss: 0.0955 - val_accuracy: 0.9783\n",
      "Epoch 848/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0586 - accuracy: 0.9767 - val_loss: 0.0976 - val_accuracy: 0.9783\n",
      "Epoch 849/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0588 - accuracy: 0.9780 - val_loss: 0.0950 - val_accuracy: 0.9689\n",
      "Epoch 850/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0592 - accuracy: 0.9770 - val_loss: 0.0927 - val_accuracy: 0.9689\n",
      "Epoch 851/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0527 - accuracy: 0.9797 - val_loss: 0.0918 - val_accuracy: 0.9689\n",
      "Epoch 852/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0528 - accuracy: 0.9824 - val_loss: 0.0945 - val_accuracy: 0.9752\n",
      "Epoch 853/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0547 - accuracy: 0.9801 - val_loss: 0.0987 - val_accuracy: 0.9814\n",
      "Epoch 854/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0571 - accuracy: 0.9790 - val_loss: 0.0914 - val_accuracy: 0.9720\n",
      "Epoch 855/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0586 - accuracy: 0.9784 - val_loss: 0.0907 - val_accuracy: 0.9720\n",
      "Epoch 856/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0595 - accuracy: 0.9804 - val_loss: 0.0957 - val_accuracy: 0.9814\n",
      "Epoch 857/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0567 - accuracy: 0.9780 - val_loss: 0.0938 - val_accuracy: 0.9814\n",
      "Epoch 858/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0584 - accuracy: 0.9760 - val_loss: 0.0894 - val_accuracy: 0.9720\n",
      "Epoch 859/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0541 - accuracy: 0.9831 - val_loss: 0.0898 - val_accuracy: 0.9720\n",
      "Epoch 860/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0570 - accuracy: 0.9794 - val_loss: 0.0992 - val_accuracy: 0.9783\n",
      "Epoch 861/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0548 - accuracy: 0.9774 - val_loss: 0.0907 - val_accuracy: 0.9720\n",
      "Epoch 862/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0560 - accuracy: 0.9801 - val_loss: 0.0921 - val_accuracy: 0.9689\n",
      "Epoch 863/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0567 - accuracy: 0.9780 - val_loss: 0.0913 - val_accuracy: 0.9720\n",
      "Epoch 864/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0567 - accuracy: 0.9787 - val_loss: 0.1043 - val_accuracy: 0.9783\n",
      "Epoch 865/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0638 - accuracy: 0.9794 - val_loss: 0.0952 - val_accuracy: 0.9783\n",
      "Epoch 866/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0537 - accuracy: 0.9794 - val_loss: 0.0934 - val_accuracy: 0.9689\n",
      "Epoch 867/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0618 - accuracy: 0.9746 - val_loss: 0.0925 - val_accuracy: 0.9689\n",
      "Epoch 868/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0586 - accuracy: 0.9794 - val_loss: 0.1050 - val_accuracy: 0.9783\n",
      "Epoch 869/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0607 - accuracy: 0.9817 - val_loss: 0.1034 - val_accuracy: 0.9783\n",
      "Epoch 870/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0591 - accuracy: 0.9790 - val_loss: 0.0910 - val_accuracy: 0.9689\n",
      "Epoch 871/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0554 - accuracy: 0.9807 - val_loss: 0.0909 - val_accuracy: 0.9720\n",
      "Epoch 872/3500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0619 - accuracy: 0.9770 - val_loss: 0.0927 - val_accuracy: 0.9783\n",
      "Epoch 873/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0555 - accuracy: 0.9760 - val_loss: 0.0929 - val_accuracy: 0.9783\n",
      "Epoch 874/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0562 - accuracy: 0.9760 - val_loss: 0.0908 - val_accuracy: 0.9720\n",
      "Epoch 875/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0534 - accuracy: 0.9807 - val_loss: 0.0899 - val_accuracy: 0.9720\n",
      "Epoch 876/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0582 - accuracy: 0.9804 - val_loss: 0.0902 - val_accuracy: 0.9720\n",
      "Epoch 877/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0577 - accuracy: 0.9784 - val_loss: 0.0906 - val_accuracy: 0.9689\n",
      "Epoch 878/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0537 - accuracy: 0.9824 - val_loss: 0.0932 - val_accuracy: 0.9720\n",
      "Epoch 879/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0559 - accuracy: 0.9787 - val_loss: 0.0981 - val_accuracy: 0.9752\n",
      "Epoch 880/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0569 - accuracy: 0.9790 - val_loss: 0.0905 - val_accuracy: 0.9720\n",
      "Epoch 881/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0565 - accuracy: 0.9804 - val_loss: 0.0923 - val_accuracy: 0.9720\n",
      "Epoch 882/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0559 - accuracy: 0.9824 - val_loss: 0.0925 - val_accuracy: 0.9689\n",
      "Epoch 883/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 0.9801 - val_loss: 0.1103 - val_accuracy: 0.9752\n",
      "Epoch 884/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0640 - accuracy: 0.9807 - val_loss: 0.0912 - val_accuracy: 0.9689\n",
      "Epoch 885/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0550 - accuracy: 0.9817 - val_loss: 0.0960 - val_accuracy: 0.9720\n",
      "Epoch 886/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0658 - accuracy: 0.9760 - val_loss: 0.0915 - val_accuracy: 0.9720\n",
      "Epoch 887/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0534 - accuracy: 0.9817 - val_loss: 0.1084 - val_accuracy: 0.9752\n",
      "Epoch 888/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0644 - accuracy: 0.9794 - val_loss: 0.0970 - val_accuracy: 0.9783\n",
      "Epoch 889/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0539 - accuracy: 0.9794 - val_loss: 0.0924 - val_accuracy: 0.9689\n",
      "Epoch 890/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0596 - accuracy: 0.9801 - val_loss: 0.0922 - val_accuracy: 0.9689\n",
      "Epoch 891/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0585 - accuracy: 0.9794 - val_loss: 0.0922 - val_accuracy: 0.9783\n",
      "Epoch 892/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0521 - accuracy: 0.9797 - val_loss: 0.0979 - val_accuracy: 0.9814\n",
      "Epoch 893/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0555 - accuracy: 0.9763 - val_loss: 0.0935 - val_accuracy: 0.9752\n",
      "Epoch 894/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0515 - accuracy: 0.9787 - val_loss: 0.0922 - val_accuracy: 0.9720\n",
      "Epoch 895/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0528 - accuracy: 0.9801 - val_loss: 0.0920 - val_accuracy: 0.9689\n",
      "Epoch 896/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0531 - accuracy: 0.9817 - val_loss: 0.0918 - val_accuracy: 0.9689\n",
      "Epoch 897/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0531 - accuracy: 0.9824 - val_loss: 0.0918 - val_accuracy: 0.9689\n",
      "Epoch 898/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0549 - accuracy: 0.9811 - val_loss: 0.0921 - val_accuracy: 0.9720\n",
      "Epoch 899/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0536 - accuracy: 0.9814 - val_loss: 0.0923 - val_accuracy: 0.9720\n",
      "Epoch 900/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0516 - accuracy: 0.9807 - val_loss: 0.0977 - val_accuracy: 0.9752\n",
      "Epoch 901/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0524 - accuracy: 0.9774 - val_loss: 0.0964 - val_accuracy: 0.9752\n",
      "Epoch 902/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0535 - accuracy: 0.9747 - val_loss: 0.0931 - val_accuracy: 0.9689\n",
      "Epoch 903/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0582 - accuracy: 0.9787 - val_loss: 0.0939 - val_accuracy: 0.9689\n",
      "Epoch 904/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0549 - accuracy: 0.9824 - val_loss: 0.0923 - val_accuracy: 0.9720\n",
      "Epoch 905/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0502 - accuracy: 0.9801 - val_loss: 0.0970 - val_accuracy: 0.9814\n",
      "Epoch 906/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0539 - accuracy: 0.9784 - val_loss: 0.0943 - val_accuracy: 0.9783\n",
      "Epoch 907/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0498 - accuracy: 0.9797 - val_loss: 0.0913 - val_accuracy: 0.9720\n",
      "Epoch 908/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0500 - accuracy: 0.9824 - val_loss: 0.0921 - val_accuracy: 0.9720\n",
      "Epoch 909/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0514 - accuracy: 0.9801 - val_loss: 0.0928 - val_accuracy: 0.9752\n",
      "Epoch 910/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0529 - accuracy: 0.9787 - val_loss: 0.0918 - val_accuracy: 0.9720\n",
      "Epoch 911/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0530 - accuracy: 0.9804 - val_loss: 0.0921 - val_accuracy: 0.9720\n",
      "Epoch 912/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0487 - accuracy: 0.9824 - val_loss: 0.0939 - val_accuracy: 0.9752\n",
      "Epoch 913/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0498 - accuracy: 0.9807 - val_loss: 0.0979 - val_accuracy: 0.9752\n",
      "Epoch 914/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0544 - accuracy: 0.9770 - val_loss: 0.0942 - val_accuracy: 0.9720\n",
      "Epoch 915/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0511 - accuracy: 0.9814 - val_loss: 0.0928 - val_accuracy: 0.9720\n",
      "Epoch 916/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0509 - accuracy: 0.9807 - val_loss: 0.0965 - val_accuracy: 0.9752\n",
      "Epoch 917/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0497 - accuracy: 0.9794 - val_loss: 0.1000 - val_accuracy: 0.9783\n",
      "Epoch 918/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0525 - accuracy: 0.9790 - val_loss: 0.0921 - val_accuracy: 0.9720\n",
      "Epoch 919/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0515 - accuracy: 0.9824 - val_loss: 0.0923 - val_accuracy: 0.9720\n",
      "Epoch 920/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0554 - accuracy: 0.9811 - val_loss: 0.0911 - val_accuracy: 0.9720\n",
      "Epoch 921/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0531 - accuracy: 0.9801 - val_loss: 0.0918 - val_accuracy: 0.9783\n",
      "Epoch 922/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0511 - accuracy: 0.9794 - val_loss: 0.0901 - val_accuracy: 0.9720\n",
      "Epoch 923/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0505 - accuracy: 0.9811 - val_loss: 0.0901 - val_accuracy: 0.9720\n",
      "Epoch 924/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0531 - accuracy: 0.9804 - val_loss: 0.0916 - val_accuracy: 0.9752\n",
      "Epoch 925/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0520 - accuracy: 0.9817 - val_loss: 0.0922 - val_accuracy: 0.9720\n",
      "Epoch 926/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0517 - accuracy: 0.9794 - val_loss: 0.0933 - val_accuracy: 0.9752\n",
      "Epoch 927/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0488 - accuracy: 0.9790 - val_loss: 0.0909 - val_accuracy: 0.9689\n",
      "Epoch 928/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0518 - accuracy: 0.9834 - val_loss: 0.0911 - val_accuracy: 0.9752\n",
      "Epoch 929/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0531 - accuracy: 0.9845 - val_loss: 0.0963 - val_accuracy: 0.9783\n",
      "Epoch 930/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0538 - accuracy: 0.9770 - val_loss: 0.0996 - val_accuracy: 0.9783\n",
      "Epoch 931/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0539 - accuracy: 0.9754 - val_loss: 0.0925 - val_accuracy: 0.9720\n",
      "Epoch 932/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0522 - accuracy: 0.9828 - val_loss: 0.0929 - val_accuracy: 0.9752\n",
      "Epoch 933/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0537 - accuracy: 0.9807 - val_loss: 0.0938 - val_accuracy: 0.9752\n",
      "Epoch 934/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0514 - accuracy: 0.9784 - val_loss: 0.0968 - val_accuracy: 0.9752\n",
      "Epoch 935/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0539 - accuracy: 0.9764 - val_loss: 0.0925 - val_accuracy: 0.9720\n",
      "Epoch 936/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0512 - accuracy: 0.9824 - val_loss: 0.0925 - val_accuracy: 0.9720\n",
      "Epoch 937/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0536 - accuracy: 0.9814 - val_loss: 0.0964 - val_accuracy: 0.9752\n",
      "Epoch 938/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0490 - accuracy: 0.9797 - val_loss: 0.0945 - val_accuracy: 0.9752\n",
      "Epoch 939/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0469 - accuracy: 0.9814 - val_loss: 0.0927 - val_accuracy: 0.9752\n",
      "Epoch 940/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0513 - accuracy: 0.9845 - val_loss: 0.0931 - val_accuracy: 0.9783\n",
      "Epoch 941/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0505 - accuracy: 0.9811 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 942/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0500 - accuracy: 0.9804 - val_loss: 0.0982 - val_accuracy: 0.9752\n",
      "Epoch 943/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0489 - accuracy: 0.9774 - val_loss: 0.0946 - val_accuracy: 0.9752\n",
      "Epoch 944/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0456 - accuracy: 0.9888 - val_loss: 0.0942 - val_accuracy: 0.9720\n",
      "Epoch 945/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0492 - accuracy: 0.9837 - val_loss: 0.0951 - val_accuracy: 0.9752\n",
      "Epoch 946/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0522 - accuracy: 0.9828 - val_loss: 0.0931 - val_accuracy: 0.9720\n",
      "Epoch 947/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0480 - accuracy: 0.9838 - val_loss: 0.0933 - val_accuracy: 0.9752\n",
      "Epoch 948/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0473 - accuracy: 0.9834 - val_loss: 0.0942 - val_accuracy: 0.9814\n",
      "Epoch 949/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0479 - accuracy: 0.9790 - val_loss: 0.0949 - val_accuracy: 0.9783\n",
      "Epoch 950/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0491 - accuracy: 0.9780 - val_loss: 0.0935 - val_accuracy: 0.9814\n",
      "Epoch 951/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0466 - accuracy: 0.9834 - val_loss: 0.0924 - val_accuracy: 0.9752\n",
      "Epoch 952/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.9848 - val_loss: 0.0923 - val_accuracy: 0.9752\n",
      "Epoch 953/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.0928 - val_accuracy: 0.9783\n",
      "Epoch 954/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0486 - accuracy: 0.9824 - val_loss: 0.0929 - val_accuracy: 0.9783\n",
      "Epoch 955/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0512 - accuracy: 0.9814 - val_loss: 0.0928 - val_accuracy: 0.9720\n",
      "Epoch 956/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.0947 - val_accuracy: 0.9752\n",
      "Epoch 957/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0494 - accuracy: 0.9851 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 958/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0486 - accuracy: 0.9828 - val_loss: 0.0936 - val_accuracy: 0.9752\n",
      "Epoch 959/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.0959 - val_accuracy: 0.9783\n",
      "Epoch 960/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0489 - accuracy: 0.9777 - val_loss: 0.1087 - val_accuracy: 0.9752\n",
      "Epoch 961/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0575 - accuracy: 0.9784 - val_loss: 0.0959 - val_accuracy: 0.9783\n",
      "Epoch 962/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0498 - accuracy: 0.9794 - val_loss: 0.0937 - val_accuracy: 0.9752\n",
      "Epoch 963/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0514 - accuracy: 0.9817 - val_loss: 0.0939 - val_accuracy: 0.9720\n",
      "Epoch 964/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0465 - accuracy: 0.9824 - val_loss: 0.0968 - val_accuracy: 0.9752\n",
      "Epoch 965/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0496 - accuracy: 0.9794 - val_loss: 0.0956 - val_accuracy: 0.9752\n",
      "Epoch 966/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0474 - accuracy: 0.9814 - val_loss: 0.0944 - val_accuracy: 0.9752\n",
      "Epoch 967/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0462 - accuracy: 0.9807 - val_loss: 0.0951 - val_accuracy: 0.9720\n",
      "Epoch 968/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0463 - accuracy: 0.9801 - val_loss: 0.0966 - val_accuracy: 0.9752\n",
      "Epoch 969/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0497 - accuracy: 0.9777 - val_loss: 0.0963 - val_accuracy: 0.9752\n",
      "Epoch 970/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0460 - accuracy: 0.9790 - val_loss: 0.0952 - val_accuracy: 0.9783\n",
      "Epoch 971/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 0.9841 - val_loss: 0.0962 - val_accuracy: 0.9752\n",
      "Epoch 972/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0476 - accuracy: 0.9784 - val_loss: 0.0961 - val_accuracy: 0.9752\n",
      "Epoch 973/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0483 - accuracy: 0.9777 - val_loss: 0.0924 - val_accuracy: 0.9752\n",
      "Epoch 974/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0505 - accuracy: 0.9848 - val_loss: 0.0921 - val_accuracy: 0.9752\n",
      "Epoch 975/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0510 - accuracy: 0.9817 - val_loss: 0.0955 - val_accuracy: 0.9752\n",
      "Epoch 976/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0468 - accuracy: 0.9774 - val_loss: 0.0920 - val_accuracy: 0.9752\n",
      "Epoch 977/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0486 - accuracy: 0.9851 - val_loss: 0.0916 - val_accuracy: 0.9752\n",
      "Epoch 978/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.0956 - val_accuracy: 0.9752\n",
      "Epoch 979/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0470 - accuracy: 0.9797 - val_loss: 0.0954 - val_accuracy: 0.9752\n",
      "Epoch 980/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0458 - accuracy: 0.9784 - val_loss: 0.0923 - val_accuracy: 0.9720\n",
      "Epoch 981/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0493 - accuracy: 0.9828 - val_loss: 0.0925 - val_accuracy: 0.9752\n",
      "Epoch 982/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0526 - accuracy: 0.9797 - val_loss: 0.0935 - val_accuracy: 0.9783\n",
      "Epoch 983/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0431 - accuracy: 0.9821 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 984/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0486 - accuracy: 0.9784 - val_loss: 0.0963 - val_accuracy: 0.9814\n",
      "Epoch 985/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0487 - accuracy: 0.9784 - val_loss: 0.0920 - val_accuracy: 0.9783\n",
      "Epoch 986/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0486 - accuracy: 0.9845 - val_loss: 0.0915 - val_accuracy: 0.9752\n",
      "Epoch 987/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0485 - accuracy: 0.9851 - val_loss: 0.0912 - val_accuracy: 0.9752\n",
      "Epoch 988/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0484 - accuracy: 0.9828 - val_loss: 0.0963 - val_accuracy: 0.9752\n",
      "Epoch 989/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0467 - accuracy: 0.9810 - val_loss: 0.0935 - val_accuracy: 0.9783\n",
      "Epoch 990/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 0.9777 - val_loss: 0.0924 - val_accuracy: 0.9752\n",
      "Epoch 991/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0482 - accuracy: 0.9834 - val_loss: 0.0924 - val_accuracy: 0.9720\n",
      "Epoch 992/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0493 - accuracy: 0.9828 - val_loss: 0.0998 - val_accuracy: 0.9752\n",
      "Epoch 993/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0481 - accuracy: 0.9817 - val_loss: 0.0948 - val_accuracy: 0.9783\n",
      "Epoch 994/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0480 - accuracy: 0.9817 - val_loss: 0.0931 - val_accuracy: 0.9783\n",
      "Epoch 995/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9834 - val_loss: 0.0960 - val_accuracy: 0.9783\n",
      "Epoch 996/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0477 - accuracy: 0.9794 - val_loss: 0.0970 - val_accuracy: 0.9752\n",
      "Epoch 997/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9784 - val_loss: 0.0944 - val_accuracy: 0.9752\n",
      "Epoch 998/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0458 - accuracy: 0.9851 - val_loss: 0.0943 - val_accuracy: 0.9752\n",
      "Epoch 999/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0454 - accuracy: 0.9854 - val_loss: 0.0978 - val_accuracy: 0.9752\n",
      "Epoch 1000/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0462 - accuracy: 0.9801 - val_loss: 0.0995 - val_accuracy: 0.9752\n",
      "Epoch 1001/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0450 - accuracy: 0.9804 - val_loss: 0.0958 - val_accuracy: 0.9752\n",
      "Epoch 1002/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0451 - accuracy: 0.9807 - val_loss: 0.0937 - val_accuracy: 0.9752\n",
      "Epoch 1003/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0465 - accuracy: 0.9817 - val_loss: 0.0936 - val_accuracy: 0.9720\n",
      "Epoch 1004/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 0.9804 - val_loss: 0.0942 - val_accuracy: 0.9752\n",
      "Epoch 1005/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0453 - accuracy: 0.9828 - val_loss: 0.0936 - val_accuracy: 0.9752\n",
      "Epoch 1006/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0446 - accuracy: 0.9817 - val_loss: 0.0934 - val_accuracy: 0.9752\n",
      "Epoch 1007/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 0.0942 - val_accuracy: 0.9783\n",
      "Epoch 1008/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0446 - accuracy: 0.9784 - val_loss: 0.0955 - val_accuracy: 0.9752\n",
      "Epoch 1009/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0473 - accuracy: 0.9777 - val_loss: 0.0943 - val_accuracy: 0.9752\n",
      "Epoch 1010/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0457 - accuracy: 0.9858 - val_loss: 0.0930 - val_accuracy: 0.9752\n",
      "Epoch 1011/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.9845 - val_loss: 0.0948 - val_accuracy: 0.9783\n",
      "Epoch 1012/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0471 - accuracy: 0.9811 - val_loss: 0.0984 - val_accuracy: 0.9752\n",
      "Epoch 1013/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0470 - accuracy: 0.9790 - val_loss: 0.0955 - val_accuracy: 0.9752\n",
      "Epoch 1014/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0478 - accuracy: 0.9787 - val_loss: 0.0942 - val_accuracy: 0.9783\n",
      "Epoch 1015/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0460 - accuracy: 0.9828 - val_loss: 0.0942 - val_accuracy: 0.9720\n",
      "Epoch 1016/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0452 - accuracy: 0.9824 - val_loss: 0.0965 - val_accuracy: 0.9752\n",
      "Epoch 1017/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0458 - accuracy: 0.9811 - val_loss: 0.0995 - val_accuracy: 0.9720\n",
      "Epoch 1018/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0479 - accuracy: 0.9801 - val_loss: 0.0950 - val_accuracy: 0.9720\n",
      "Epoch 1019/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0469 - accuracy: 0.9828 - val_loss: 0.0939 - val_accuracy: 0.9752\n",
      "Epoch 1020/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0462 - accuracy: 0.9845 - val_loss: 0.0947 - val_accuracy: 0.9720\n",
      "Epoch 1021/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0462 - accuracy: 0.9828 - val_loss: 0.0975 - val_accuracy: 0.9752\n",
      "Epoch 1022/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0478 - accuracy: 0.9770 - val_loss: 0.0960 - val_accuracy: 0.9752\n",
      "Epoch 1023/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0445 - accuracy: 0.9824 - val_loss: 0.0948 - val_accuracy: 0.9752\n",
      "Epoch 1024/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0448 - accuracy: 0.9841 - val_loss: 0.0946 - val_accuracy: 0.9752\n",
      "Epoch 1025/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0443 - accuracy: 0.9828 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 1026/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0459 - accuracy: 0.9801 - val_loss: 0.0974 - val_accuracy: 0.9783\n",
      "Epoch 1027/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0443 - accuracy: 0.9794 - val_loss: 0.0936 - val_accuracy: 0.9752\n",
      "Epoch 1028/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0456 - accuracy: 0.9845 - val_loss: 0.0932 - val_accuracy: 0.9783\n",
      "Epoch 1029/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9845 - val_loss: 0.0940 - val_accuracy: 0.9783\n",
      "Epoch 1030/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0412 - accuracy: 0.9807 - val_loss: 0.0930 - val_accuracy: 0.9783\n",
      "Epoch 1031/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0432 - accuracy: 0.9834 - val_loss: 0.0933 - val_accuracy: 0.9783\n",
      "Epoch 1032/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0465 - accuracy: 0.9787 - val_loss: 0.0925 - val_accuracy: 0.9783\n",
      "Epoch 1033/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0428 - accuracy: 0.9814 - val_loss: 0.0913 - val_accuracy: 0.9783\n",
      "Epoch 1034/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 0.0931 - val_accuracy: 0.9783\n",
      "Epoch 1035/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9821 - val_loss: 0.0928 - val_accuracy: 0.9783\n",
      "Epoch 1036/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0473 - accuracy: 0.9821 - val_loss: 0.0907 - val_accuracy: 0.9720\n",
      "Epoch 1037/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0465 - accuracy: 0.9855 - val_loss: 0.0910 - val_accuracy: 0.9752\n",
      "Epoch 1038/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0429 - accuracy: 0.9875 - val_loss: 0.0923 - val_accuracy: 0.9783\n",
      "Epoch 1039/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0422 - accuracy: 0.9814 - val_loss: 0.1007 - val_accuracy: 0.9783\n",
      "Epoch 1040/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0493 - accuracy: 0.9801 - val_loss: 0.1007 - val_accuracy: 0.9783\n",
      "Epoch 1041/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0503 - accuracy: 0.9777 - val_loss: 0.0920 - val_accuracy: 0.9752\n",
      "Epoch 1042/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0449 - accuracy: 0.9838 - val_loss: 0.0919 - val_accuracy: 0.9752\n",
      "Epoch 1043/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.0932 - val_accuracy: 0.9814\n",
      "Epoch 1044/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0438 - accuracy: 0.9828 - val_loss: 0.0986 - val_accuracy: 0.9814\n",
      "Epoch 1045/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0433 - accuracy: 0.9814 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1046/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0444 - accuracy: 0.9817 - val_loss: 0.0943 - val_accuracy: 0.9752\n",
      "Epoch 1047/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0442 - accuracy: 0.9868 - val_loss: 0.0964 - val_accuracy: 0.9752\n",
      "Epoch 1048/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 0.0980 - val_accuracy: 0.9783\n",
      "Epoch 1049/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0443 - accuracy: 0.9851 - val_loss: 0.0933 - val_accuracy: 0.9752\n",
      "Epoch 1050/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0448 - accuracy: 0.9845 - val_loss: 0.0933 - val_accuracy: 0.9783\n",
      "Epoch 1051/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0433 - accuracy: 0.9845 - val_loss: 0.0962 - val_accuracy: 0.9814\n",
      "Epoch 1052/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0479 - accuracy: 0.9787 - val_loss: 0.0969 - val_accuracy: 0.9814\n",
      "Epoch 1053/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0489 - accuracy: 0.9804 - val_loss: 0.0930 - val_accuracy: 0.9814\n",
      "Epoch 1054/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0450 - accuracy: 0.9824 - val_loss: 0.0930 - val_accuracy: 0.9814\n",
      "Epoch 1055/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0442 - accuracy: 0.9821 - val_loss: 0.0992 - val_accuracy: 0.9814\n",
      "Epoch 1056/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0458 - accuracy: 0.9817 - val_loss: 0.0977 - val_accuracy: 0.9783\n",
      "Epoch 1057/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0432 - accuracy: 0.9834 - val_loss: 0.0926 - val_accuracy: 0.9752\n",
      "Epoch 1058/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 0.0935 - val_accuracy: 0.9720\n",
      "Epoch 1059/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0490 - accuracy: 0.9834 - val_loss: 0.0931 - val_accuracy: 0.9752\n",
      "Epoch 1060/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0460 - accuracy: 0.9817 - val_loss: 0.1029 - val_accuracy: 0.9752\n",
      "Epoch 1061/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0484 - accuracy: 0.9817 - val_loss: 0.0933 - val_accuracy: 0.9752\n",
      "Epoch 1062/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0443 - accuracy: 0.9848 - val_loss: 0.0926 - val_accuracy: 0.9752\n",
      "Epoch 1063/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 0.9845 - val_loss: 0.1000 - val_accuracy: 0.9720\n",
      "Epoch 1064/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0478 - accuracy: 0.9811 - val_loss: 0.1003 - val_accuracy: 0.9752\n",
      "Epoch 1065/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0454 - accuracy: 0.9807 - val_loss: 0.0935 - val_accuracy: 0.9783\n",
      "Epoch 1066/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0432 - accuracy: 0.9834 - val_loss: 0.0935 - val_accuracy: 0.9783\n",
      "Epoch 1067/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0453 - accuracy: 0.9828 - val_loss: 0.0953 - val_accuracy: 0.9752\n",
      "Epoch 1068/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0440 - accuracy: 0.9855 - val_loss: 0.1003 - val_accuracy: 0.9783\n",
      "Epoch 1069/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0435 - accuracy: 0.9824 - val_loss: 0.0957 - val_accuracy: 0.9752\n",
      "Epoch 1070/3500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0435 - accuracy: 0.9838 - val_loss: 0.0948 - val_accuracy: 0.9783\n",
      "Epoch 1071/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0470 - accuracy: 0.9804 - val_loss: 0.0947 - val_accuracy: 0.9783\n",
      "Epoch 1072/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0423 - accuracy: 0.9858 - val_loss: 0.0987 - val_accuracy: 0.9783\n",
      "Epoch 1073/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0433 - accuracy: 0.9817 - val_loss: 0.1028 - val_accuracy: 0.9783\n",
      "Epoch 1074/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0478 - accuracy: 0.9784 - val_loss: 0.0958 - val_accuracy: 0.9783\n",
      "Epoch 1075/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0424 - accuracy: 0.9828 - val_loss: 0.0945 - val_accuracy: 0.9752\n",
      "Epoch 1076/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0434 - accuracy: 0.9851 - val_loss: 0.0946 - val_accuracy: 0.9752\n",
      "Epoch 1077/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0413 - accuracy: 0.9875 - val_loss: 0.0978 - val_accuracy: 0.9783\n",
      "Epoch 1078/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0444 - accuracy: 0.9824 - val_loss: 0.0938 - val_accuracy: 0.9752\n",
      "Epoch 1079/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.0946 - val_accuracy: 0.9752\n",
      "Epoch 1080/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0491 - accuracy: 0.9834 - val_loss: 0.0929 - val_accuracy: 0.9783\n",
      "Epoch 1081/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9834 - val_loss: 0.1029 - val_accuracy: 0.9814\n",
      "Epoch 1082/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0515 - accuracy: 0.9811 - val_loss: 0.0969 - val_accuracy: 0.9814\n",
      "Epoch 1083/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0446 - accuracy: 0.9777 - val_loss: 0.0957 - val_accuracy: 0.9752\n",
      "Epoch 1084/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0538 - accuracy: 0.9821 - val_loss: 0.0949 - val_accuracy: 0.9752\n",
      "Epoch 1085/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0519 - accuracy: 0.9821 - val_loss: 0.0966 - val_accuracy: 0.9783\n",
      "Epoch 1086/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0436 - accuracy: 0.9828 - val_loss: 0.1046 - val_accuracy: 0.9752\n",
      "Epoch 1087/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0472 - accuracy: 0.9797 - val_loss: 0.0955 - val_accuracy: 0.9783\n",
      "Epoch 1088/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0428 - accuracy: 0.9831 - val_loss: 0.0937 - val_accuracy: 0.9752\n",
      "Epoch 1089/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 0.0935 - val_accuracy: 0.9752\n",
      "Epoch 1090/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 0.1034 - val_accuracy: 0.9783\n",
      "Epoch 1091/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0479 - accuracy: 0.9787 - val_loss: 0.0995 - val_accuracy: 0.9814\n",
      "Epoch 1092/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0451 - accuracy: 0.9801 - val_loss: 0.0933 - val_accuracy: 0.9752\n",
      "Epoch 1093/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0418 - accuracy: 0.9851 - val_loss: 0.0932 - val_accuracy: 0.9752\n",
      "Epoch 1094/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 0.9831 - val_loss: 0.0946 - val_accuracy: 0.9783\n",
      "Epoch 1095/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0399 - accuracy: 0.9865 - val_loss: 0.0964 - val_accuracy: 0.9783\n",
      "Epoch 1096/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0439 - accuracy: 0.9851 - val_loss: 0.0956 - val_accuracy: 0.9783\n",
      "Epoch 1097/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0428 - accuracy: 0.9828 - val_loss: 0.0931 - val_accuracy: 0.9783\n",
      "Epoch 1098/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0434 - accuracy: 0.9841 - val_loss: 0.0924 - val_accuracy: 0.9783\n",
      "Epoch 1099/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0433 - accuracy: 0.9841 - val_loss: 0.0987 - val_accuracy: 0.9783\n",
      "Epoch 1100/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0450 - accuracy: 0.9841 - val_loss: 0.0950 - val_accuracy: 0.9752\n",
      "Epoch 1101/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 0.9845 - val_loss: 0.0914 - val_accuracy: 0.9720\n",
      "Epoch 1102/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0463 - accuracy: 0.9838 - val_loss: 0.0905 - val_accuracy: 0.9783\n",
      "Epoch 1103/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.0917 - val_accuracy: 0.9814\n",
      "Epoch 1104/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0422 - accuracy: 0.9845 - val_loss: 0.0926 - val_accuracy: 0.9814\n",
      "Epoch 1105/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0392 - accuracy: 0.9848 - val_loss: 0.0937 - val_accuracy: 0.9783\n",
      "Epoch 1106/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0404 - accuracy: 0.9841 - val_loss: 0.0998 - val_accuracy: 0.9783\n",
      "Epoch 1107/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.0976 - val_accuracy: 0.9752\n",
      "Epoch 1108/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 0.0940 - val_accuracy: 0.9752\n",
      "Epoch 1109/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0433 - accuracy: 0.9878 - val_loss: 0.0951 - val_accuracy: 0.9783\n",
      "Epoch 1110/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0425 - accuracy: 0.9855 - val_loss: 0.0962 - val_accuracy: 0.9783\n",
      "Epoch 1111/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0404 - accuracy: 0.9828 - val_loss: 0.0951 - val_accuracy: 0.9814\n",
      "Epoch 1112/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0390 - accuracy: 0.9875 - val_loss: 0.0958 - val_accuracy: 0.9814\n",
      "Epoch 1113/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0406 - accuracy: 0.9828 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 1114/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0383 - accuracy: 0.9841 - val_loss: 0.1026 - val_accuracy: 0.9783\n",
      "Epoch 1115/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0419 - accuracy: 0.9841 - val_loss: 0.1067 - val_accuracy: 0.9752\n",
      "Epoch 1116/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0455 - accuracy: 0.9817 - val_loss: 0.0978 - val_accuracy: 0.9783\n",
      "Epoch 1117/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0405 - accuracy: 0.9855 - val_loss: 0.0972 - val_accuracy: 0.9752\n",
      "Epoch 1118/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0462 - accuracy: 0.9841 - val_loss: 0.0960 - val_accuracy: 0.9752\n",
      "Epoch 1119/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0372 - accuracy: 0.9892 - val_loss: 0.1115 - val_accuracy: 0.9752\n",
      "Epoch 1120/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0516 - accuracy: 0.9811 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
      "Epoch 1121/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0428 - accuracy: 0.9807 - val_loss: 0.0945 - val_accuracy: 0.9783\n",
      "Epoch 1122/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0434 - accuracy: 0.9824 - val_loss: 0.0935 - val_accuracy: 0.9814\n",
      "Epoch 1123/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0445 - accuracy: 0.9848 - val_loss: 0.0955 - val_accuracy: 0.9783\n",
      "Epoch 1124/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 0.9848 - val_loss: 0.0935 - val_accuracy: 0.9783\n",
      "Epoch 1125/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0424 - accuracy: 0.9845 - val_loss: 0.0923 - val_accuracy: 0.9752\n",
      "Epoch 1126/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0404 - accuracy: 0.9845 - val_loss: 0.0928 - val_accuracy: 0.9752\n",
      "Epoch 1127/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0423 - accuracy: 0.9848 - val_loss: 0.0931 - val_accuracy: 0.9783\n",
      "Epoch 1128/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0406 - accuracy: 0.9845 - val_loss: 0.0940 - val_accuracy: 0.9783\n",
      "Epoch 1129/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0415 - accuracy: 0.9851 - val_loss: 0.0962 - val_accuracy: 0.9814\n",
      "Epoch 1130/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0416 - accuracy: 0.9834 - val_loss: 0.0949 - val_accuracy: 0.9783\n",
      "Epoch 1131/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0401 - accuracy: 0.9845 - val_loss: 0.0935 - val_accuracy: 0.9752\n",
      "Epoch 1132/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0413 - accuracy: 0.9861 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1133/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0418 - accuracy: 0.9851 - val_loss: 0.1022 - val_accuracy: 0.9783\n",
      "Epoch 1134/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 0.0936 - val_accuracy: 0.9783\n",
      "Epoch 1135/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0420 - accuracy: 0.9848 - val_loss: 0.0937 - val_accuracy: 0.9783\n",
      "Epoch 1136/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0467 - accuracy: 0.9821 - val_loss: 0.0929 - val_accuracy: 0.9783\n",
      "Epoch 1137/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0438 - accuracy: 0.9831 - val_loss: 0.0949 - val_accuracy: 0.9783\n",
      "Epoch 1138/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0396 - accuracy: 0.9834 - val_loss: 0.0960 - val_accuracy: 0.9783\n",
      "Epoch 1139/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0420 - accuracy: 0.9838 - val_loss: 0.0930 - val_accuracy: 0.9752\n",
      "Epoch 1140/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0415 - accuracy: 0.9855 - val_loss: 0.0931 - val_accuracy: 0.9752\n",
      "Epoch 1141/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0424 - accuracy: 0.9845 - val_loss: 0.0949 - val_accuracy: 0.9783\n",
      "Epoch 1142/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0396 - accuracy: 0.9845 - val_loss: 0.1007 - val_accuracy: 0.9783\n",
      "Epoch 1143/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0419 - accuracy: 0.9841 - val_loss: 0.0941 - val_accuracy: 0.9752\n",
      "Epoch 1144/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 0.0945 - val_accuracy: 0.9720\n",
      "Epoch 1145/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0480 - accuracy: 0.9821 - val_loss: 0.0940 - val_accuracy: 0.9783\n",
      "Epoch 1146/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0409 - accuracy: 0.9851 - val_loss: 0.0986 - val_accuracy: 0.9814\n",
      "Epoch 1147/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0412 - accuracy: 0.9824 - val_loss: 0.1108 - val_accuracy: 0.9752\n",
      "Epoch 1148/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0491 - accuracy: 0.9824 - val_loss: 0.0933 - val_accuracy: 0.9783\n",
      "Epoch 1149/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0437 - accuracy: 0.9858 - val_loss: 0.0935 - val_accuracy: 0.9783\n",
      "Epoch 1150/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0394 - accuracy: 0.9848 - val_loss: 0.0988 - val_accuracy: 0.9814\n",
      "Epoch 1151/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0431 - accuracy: 0.9828 - val_loss: 0.1053 - val_accuracy: 0.9783\n",
      "Epoch 1152/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0463 - accuracy: 0.9824 - val_loss: 0.0917 - val_accuracy: 0.9752\n",
      "Epoch 1153/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0409 - accuracy: 0.9838 - val_loss: 0.0924 - val_accuracy: 0.9783\n",
      "Epoch 1154/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0418 - accuracy: 0.9841 - val_loss: 0.0921 - val_accuracy: 0.9814\n",
      "Epoch 1155/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0381 - accuracy: 0.9848 - val_loss: 0.1021 - val_accuracy: 0.9814\n",
      "Epoch 1156/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9821 - val_loss: 0.0941 - val_accuracy: 0.9814\n",
      "Epoch 1157/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0411 - accuracy: 0.9797 - val_loss: 0.0909 - val_accuracy: 0.9752\n",
      "Epoch 1158/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.0922 - val_accuracy: 0.9783\n",
      "Epoch 1159/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0402 - accuracy: 0.9828 - val_loss: 0.0938 - val_accuracy: 0.9783\n",
      "Epoch 1160/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0419 - accuracy: 0.9848 - val_loss: 0.0926 - val_accuracy: 0.9752\n",
      "Epoch 1161/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0354 - accuracy: 0.9881 - val_loss: 0.0933 - val_accuracy: 0.9783\n",
      "Epoch 1162/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 0.0982 - val_accuracy: 0.9814\n",
      "Epoch 1163/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0417 - accuracy: 0.9845 - val_loss: 0.0991 - val_accuracy: 0.9814\n",
      "Epoch 1164/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0423 - accuracy: 0.9811 - val_loss: 0.0959 - val_accuracy: 0.9783\n",
      "Epoch 1165/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 0.9841 - val_loss: 0.0942 - val_accuracy: 0.9783\n",
      "Epoch 1166/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0391 - accuracy: 0.9845 - val_loss: 0.0951 - val_accuracy: 0.9783\n",
      "Epoch 1167/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0405 - accuracy: 0.9854 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1168/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0412 - accuracy: 0.9834 - val_loss: 0.1138 - val_accuracy: 0.9720\n",
      "Epoch 1169/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0503 - accuracy: 0.9834 - val_loss: 0.0937 - val_accuracy: 0.9752\n",
      "Epoch 1170/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0415 - accuracy: 0.9885 - val_loss: 0.0981 - val_accuracy: 0.9720\n",
      "Epoch 1171/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0506 - accuracy: 0.9834 - val_loss: 0.0944 - val_accuracy: 0.9752\n",
      "Epoch 1172/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.1080 - val_accuracy: 0.9783\n",
      "Epoch 1173/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0449 - accuracy: 0.9841 - val_loss: 0.0958 - val_accuracy: 0.9783\n",
      "Epoch 1174/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0390 - accuracy: 0.9855 - val_loss: 0.0948 - val_accuracy: 0.9783\n",
      "Epoch 1175/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9814 - val_loss: 0.0940 - val_accuracy: 0.9783\n",
      "Epoch 1176/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.0975 - val_accuracy: 0.9814\n",
      "Epoch 1177/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0393 - accuracy: 0.9841 - val_loss: 0.1073 - val_accuracy: 0.9783\n",
      "Epoch 1178/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0470 - accuracy: 0.9811 - val_loss: 0.0944 - val_accuracy: 0.9752\n",
      "Epoch 1179/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0405 - accuracy: 0.9851 - val_loss: 0.0952 - val_accuracy: 0.9720\n",
      "Epoch 1180/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0453 - accuracy: 0.9821 - val_loss: 0.0950 - val_accuracy: 0.9783\n",
      "Epoch 1181/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0405 - accuracy: 0.9872 - val_loss: 0.0999 - val_accuracy: 0.9814\n",
      "Epoch 1182/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0409 - accuracy: 0.9838 - val_loss: 0.0960 - val_accuracy: 0.9783\n",
      "Epoch 1183/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 0.9824 - val_loss: 0.0942 - val_accuracy: 0.9783\n",
      "Epoch 1184/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 0.9858 - val_loss: 0.0940 - val_accuracy: 0.9783\n",
      "Epoch 1185/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0343 - accuracy: 0.9881 - val_loss: 0.0962 - val_accuracy: 0.9783\n",
      "Epoch 1186/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0380 - accuracy: 0.9841 - val_loss: 0.0957 - val_accuracy: 0.9752\n",
      "Epoch 1187/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0399 - accuracy: 0.9855 - val_loss: 0.0929 - val_accuracy: 0.9783\n",
      "Epoch 1188/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0363 - accuracy: 0.9868 - val_loss: 0.0920 - val_accuracy: 0.9752\n",
      "Epoch 1189/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.0922 - val_accuracy: 0.9752\n",
      "Epoch 1190/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.0957 - val_accuracy: 0.9783\n",
      "Epoch 1191/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 0.9817 - val_loss: 0.0982 - val_accuracy: 0.9783\n",
      "Epoch 1192/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0405 - accuracy: 0.9845 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 1193/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 0.9834 - val_loss: 0.0957 - val_accuracy: 0.9783\n",
      "Epoch 1194/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 0.0954 - val_accuracy: 0.9783\n",
      "Epoch 1195/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 0.9868 - val_loss: 0.0958 - val_accuracy: 0.9783\n",
      "Epoch 1196/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0387 - accuracy: 0.9861 - val_loss: 0.0954 - val_accuracy: 0.9783\n",
      "Epoch 1197/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0391 - accuracy: 0.9861 - val_loss: 0.0952 - val_accuracy: 0.9752\n",
      "Epoch 1198/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 0.0944 - val_accuracy: 0.9752\n",
      "Epoch 1199/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0384 - accuracy: 0.9878 - val_loss: 0.0943 - val_accuracy: 0.9752\n",
      "Epoch 1200/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0394 - accuracy: 0.9848 - val_loss: 0.0948 - val_accuracy: 0.9783\n",
      "Epoch 1201/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0404 - accuracy: 0.9848 - val_loss: 0.0953 - val_accuracy: 0.9783\n",
      "Epoch 1202/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0379 - accuracy: 0.9875 - val_loss: 0.0966 - val_accuracy: 0.9783\n",
      "Epoch 1203/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0366 - accuracy: 0.9851 - val_loss: 0.1004 - val_accuracy: 0.9783\n",
      "Epoch 1204/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0403 - accuracy: 0.9828 - val_loss: 0.0973 - val_accuracy: 0.9783\n",
      "Epoch 1205/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.0962 - val_accuracy: 0.9752\n",
      "Epoch 1206/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0399 - accuracy: 0.9845 - val_loss: 0.0963 - val_accuracy: 0.9752\n",
      "Epoch 1207/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0360 - accuracy: 0.9865 - val_loss: 0.1020 - val_accuracy: 0.9814\n",
      "Epoch 1208/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 0.9851 - val_loss: 0.1015 - val_accuracy: 0.9814\n",
      "Epoch 1209/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0406 - accuracy: 0.9868 - val_loss: 0.0951 - val_accuracy: 0.9752\n",
      "Epoch 1210/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0384 - accuracy: 0.9878 - val_loss: 0.0947 - val_accuracy: 0.9752\n",
      "Epoch 1211/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 0.0991 - val_accuracy: 0.9752\n",
      "Epoch 1212/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0424 - accuracy: 0.9841 - val_loss: 0.0981 - val_accuracy: 0.9752\n",
      "Epoch 1213/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 0.9868 - val_loss: 0.0942 - val_accuracy: 0.9783\n",
      "Epoch 1214/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0400 - accuracy: 0.9845 - val_loss: 0.0953 - val_accuracy: 0.9783\n",
      "Epoch 1215/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0417 - accuracy: 0.9851 - val_loss: 0.0963 - val_accuracy: 0.9814\n",
      "Epoch 1216/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0402 - accuracy: 0.9858 - val_loss: 0.1004 - val_accuracy: 0.9845\n",
      "Epoch 1217/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0430 - accuracy: 0.9841 - val_loss: 0.0951 - val_accuracy: 0.9814\n",
      "Epoch 1218/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 0.9851 - val_loss: 0.0945 - val_accuracy: 0.9752\n",
      "Epoch 1219/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0407 - accuracy: 0.9834 - val_loss: 0.0942 - val_accuracy: 0.9752\n",
      "Epoch 1220/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0405 - accuracy: 0.9872 - val_loss: 0.1026 - val_accuracy: 0.9783\n",
      "Epoch 1221/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0421 - accuracy: 0.9851 - val_loss: 0.0968 - val_accuracy: 0.9783\n",
      "Epoch 1222/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0373 - accuracy: 0.9902 - val_loss: 0.0952 - val_accuracy: 0.9752\n",
      "Epoch 1223/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0394 - accuracy: 0.9855 - val_loss: 0.0962 - val_accuracy: 0.9783\n",
      "Epoch 1224/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1225/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0385 - accuracy: 0.9845 - val_loss: 0.0983 - val_accuracy: 0.9783\n",
      "Epoch 1226/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0359 - accuracy: 0.9861 - val_loss: 0.0977 - val_accuracy: 0.9783\n",
      "Epoch 1227/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0345 - accuracy: 0.9858 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1228/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0384 - accuracy: 0.9834 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1229/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 0.0960 - val_accuracy: 0.9752\n",
      "Epoch 1230/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0380 - accuracy: 0.9861 - val_loss: 0.0963 - val_accuracy: 0.9783\n",
      "Epoch 1231/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: 0.0962 - val_accuracy: 0.9783\n",
      "Epoch 1232/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0367 - accuracy: 0.9868 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1233/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0338 - accuracy: 0.9858 - val_loss: 0.1007 - val_accuracy: 0.9814\n",
      "Epoch 1234/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0413 - accuracy: 0.9814 - val_loss: 0.0968 - val_accuracy: 0.9783\n",
      "Epoch 1235/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.0933 - val_accuracy: 0.9752\n",
      "Epoch 1236/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.0937 - val_accuracy: 0.9783\n",
      "Epoch 1237/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0407 - accuracy: 0.9855 - val_loss: 0.0942 - val_accuracy: 0.9814\n",
      "Epoch 1238/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0374 - accuracy: 0.9861 - val_loss: 0.0980 - val_accuracy: 0.9783\n",
      "Epoch 1239/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0390 - accuracy: 0.9838 - val_loss: 0.0972 - val_accuracy: 0.9783\n",
      "Epoch 1240/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0383 - accuracy: 0.9855 - val_loss: 0.0960 - val_accuracy: 0.9783\n",
      "Epoch 1241/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0379 - accuracy: 0.9861 - val_loss: 0.0966 - val_accuracy: 0.9783\n",
      "Epoch 1242/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
      "Epoch 1243/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 0.9861 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
      "Epoch 1244/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0346 - accuracy: 0.9871 - val_loss: 0.0956 - val_accuracy: 0.9783\n",
      "Epoch 1245/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0378 - accuracy: 0.9868 - val_loss: 0.0948 - val_accuracy: 0.9752\n",
      "Epoch 1246/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0395 - accuracy: 0.9831 - val_loss: 0.0962 - val_accuracy: 0.9783\n",
      "Epoch 1247/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
      "Epoch 1248/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0370 - accuracy: 0.9845 - val_loss: 0.0945 - val_accuracy: 0.9814\n",
      "Epoch 1249/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0385 - accuracy: 0.9855 - val_loss: 0.0942 - val_accuracy: 0.9783\n",
      "Epoch 1250/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0403 - accuracy: 0.9845 - val_loss: 0.0942 - val_accuracy: 0.9814\n",
      "Epoch 1251/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0386 - accuracy: 0.9855 - val_loss: 0.1001 - val_accuracy: 0.9814\n",
      "Epoch 1252/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 0.9875 - val_loss: 0.1017 - val_accuracy: 0.9814\n",
      "Epoch 1253/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
      "Epoch 1254/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0357 - accuracy: 0.9861 - val_loss: 0.0965 - val_accuracy: 0.9752\n",
      "Epoch 1255/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.0979 - val_accuracy: 0.9783\n",
      "Epoch 1256/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0365 - accuracy: 0.9885 - val_loss: 0.0987 - val_accuracy: 0.9783\n",
      "Epoch 1257/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0359 - accuracy: 0.9868 - val_loss: 0.0998 - val_accuracy: 0.9783\n",
      "Epoch 1258/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0375 - accuracy: 0.9861 - val_loss: 0.0984 - val_accuracy: 0.9752\n",
      "Epoch 1259/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.0978 - val_accuracy: 0.9752\n",
      "Epoch 1260/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0370 - accuracy: 0.9845 - val_loss: 0.0986 - val_accuracy: 0.9783\n",
      "Epoch 1261/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0358 - accuracy: 0.9855 - val_loss: 0.0986 - val_accuracy: 0.9783\n",
      "Epoch 1262/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0370 - accuracy: 0.9845 - val_loss: 0.0982 - val_accuracy: 0.9814\n",
      "Epoch 1263/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0358 - accuracy: 0.9845 - val_loss: 0.0962 - val_accuracy: 0.9814\n",
      "Epoch 1264/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.0953 - val_accuracy: 0.9783\n",
      "Epoch 1265/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
      "Epoch 1266/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0364 - accuracy: 0.9828 - val_loss: 0.0959 - val_accuracy: 0.9783\n",
      "Epoch 1267/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0368 - accuracy: 0.9821 - val_loss: 0.0952 - val_accuracy: 0.9783\n",
      "Epoch 1268/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0362 - accuracy: 0.9855 - val_loss: 0.0963 - val_accuracy: 0.9783\n",
      "Epoch 1269/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0337 - accuracy: 0.9841 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 1270/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0337 - accuracy: 0.9858 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1271/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0358 - accuracy: 0.9845 - val_loss: 0.0965 - val_accuracy: 0.9814\n",
      "Epoch 1272/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0352 - accuracy: 0.9861 - val_loss: 0.0965 - val_accuracy: 0.9752\n",
      "Epoch 1273/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0361 - accuracy: 0.9851 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1274/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
      "Epoch 1275/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 0.0957 - val_accuracy: 0.9752\n",
      "Epoch 1276/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.0947 - val_accuracy: 0.9752\n",
      "Epoch 1277/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0357 - accuracy: 0.9861 - val_loss: 0.0947 - val_accuracy: 0.9783\n",
      "Epoch 1278/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 0.9861 - val_loss: 0.0961 - val_accuracy: 0.9814\n",
      "Epoch 1279/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0366 - accuracy: 0.9838 - val_loss: 0.0977 - val_accuracy: 0.9814\n",
      "Epoch 1280/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0356 - accuracy: 0.9834 - val_loss: 0.0974 - val_accuracy: 0.9814\n",
      "Epoch 1281/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0365 - accuracy: 0.9828 - val_loss: 0.0950 - val_accuracy: 0.9783\n",
      "Epoch 1282/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0356 - accuracy: 0.9861 - val_loss: 0.0948 - val_accuracy: 0.9752\n",
      "Epoch 1283/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0368 - accuracy: 0.9872 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 1284/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0320 - accuracy: 0.9909 - val_loss: 0.0998 - val_accuracy: 0.9783\n",
      "Epoch 1285/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0357 - accuracy: 0.9851 - val_loss: 0.0954 - val_accuracy: 0.9783\n",
      "Epoch 1286/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0341 - accuracy: 0.9895 - val_loss: 0.0944 - val_accuracy: 0.9783\n",
      "Epoch 1287/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0359 - accuracy: 0.9885 - val_loss: 0.0940 - val_accuracy: 0.9783\n",
      "Epoch 1288/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0339 - accuracy: 0.9905 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 1289/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 0.9861 - val_loss: 0.0962 - val_accuracy: 0.9783\n",
      "Epoch 1290/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0368 - accuracy: 0.9821 - val_loss: 0.0956 - val_accuracy: 0.9814\n",
      "Epoch 1291/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0347 - accuracy: 0.9861 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 1292/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0352 - accuracy: 0.9861 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
      "Epoch 1293/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0326 - accuracy: 0.9885 - val_loss: 0.0956 - val_accuracy: 0.9752\n",
      "Epoch 1294/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.0955 - val_accuracy: 0.9752\n",
      "Epoch 1295/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0361 - accuracy: 0.9865 - val_loss: 0.0958 - val_accuracy: 0.9752\n",
      "Epoch 1296/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1297/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0362 - accuracy: 0.9872 - val_loss: 0.0991 - val_accuracy: 0.9783\n",
      "Epoch 1298/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0366 - accuracy: 0.9838 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 1299/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.0955 - val_accuracy: 0.9752\n",
      "Epoch 1300/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0383 - accuracy: 0.9848 - val_loss: 0.0954 - val_accuracy: 0.9752\n",
      "Epoch 1301/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0367 - accuracy: 0.9838 - val_loss: 0.0966 - val_accuracy: 0.9783\n",
      "Epoch 1302/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0344 - accuracy: 0.9845 - val_loss: 0.0970 - val_accuracy: 0.9783\n",
      "Epoch 1303/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0352 - accuracy: 0.9831 - val_loss: 0.0950 - val_accuracy: 0.9783\n",
      "Epoch 1304/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 0.0946 - val_accuracy: 0.9752\n",
      "Epoch 1305/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0353 - accuracy: 0.9872 - val_loss: 0.0946 - val_accuracy: 0.9752\n",
      "Epoch 1306/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 0.0983 - val_accuracy: 0.9783\n",
      "Epoch 1307/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0363 - accuracy: 0.9855 - val_loss: 0.1029 - val_accuracy: 0.9814\n",
      "Epoch 1308/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0363 - accuracy: 0.9858 - val_loss: 0.0951 - val_accuracy: 0.9752\n",
      "Epoch 1309/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.0956 - val_accuracy: 0.9752\n",
      "Epoch 1310/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0342 - accuracy: 0.9892 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 1311/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0366 - accuracy: 0.9855 - val_loss: 0.0984 - val_accuracy: 0.9783\n",
      "Epoch 1312/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0345 - accuracy: 0.9845 - val_loss: 0.0972 - val_accuracy: 0.9783\n",
      "Epoch 1313/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0371 - accuracy: 0.9855 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 1314/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1315/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 1316/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0340 - accuracy: 0.9834 - val_loss: 0.1007 - val_accuracy: 0.9783\n",
      "Epoch 1317/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0328 - accuracy: 0.9892 - val_loss: 0.0959 - val_accuracy: 0.9752\n",
      "Epoch 1318/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0355 - accuracy: 0.9865 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 1319/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0374 - accuracy: 0.9834 - val_loss: 0.0966 - val_accuracy: 0.9752\n",
      "Epoch 1320/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0321 - accuracy: 0.9861 - val_loss: 0.1114 - val_accuracy: 0.9783\n",
      "Epoch 1321/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0415 - accuracy: 0.9851 - val_loss: 0.1025 - val_accuracy: 0.9783\n",
      "Epoch 1322/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0378 - accuracy: 0.9848 - val_loss: 0.0985 - val_accuracy: 0.9783\n",
      "Epoch 1323/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0433 - accuracy: 0.9804 - val_loss: 0.0993 - val_accuracy: 0.9783\n",
      "Epoch 1324/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0407 - accuracy: 0.9851 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1325/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0305 - accuracy: 0.9875 - val_loss: 0.1068 - val_accuracy: 0.9783\n",
      "Epoch 1326/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0389 - accuracy: 0.9851 - val_loss: 0.0963 - val_accuracy: 0.9783\n",
      "Epoch 1327/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0346 - accuracy: 0.9878 - val_loss: 0.0964 - val_accuracy: 0.9783\n",
      "Epoch 1328/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0362 - accuracy: 0.9834 - val_loss: 0.0979 - val_accuracy: 0.9783\n",
      "Epoch 1329/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0337 - accuracy: 0.9872 - val_loss: 0.1063 - val_accuracy: 0.9783\n",
      "Epoch 1330/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0414 - accuracy: 0.9831 - val_loss: 0.0972 - val_accuracy: 0.9783\n",
      "Epoch 1331/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0351 - accuracy: 0.9855 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
      "Epoch 1332/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0375 - accuracy: 0.9861 - val_loss: 0.0963 - val_accuracy: 0.9752\n",
      "Epoch 1333/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0351 - accuracy: 0.9872 - val_loss: 0.1027 - val_accuracy: 0.9783\n",
      "Epoch 1334/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.1019 - val_accuracy: 0.9783\n",
      "Epoch 1335/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0325 - accuracy: 0.9919 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1336/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0351 - accuracy: 0.9834 - val_loss: 0.0978 - val_accuracy: 0.9783\n",
      "Epoch 1337/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0375 - accuracy: 0.9845 - val_loss: 0.0983 - val_accuracy: 0.9783\n",
      "Epoch 1338/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0333 - accuracy: 0.9845 - val_loss: 0.1031 - val_accuracy: 0.9814\n",
      "Epoch 1339/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0363 - accuracy: 0.9872 - val_loss: 0.0955 - val_accuracy: 0.9783\n",
      "Epoch 1340/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0326 - accuracy: 0.9889 - val_loss: 0.0955 - val_accuracy: 0.9783\n",
      "Epoch 1341/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0380 - accuracy: 0.9861 - val_loss: 0.0942 - val_accuracy: 0.9752\n",
      "Epoch 1342/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0344 - accuracy: 0.9861 - val_loss: 0.0952 - val_accuracy: 0.9783\n",
      "Epoch 1343/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0318 - accuracy: 0.9885 - val_loss: 0.0957 - val_accuracy: 0.9814\n",
      "Epoch 1344/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0350 - accuracy: 0.9861 - val_loss: 0.0974 - val_accuracy: 0.9814\n",
      "Epoch 1345/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0333 - accuracy: 0.9817 - val_loss: 0.0995 - val_accuracy: 0.9783\n",
      "Epoch 1346/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0341 - accuracy: 0.9872 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 1347/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0345 - accuracy: 0.9865 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
      "Epoch 1348/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
      "Epoch 1349/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0368 - accuracy: 0.9865 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 1350/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0331 - accuracy: 0.9872 - val_loss: 0.1017 - val_accuracy: 0.9783\n",
      "Epoch 1351/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0354 - accuracy: 0.9845 - val_loss: 0.0980 - val_accuracy: 0.9814\n",
      "Epoch 1352/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0355 - accuracy: 0.9865 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1353/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0376 - accuracy: 0.9845 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 1354/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0330 - accuracy: 0.9861 - val_loss: 0.0988 - val_accuracy: 0.9783\n",
      "Epoch 1355/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0323 - accuracy: 0.9861 - val_loss: 0.1018 - val_accuracy: 0.9783\n",
      "Epoch 1356/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0334 - accuracy: 0.9851 - val_loss: 0.0993 - val_accuracy: 0.9783\n",
      "Epoch 1357/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0328 - accuracy: 0.9855 - val_loss: 0.0963 - val_accuracy: 0.9783\n",
      "Epoch 1358/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0320 - accuracy: 0.9868 - val_loss: 0.0951 - val_accuracy: 0.9752\n",
      "Epoch 1359/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: 0.0951 - val_accuracy: 0.9783\n",
      "Epoch 1360/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0297 - accuracy: 0.9868 - val_loss: 0.0953 - val_accuracy: 0.9783\n",
      "Epoch 1361/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0304 - accuracy: 0.9885 - val_loss: 0.0942 - val_accuracy: 0.9783\n",
      "Epoch 1362/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.0942 - val_accuracy: 0.9752\n",
      "Epoch 1363/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0343 - accuracy: 0.9899 - val_loss: 0.0947 - val_accuracy: 0.9783\n",
      "Epoch 1364/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.0966 - val_accuracy: 0.9783\n",
      "Epoch 1365/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.1015 - val_accuracy: 0.9752\n",
      "Epoch 1366/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0351 - accuracy: 0.9855 - val_loss: 0.1016 - val_accuracy: 0.9783\n",
      "Epoch 1367/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0351 - accuracy: 0.9848 - val_loss: 0.0974 - val_accuracy: 0.9783\n",
      "Epoch 1368/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0336 - accuracy: 0.9865 - val_loss: 0.0978 - val_accuracy: 0.9783\n",
      "Epoch 1369/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0328 - accuracy: 0.9875 - val_loss: 0.0999 - val_accuracy: 0.9783\n",
      "Epoch 1370/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0319 - accuracy: 0.9861 - val_loss: 0.1090 - val_accuracy: 0.9814\n",
      "Epoch 1371/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0390 - accuracy: 0.9838 - val_loss: 0.0968 - val_accuracy: 0.9783\n",
      "Epoch 1372/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0311 - accuracy: 0.9895 - val_loss: 0.0973 - val_accuracy: 0.9814\n",
      "Epoch 1373/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0370 - accuracy: 0.9828 - val_loss: 0.0954 - val_accuracy: 0.9783\n",
      "Epoch 1374/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0322 - accuracy: 0.9851 - val_loss: 0.0985 - val_accuracy: 0.9783\n",
      "Epoch 1375/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0327 - accuracy: 0.9868 - val_loss: 0.0972 - val_accuracy: 0.9783\n",
      "Epoch 1376/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0326 - accuracy: 0.9861 - val_loss: 0.0946 - val_accuracy: 0.9752\n",
      "Epoch 1377/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0330 - accuracy: 0.9861 - val_loss: 0.0948 - val_accuracy: 0.9752\n",
      "Epoch 1378/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0320 - accuracy: 0.9861 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 1379/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0326 - accuracy: 0.9838 - val_loss: 0.0972 - val_accuracy: 0.9783\n",
      "Epoch 1380/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0314 - accuracy: 0.9885 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
      "Epoch 1381/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0314 - accuracy: 0.9872 - val_loss: 0.0977 - val_accuracy: 0.9783\n",
      "Epoch 1382/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0971 - val_accuracy: 0.9752\n",
      "Epoch 1383/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0329 - accuracy: 0.9872 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1384/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0301 - accuracy: 0.9895 - val_loss: 0.1003 - val_accuracy: 0.9783\n",
      "Epoch 1385/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0306 - accuracy: 0.9881 - val_loss: 0.1019 - val_accuracy: 0.9783\n",
      "Epoch 1386/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0335 - accuracy: 0.9861 - val_loss: 0.0956 - val_accuracy: 0.9752\n",
      "Epoch 1387/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0313 - accuracy: 0.9892 - val_loss: 0.0956 - val_accuracy: 0.9783\n",
      "Epoch 1388/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0337 - accuracy: 0.9861 - val_loss: 0.0958 - val_accuracy: 0.9783\n",
      "Epoch 1389/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0307 - accuracy: 0.9868 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 1390/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0321 - accuracy: 0.9851 - val_loss: 0.0960 - val_accuracy: 0.9783\n",
      "Epoch 1391/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.0957 - val_accuracy: 0.9752\n",
      "Epoch 1392/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 0.0972 - val_accuracy: 0.9783\n",
      "Epoch 1393/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0304 - accuracy: 0.9878 - val_loss: 0.0973 - val_accuracy: 0.9783\n",
      "Epoch 1394/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0316 - accuracy: 0.9878 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
      "Epoch 1395/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0309 - accuracy: 0.9895 - val_loss: 0.0982 - val_accuracy: 0.9783\n",
      "Epoch 1396/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0320 - accuracy: 0.9855 - val_loss: 0.0999 - val_accuracy: 0.9783\n",
      "Epoch 1397/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0313 - accuracy: 0.9851 - val_loss: 0.0972 - val_accuracy: 0.9783\n",
      "Epoch 1398/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.0964 - val_accuracy: 0.9752\n",
      "Epoch 1399/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0311 - accuracy: 0.9895 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1400/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.1000 - val_accuracy: 0.9783\n",
      "Epoch 1401/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0314 - accuracy: 0.9868 - val_loss: 0.0958 - val_accuracy: 0.9783\n",
      "Epoch 1402/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0307 - accuracy: 0.9889 - val_loss: 0.0948 - val_accuracy: 0.9814\n",
      "Epoch 1403/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0347 - accuracy: 0.9855 - val_loss: 0.0947 - val_accuracy: 0.9783\n",
      "Epoch 1404/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0298 - accuracy: 0.9892 - val_loss: 0.0968 - val_accuracy: 0.9783\n",
      "Epoch 1405/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0339 - accuracy: 0.9845 - val_loss: 0.1037 - val_accuracy: 0.9783\n",
      "Epoch 1406/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0375 - accuracy: 0.9838 - val_loss: 0.0952 - val_accuracy: 0.9783\n",
      "Epoch 1407/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0340 - accuracy: 0.9865 - val_loss: 0.0974 - val_accuracy: 0.9814\n",
      "Epoch 1408/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0382 - accuracy: 0.9831 - val_loss: 0.0964 - val_accuracy: 0.9814\n",
      "Epoch 1409/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.1015 - val_accuracy: 0.9783\n",
      "Epoch 1410/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0338 - accuracy: 0.9848 - val_loss: 0.0998 - val_accuracy: 0.9783\n",
      "Epoch 1411/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0327 - accuracy: 0.9865 - val_loss: 0.0973 - val_accuracy: 0.9783\n",
      "Epoch 1412/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0336 - accuracy: 0.9865 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1413/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0342 - accuracy: 0.9848 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1414/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0306 - accuracy: 0.9878 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 1415/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0310 - accuracy: 0.9889 - val_loss: 0.0970 - val_accuracy: 0.9783\n",
      "Epoch 1416/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0301 - accuracy: 0.9919 - val_loss: 0.0966 - val_accuracy: 0.9783\n",
      "Epoch 1417/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.0979 - val_accuracy: 0.9783\n",
      "Epoch 1418/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0312 - accuracy: 0.9878 - val_loss: 0.0976 - val_accuracy: 0.9783\n",
      "Epoch 1419/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0302 - accuracy: 0.9872 - val_loss: 0.0976 - val_accuracy: 0.9783\n",
      "Epoch 1420/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.0990 - val_accuracy: 0.9783\n",
      "Epoch 1421/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0317 - accuracy: 0.9872 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 1422/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0287 - accuracy: 0.9885 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1423/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0296 - accuracy: 0.9885 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
      "Epoch 1424/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0310 - accuracy: 0.9872 - val_loss: 0.0953 - val_accuracy: 0.9783\n",
      "Epoch 1425/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.0947 - val_accuracy: 0.9814\n",
      "Epoch 1426/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.0945 - val_accuracy: 0.9814\n",
      "Epoch 1427/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 0.0960 - val_accuracy: 0.9783\n",
      "Epoch 1428/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0280 - accuracy: 0.9892 - val_loss: 0.1029 - val_accuracy: 0.9783\n",
      "Epoch 1429/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0345 - accuracy: 0.9861 - val_loss: 0.0974 - val_accuracy: 0.9783\n",
      "Epoch 1430/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0307 - accuracy: 0.9885 - val_loss: 0.0955 - val_accuracy: 0.9783\n",
      "Epoch 1431/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0963 - val_accuracy: 0.9783\n",
      "Epoch 1432/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0309 - accuracy: 0.9889 - val_loss: 0.1005 - val_accuracy: 0.9752\n",
      "Epoch 1433/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.0968 - val_accuracy: 0.9783\n",
      "Epoch 1434/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0293 - accuracy: 0.9889 - val_loss: 0.0967 - val_accuracy: 0.9814\n",
      "Epoch 1435/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0297 - accuracy: 0.9898 - val_loss: 0.0984 - val_accuracy: 0.9783\n",
      "Epoch 1436/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0296 - accuracy: 0.9855 - val_loss: 0.1169 - val_accuracy: 0.9720\n",
      "Epoch 1437/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0417 - accuracy: 0.9858 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
      "Epoch 1438/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.1042 - val_accuracy: 0.9814\n",
      "Epoch 1439/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0453 - accuracy: 0.9834 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1440/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0378 - accuracy: 0.9855 - val_loss: 0.1078 - val_accuracy: 0.9783\n",
      "Epoch 1441/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0401 - accuracy: 0.9855 - val_loss: 0.0963 - val_accuracy: 0.9783\n",
      "Epoch 1442/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0969 - val_accuracy: 0.9814\n",
      "Epoch 1443/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 0.9855 - val_loss: 0.0961 - val_accuracy: 0.9814\n",
      "Epoch 1444/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0275 - accuracy: 0.9888 - val_loss: 0.0998 - val_accuracy: 0.9783\n",
      "Epoch 1445/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0313 - accuracy: 0.9878 - val_loss: 0.1034 - val_accuracy: 0.9783\n",
      "Epoch 1446/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0329 - accuracy: 0.9875 - val_loss: 0.0968 - val_accuracy: 0.9783\n",
      "Epoch 1447/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0292 - accuracy: 0.9885 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 1448/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0324 - accuracy: 0.9885 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 1449/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0304 - accuracy: 0.9875 - val_loss: 0.0998 - val_accuracy: 0.9783\n",
      "Epoch 1450/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0290 - accuracy: 0.9878 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 1451/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0298 - accuracy: 0.9855 - val_loss: 0.0944 - val_accuracy: 0.9783\n",
      "Epoch 1452/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0324 - accuracy: 0.9872 - val_loss: 0.0938 - val_accuracy: 0.9783\n",
      "Epoch 1453/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0314 - accuracy: 0.9895 - val_loss: 0.0950 - val_accuracy: 0.9783\n",
      "Epoch 1454/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0302 - accuracy: 0.9889 - val_loss: 0.0993 - val_accuracy: 0.9814\n",
      "Epoch 1455/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.0972 - val_accuracy: 0.9783\n",
      "Epoch 1456/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.0956 - val_accuracy: 0.9783\n",
      "Epoch 1457/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.0966 - val_accuracy: 0.9752\n",
      "Epoch 1458/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0282 - accuracy: 0.9895 - val_loss: 0.1014 - val_accuracy: 0.9783\n",
      "Epoch 1459/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.1031 - val_accuracy: 0.9783\n",
      "Epoch 1460/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0319 - accuracy: 0.9855 - val_loss: 0.0993 - val_accuracy: 0.9814\n",
      "Epoch 1461/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0310 - accuracy: 0.9865 - val_loss: 0.0979 - val_accuracy: 0.9783\n",
      "Epoch 1462/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0287 - accuracy: 0.9892 - val_loss: 0.0978 - val_accuracy: 0.9783\n",
      "Epoch 1463/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0297 - accuracy: 0.9882 - val_loss: 0.0994 - val_accuracy: 0.9783\n",
      "Epoch 1464/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0301 - accuracy: 0.9855 - val_loss: 0.0993 - val_accuracy: 0.9783\n",
      "Epoch 1465/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0307 - accuracy: 0.9865 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 1466/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0293 - accuracy: 0.9889 - val_loss: 0.0954 - val_accuracy: 0.9783\n",
      "Epoch 1467/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.0962 - val_accuracy: 0.9783\n",
      "Epoch 1468/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 0.0960 - val_accuracy: 0.9783\n",
      "Epoch 1469/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0290 - accuracy: 0.9895 - val_loss: 0.0964 - val_accuracy: 0.9783\n",
      "Epoch 1470/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0312 - accuracy: 0.9889 - val_loss: 0.0969 - val_accuracy: 0.9752\n",
      "Epoch 1471/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0287 - accuracy: 0.9895 - val_loss: 0.1007 - val_accuracy: 0.9752\n",
      "Epoch 1472/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0290 - accuracy: 0.9895 - val_loss: 0.1025 - val_accuracy: 0.9783\n",
      "Epoch 1473/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0298 - accuracy: 0.9895 - val_loss: 0.0998 - val_accuracy: 0.9783\n",
      "Epoch 1474/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0296 - accuracy: 0.9885 - val_loss: 0.0990 - val_accuracy: 0.9814\n",
      "Epoch 1475/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0295 - accuracy: 0.9878 - val_loss: 0.0988 - val_accuracy: 0.9783\n",
      "Epoch 1476/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 1477/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0287 - accuracy: 0.9878 - val_loss: 0.0962 - val_accuracy: 0.9814\n",
      "Epoch 1478/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0300 - accuracy: 0.9905 - val_loss: 0.0961 - val_accuracy: 0.9814\n",
      "Epoch 1479/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.0988 - val_accuracy: 0.9783\n",
      "Epoch 1480/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.1024 - val_accuracy: 0.9814\n",
      "Epoch 1481/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0328 - accuracy: 0.9865 - val_loss: 0.0987 - val_accuracy: 0.9783\n",
      "Epoch 1482/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0287 - accuracy: 0.9895 - val_loss: 0.0983 - val_accuracy: 0.9783\n",
      "Epoch 1483/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0285 - accuracy: 0.9889 - val_loss: 0.1002 - val_accuracy: 0.9783\n",
      "Epoch 1484/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0288 - accuracy: 0.9895 - val_loss: 0.0997 - val_accuracy: 0.9783\n",
      "Epoch 1485/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0279 - accuracy: 0.9878 - val_loss: 0.0988 - val_accuracy: 0.9783\n",
      "Epoch 1486/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0303 - accuracy: 0.9878 - val_loss: 0.0986 - val_accuracy: 0.9783\n",
      "Epoch 1487/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.1016 - val_accuracy: 0.9783\n",
      "Epoch 1488/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0291 - accuracy: 0.9889 - val_loss: 0.0994 - val_accuracy: 0.9783\n",
      "Epoch 1489/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.0976 - val_accuracy: 0.9814\n",
      "Epoch 1490/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0295 - accuracy: 0.9892 - val_loss: 0.0962 - val_accuracy: 0.9814\n",
      "Epoch 1491/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.1002 - val_accuracy: 0.9783\n",
      "Epoch 1492/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0315 - accuracy: 0.9872 - val_loss: 0.1039 - val_accuracy: 0.9783\n",
      "Epoch 1493/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0332 - accuracy: 0.9878 - val_loss: 0.0975 - val_accuracy: 0.9783\n",
      "Epoch 1494/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0333 - accuracy: 0.9881 - val_loss: 0.0973 - val_accuracy: 0.9783\n",
      "Epoch 1495/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0293 - accuracy: 0.9878 - val_loss: 0.1032 - val_accuracy: 0.9783\n",
      "Epoch 1496/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0326 - accuracy: 0.9861 - val_loss: 0.1043 - val_accuracy: 0.9783\n",
      "Epoch 1497/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.1000 - val_accuracy: 0.9814\n",
      "Epoch 1498/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0350 - accuracy: 0.9851 - val_loss: 0.0996 - val_accuracy: 0.9814\n",
      "Epoch 1499/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0345 - accuracy: 0.9865 - val_loss: 0.1007 - val_accuracy: 0.9783\n",
      "Epoch 1500/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0274 - accuracy: 0.9902 - val_loss: 0.1039 - val_accuracy: 0.9783\n",
      "Epoch 1501/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0338 - accuracy: 0.9865 - val_loss: 0.0979 - val_accuracy: 0.9814\n",
      "Epoch 1502/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.0968 - val_accuracy: 0.9783\n",
      "Epoch 1503/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0302 - accuracy: 0.9895 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
      "Epoch 1504/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.1011 - val_accuracy: 0.9814\n",
      "Epoch 1505/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 0.0982 - val_accuracy: 0.9783\n",
      "Epoch 1506/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0287 - accuracy: 0.9872 - val_loss: 0.0976 - val_accuracy: 0.9814\n",
      "Epoch 1507/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0308 - accuracy: 0.9895 - val_loss: 0.0973 - val_accuracy: 0.9845\n",
      "Epoch 1508/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0296 - accuracy: 0.9855 - val_loss: 0.0976 - val_accuracy: 0.9783\n",
      "Epoch 1509/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0278 - accuracy: 0.9895 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1510/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0278 - accuracy: 0.9889 - val_loss: 0.0969 - val_accuracy: 0.9783\n",
      "Epoch 1511/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0297 - accuracy: 0.9889 - val_loss: 0.0977 - val_accuracy: 0.9783\n",
      "Epoch 1512/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0307 - accuracy: 0.9872 - val_loss: 0.0978 - val_accuracy: 0.9783\n",
      "Epoch 1513/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0289 - accuracy: 0.9889 - val_loss: 0.0983 - val_accuracy: 0.9783\n",
      "Epoch 1514/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.1022 - val_accuracy: 0.9783\n",
      "Epoch 1515/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0290 - accuracy: 0.9889 - val_loss: 0.1019 - val_accuracy: 0.9783\n",
      "Epoch 1516/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0269 - accuracy: 0.9885 - val_loss: 0.0993 - val_accuracy: 0.9814\n",
      "Epoch 1517/3500\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0269 - accuracy: 0.9885 - val_loss: 0.0980 - val_accuracy: 0.9814\n",
      "Epoch 1518/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 0.0978 - val_accuracy: 0.9783\n",
      "Epoch 1519/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0294 - accuracy: 0.9872 - val_loss: 0.1037 - val_accuracy: 0.9783\n",
      "Epoch 1520/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 1521/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0284 - accuracy: 0.9855 - val_loss: 0.0966 - val_accuracy: 0.9814\n",
      "Epoch 1522/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0265 - accuracy: 0.9919 - val_loss: 0.0990 - val_accuracy: 0.9783\n",
      "Epoch 1523/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0266 - accuracy: 0.9929 - val_loss: 0.1075 - val_accuracy: 0.9814\n",
      "Epoch 1524/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0341 - accuracy: 0.9872 - val_loss: 0.1017 - val_accuracy: 0.9783\n",
      "Epoch 1525/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0284 - accuracy: 0.9889 - val_loss: 0.0985 - val_accuracy: 0.9814\n",
      "Epoch 1526/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.9872 - val_loss: 0.0991 - val_accuracy: 0.9814\n",
      "Epoch 1527/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0310 - accuracy: 0.9865 - val_loss: 0.0996 - val_accuracy: 0.9783\n",
      "Epoch 1528/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.1046 - val_accuracy: 0.9783\n",
      "Epoch 1529/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0293 - accuracy: 0.9895 - val_loss: 0.0987 - val_accuracy: 0.9783\n",
      "Epoch 1530/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.0992 - val_accuracy: 0.9783\n",
      "Epoch 1531/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.0973 - val_accuracy: 0.9783\n",
      "Epoch 1532/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0280 - accuracy: 0.9922 - val_loss: 0.0990 - val_accuracy: 0.9752\n",
      "Epoch 1533/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.0966 - val_accuracy: 0.9783\n",
      "Epoch 1534/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 0.0952 - val_accuracy: 0.9814\n",
      "Epoch 1535/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0281 - accuracy: 0.9889 - val_loss: 0.0951 - val_accuracy: 0.9845\n",
      "Epoch 1536/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0294 - accuracy: 0.9882 - val_loss: 0.0951 - val_accuracy: 0.9845\n",
      "Epoch 1537/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0273 - accuracy: 0.9885 - val_loss: 0.0955 - val_accuracy: 0.9845\n",
      "Epoch 1538/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0275 - accuracy: 0.9895 - val_loss: 0.0986 - val_accuracy: 0.9783\n",
      "Epoch 1539/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0284 - accuracy: 0.9872 - val_loss: 0.0977 - val_accuracy: 0.9783\n",
      "Epoch 1540/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
      "Epoch 1541/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.9899 - val_loss: 0.0972 - val_accuracy: 0.9783\n",
      "Epoch 1542/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0296 - accuracy: 0.9889 - val_loss: 0.0974 - val_accuracy: 0.9814\n",
      "Epoch 1543/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0270 - accuracy: 0.9889 - val_loss: 0.1000 - val_accuracy: 0.9783\n",
      "Epoch 1544/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.0988 - val_accuracy: 0.9783\n",
      "Epoch 1545/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0281 - accuracy: 0.9902 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 1546/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0264 - accuracy: 0.9895 - val_loss: 0.1006 - val_accuracy: 0.9783\n",
      "Epoch 1547/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0266 - accuracy: 0.9895 - val_loss: 0.1057 - val_accuracy: 0.9783\n",
      "Epoch 1548/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0318 - accuracy: 0.9878 - val_loss: 0.0969 - val_accuracy: 0.9814\n",
      "Epoch 1549/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0270 - accuracy: 0.9939 - val_loss: 0.0971 - val_accuracy: 0.9814\n",
      "Epoch 1550/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0293 - accuracy: 0.9885 - val_loss: 0.0960 - val_accuracy: 0.9814\n",
      "Epoch 1551/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0259 - accuracy: 0.9868 - val_loss: 0.1034 - val_accuracy: 0.9783\n",
      "Epoch 1552/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0304 - accuracy: 0.9868 - val_loss: 0.0971 - val_accuracy: 0.9814\n",
      "Epoch 1553/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0269 - accuracy: 0.9871 - val_loss: 0.0977 - val_accuracy: 0.9783\n",
      "Epoch 1554/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0282 - accuracy: 0.9902 - val_loss: 0.1006 - val_accuracy: 0.9783\n",
      "Epoch 1555/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.1014 - val_accuracy: 0.9783\n",
      "Epoch 1556/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.0995 - val_accuracy: 0.9783\n",
      "Epoch 1557/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.0992 - val_accuracy: 0.9783\n",
      "Epoch 1558/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.1021 - val_accuracy: 0.9783\n",
      "Epoch 1559/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0269 - accuracy: 0.9892 - val_loss: 0.1019 - val_accuracy: 0.9783\n",
      "Epoch 1560/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9889 - val_loss: 0.0994 - val_accuracy: 0.9783\n",
      "Epoch 1561/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.0994 - val_accuracy: 0.9783\n",
      "Epoch 1562/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0261 - accuracy: 0.9885 - val_loss: 0.1059 - val_accuracy: 0.9814\n",
      "Epoch 1563/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0320 - accuracy: 0.9865 - val_loss: 0.1005 - val_accuracy: 0.9783\n",
      "Epoch 1564/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0268 - accuracy: 0.9878 - val_loss: 0.0975 - val_accuracy: 0.9814\n",
      "Epoch 1565/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.0992 - val_accuracy: 0.9783\n",
      "Epoch 1566/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.1039 - val_accuracy: 0.9752\n",
      "Epoch 1567/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0310 - accuracy: 0.9848 - val_loss: 0.1001 - val_accuracy: 0.9783\n",
      "Epoch 1568/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0260 - accuracy: 0.9922 - val_loss: 0.0994 - val_accuracy: 0.9814\n",
      "Epoch 1569/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0263 - accuracy: 0.9902 - val_loss: 0.0997 - val_accuracy: 0.9814\n",
      "Epoch 1570/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0269 - accuracy: 0.9889 - val_loss: 0.1058 - val_accuracy: 0.9814\n",
      "Epoch 1571/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0290 - accuracy: 0.9861 - val_loss: 0.1026 - val_accuracy: 0.9783\n",
      "Epoch 1572/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0283 - accuracy: 0.9861 - val_loss: 0.0986 - val_accuracy: 0.9814\n",
      "Epoch 1573/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0256 - accuracy: 0.9895 - val_loss: 0.0986 - val_accuracy: 0.9814\n",
      "Epoch 1574/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 0.0997 - val_accuracy: 0.9783\n",
      "Epoch 1575/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0255 - accuracy: 0.9905 - val_loss: 0.1022 - val_accuracy: 0.9814\n",
      "Epoch 1576/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0296 - accuracy: 0.9855 - val_loss: 0.1004 - val_accuracy: 0.9814\n",
      "Epoch 1577/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9895 - val_loss: 0.0994 - val_accuracy: 0.9845\n",
      "Epoch 1578/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0255 - accuracy: 0.9878 - val_loss: 0.1004 - val_accuracy: 0.9783\n",
      "Epoch 1579/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0262 - accuracy: 0.9909 - val_loss: 0.0984 - val_accuracy: 0.9814\n",
      "Epoch 1580/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0273 - accuracy: 0.9889 - val_loss: 0.1000 - val_accuracy: 0.9783\n",
      "Epoch 1581/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0327 - accuracy: 0.9858 - val_loss: 0.0971 - val_accuracy: 0.9783\n",
      "Epoch 1582/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.1092 - val_accuracy: 0.9783\n",
      "Epoch 1583/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0339 - accuracy: 0.9861 - val_loss: 0.1023 - val_accuracy: 0.9814\n",
      "Epoch 1584/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.0990 - val_accuracy: 0.9814\n",
      "Epoch 1585/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0324 - accuracy: 0.9872 - val_loss: 0.1001 - val_accuracy: 0.9814\n",
      "Epoch 1586/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0318 - accuracy: 0.9872 - val_loss: 0.0975 - val_accuracy: 0.9814\n",
      "Epoch 1587/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0258 - accuracy: 0.9858 - val_loss: 0.1028 - val_accuracy: 0.9783\n",
      "Epoch 1588/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.0966 - val_accuracy: 0.9783\n",
      "Epoch 1589/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0304 - accuracy: 0.9885 - val_loss: 0.0980 - val_accuracy: 0.9783\n",
      "Epoch 1590/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.1047 - val_accuracy: 0.9783\n",
      "Epoch 1591/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0319 - accuracy: 0.9855 - val_loss: 0.1069 - val_accuracy: 0.9814\n",
      "Epoch 1592/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0309 - accuracy: 0.9861 - val_loss: 0.0992 - val_accuracy: 0.9814\n",
      "Epoch 1593/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0288 - accuracy: 0.9861 - val_loss: 0.1002 - val_accuracy: 0.9783\n",
      "Epoch 1594/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.1034 - val_accuracy: 0.9752\n",
      "Epoch 1595/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0308 - accuracy: 0.9885 - val_loss: 0.1070 - val_accuracy: 0.9752\n",
      "Epoch 1596/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0301 - accuracy: 0.9872 - val_loss: 0.0996 - val_accuracy: 0.9783\n",
      "Epoch 1597/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.0993 - val_accuracy: 0.9783\n",
      "Epoch 1598/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0273 - accuracy: 0.9878 - val_loss: 0.1066 - val_accuracy: 0.9783\n",
      "Epoch 1599/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0306 - accuracy: 0.9861 - val_loss: 0.0999 - val_accuracy: 0.9783\n",
      "Epoch 1600/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0987 - val_accuracy: 0.9783\n",
      "Epoch 1601/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0293 - accuracy: 0.9889 - val_loss: 0.0977 - val_accuracy: 0.9783\n",
      "Epoch 1602/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0259 - accuracy: 0.9902 - val_loss: 0.1012 - val_accuracy: 0.9814\n",
      "Epoch 1603/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0290 - accuracy: 0.9865 - val_loss: 0.1006 - val_accuracy: 0.9783\n",
      "Epoch 1604/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0259 - accuracy: 0.9905 - val_loss: 0.0980 - val_accuracy: 0.9814\n",
      "Epoch 1605/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0262 - accuracy: 0.9895 - val_loss: 0.0984 - val_accuracy: 0.9814\n",
      "Epoch 1606/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.1010 - val_accuracy: 0.9783\n",
      "Epoch 1607/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0253 - accuracy: 0.9885 - val_loss: 0.1004 - val_accuracy: 0.9783\n",
      "Epoch 1608/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.0988 - val_accuracy: 0.9783\n",
      "Epoch 1609/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0244 - accuracy: 0.9912 - val_loss: 0.0991 - val_accuracy: 0.9814\n",
      "Epoch 1610/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0245 - accuracy: 0.9905 - val_loss: 0.1006 - val_accuracy: 0.9783\n",
      "Epoch 1611/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 0.0993 - val_accuracy: 0.9814\n",
      "Epoch 1612/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0269 - accuracy: 0.9889 - val_loss: 0.0980 - val_accuracy: 0.9814\n",
      "Epoch 1613/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0247 - accuracy: 0.9892 - val_loss: 0.0977 - val_accuracy: 0.9814\n",
      "Epoch 1614/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.1035 - val_accuracy: 0.9783\n",
      "Epoch 1615/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0280 - accuracy: 0.9878 - val_loss: 0.0978 - val_accuracy: 0.9814\n",
      "Epoch 1616/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.0980 - val_accuracy: 0.9783\n",
      "Epoch 1617/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0262 - accuracy: 0.9889 - val_loss: 0.0990 - val_accuracy: 0.9814\n",
      "Epoch 1618/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.1028 - val_accuracy: 0.9814\n",
      "Epoch 1619/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0258 - accuracy: 0.9895 - val_loss: 0.0988 - val_accuracy: 0.9845\n",
      "Epoch 1620/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.0999 - val_accuracy: 0.9814\n",
      "Epoch 1621/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0288 - accuracy: 0.9848 - val_loss: 0.0990 - val_accuracy: 0.9814\n",
      "Epoch 1622/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.1060 - val_accuracy: 0.9814\n",
      "Epoch 1623/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0304 - accuracy: 0.9855 - val_loss: 0.1026 - val_accuracy: 0.9783\n",
      "Epoch 1624/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9861 - val_loss: 0.0979 - val_accuracy: 0.9783\n",
      "Epoch 1625/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0270 - accuracy: 0.9899 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 1626/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0261 - accuracy: 0.9922 - val_loss: 0.0984 - val_accuracy: 0.9814\n",
      "Epoch 1627/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.0990 - val_accuracy: 0.9814\n",
      "Epoch 1628/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.0989 - val_accuracy: 0.9814\n",
      "Epoch 1629/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0991 - val_accuracy: 0.9814\n",
      "Epoch 1630/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.0992 - val_accuracy: 0.9783\n",
      "Epoch 1631/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.0999 - val_accuracy: 0.9814\n",
      "Epoch 1632/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.1027 - val_accuracy: 0.9783\n",
      "Epoch 1633/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.1001 - val_accuracy: 0.9814\n",
      "Epoch 1634/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0242 - accuracy: 0.9929 - val_loss: 0.0989 - val_accuracy: 0.9814\n",
      "Epoch 1635/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0983 - val_accuracy: 0.9783\n",
      "Epoch 1636/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0229 - accuracy: 0.9912 - val_loss: 0.0983 - val_accuracy: 0.9814\n",
      "Epoch 1637/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.0999 - val_accuracy: 0.9814\n",
      "Epoch 1638/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0258 - accuracy: 0.9899 - val_loss: 0.0985 - val_accuracy: 0.9814\n",
      "Epoch 1639/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.0991 - val_accuracy: 0.9783\n",
      "Epoch 1640/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0255 - accuracy: 0.9905 - val_loss: 0.1008 - val_accuracy: 0.9814\n",
      "Epoch 1641/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0249 - accuracy: 0.9902 - val_loss: 0.1004 - val_accuracy: 0.9814\n",
      "Epoch 1642/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.0991 - val_accuracy: 0.9783\n",
      "Epoch 1643/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0999 - val_accuracy: 0.9814\n",
      "Epoch 1644/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 0.1015 - val_accuracy: 0.9814\n",
      "Epoch 1645/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0245 - accuracy: 0.9895 - val_loss: 0.1005 - val_accuracy: 0.9814\n",
      "Epoch 1646/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0213 - accuracy: 0.9952 - val_loss: 0.0994 - val_accuracy: 0.9783\n",
      "Epoch 1647/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.9889 - val_loss: 0.0993 - val_accuracy: 0.9783\n",
      "Epoch 1648/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0226 - accuracy: 0.9912 - val_loss: 0.1008 - val_accuracy: 0.9814\n",
      "Epoch 1649/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.1045 - val_accuracy: 0.9814\n",
      "Epoch 1650/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0280 - accuracy: 0.9865 - val_loss: 0.0993 - val_accuracy: 0.9814\n",
      "Epoch 1651/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.0988 - val_accuracy: 0.9783\n",
      "Epoch 1652/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.0991 - val_accuracy: 0.9814\n",
      "Epoch 1653/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0234 - accuracy: 0.9895 - val_loss: 0.1002 - val_accuracy: 0.9814\n",
      "Epoch 1654/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 0.1006 - val_accuracy: 0.9814\n",
      "Epoch 1655/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 0.1004 - val_accuracy: 0.9814\n",
      "Epoch 1656/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 0.0999 - val_accuracy: 0.9814\n",
      "Epoch 1657/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 0.1011 - val_accuracy: 0.9814\n",
      "Epoch 1658/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.1021 - val_accuracy: 0.9814\n",
      "Epoch 1659/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.1017 - val_accuracy: 0.9814\n",
      "Epoch 1660/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.0999 - val_accuracy: 0.9814\n",
      "Epoch 1661/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.0997 - val_accuracy: 0.9845\n",
      "Epoch 1662/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0249 - accuracy: 0.9889 - val_loss: 0.1010 - val_accuracy: 0.9814\n",
      "Epoch 1663/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.1014 - val_accuracy: 0.9814\n",
      "Epoch 1664/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0236 - accuracy: 0.9912 - val_loss: 0.0993 - val_accuracy: 0.9783\n",
      "Epoch 1665/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.9895 - val_loss: 0.1004 - val_accuracy: 0.9783\n",
      "Epoch 1666/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0287 - accuracy: 0.9889 - val_loss: 0.0997 - val_accuracy: 0.9814\n",
      "Epoch 1667/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.1023 - val_accuracy: 0.9814\n",
      "Epoch 1668/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0249 - accuracy: 0.9889 - val_loss: 0.1001 - val_accuracy: 0.9814\n",
      "Epoch 1669/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 0.1003 - val_accuracy: 0.9783\n",
      "Epoch 1670/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0245 - accuracy: 0.9905 - val_loss: 0.1004 - val_accuracy: 0.9814\n",
      "Epoch 1671/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0229 - accuracy: 0.9946 - val_loss: 0.1023 - val_accuracy: 0.9814\n",
      "Epoch 1672/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0253 - accuracy: 0.9895 - val_loss: 0.0986 - val_accuracy: 0.9814\n",
      "Epoch 1673/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.0982 - val_accuracy: 0.9783\n",
      "Epoch 1674/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0234 - accuracy: 0.9912 - val_loss: 0.0986 - val_accuracy: 0.9814\n",
      "Epoch 1675/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.1054 - val_accuracy: 0.9814\n",
      "Epoch 1676/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0276 - accuracy: 0.9885 - val_loss: 0.0984 - val_accuracy: 0.9814\n",
      "Epoch 1677/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0241 - accuracy: 0.9902 - val_loss: 0.0981 - val_accuracy: 0.9783\n",
      "Epoch 1678/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 0.1004 - val_accuracy: 0.9814\n",
      "Epoch 1679/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0235 - accuracy: 0.9912 - val_loss: 0.1019 - val_accuracy: 0.9814\n",
      "Epoch 1680/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0235 - accuracy: 0.9889 - val_loss: 0.1006 - val_accuracy: 0.9845\n",
      "Epoch 1681/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.9905 - val_loss: 0.1003 - val_accuracy: 0.9814\n",
      "Epoch 1682/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0997 - val_accuracy: 0.9814\n",
      "Epoch 1683/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0226 - accuracy: 0.9922 - val_loss: 0.0994 - val_accuracy: 0.9814\n",
      "Epoch 1684/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0228 - accuracy: 0.9902 - val_loss: 0.1001 - val_accuracy: 0.9814\n",
      "Epoch 1685/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.1023 - val_accuracy: 0.9814\n",
      "Epoch 1686/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.1006 - val_accuracy: 0.9814\n",
      "Epoch 1687/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.1010 - val_accuracy: 0.9814\n",
      "Epoch 1688/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0272 - accuracy: 0.9872 - val_loss: 0.1012 - val_accuracy: 0.9814\n",
      "Epoch 1689/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.1027 - val_accuracy: 0.9783\n",
      "Epoch 1690/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0250 - accuracy: 0.9882 - val_loss: 0.1040 - val_accuracy: 0.9783\n",
      "Epoch 1691/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0245 - accuracy: 0.9895 - val_loss: 0.1008 - val_accuracy: 0.9814\n",
      "Epoch 1692/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.1010 - val_accuracy: 0.9783\n",
      "Epoch 1693/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0267 - accuracy: 0.9899 - val_loss: 0.1006 - val_accuracy: 0.9814\n",
      "Epoch 1694/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0226 - accuracy: 0.9919 - val_loss: 0.1057 - val_accuracy: 0.9752\n",
      "Epoch 1695/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0256 - accuracy: 0.9902 - val_loss: 0.1030 - val_accuracy: 0.9814\n",
      "Epoch 1696/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.1001 - val_accuracy: 0.9783\n",
      "Epoch 1697/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.1001 - val_accuracy: 0.9783\n",
      "Epoch 1698/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.1005 - val_accuracy: 0.9814\n",
      "Epoch 1699/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0238 - accuracy: 0.9949 - val_loss: 0.1035 - val_accuracy: 0.9814\n",
      "Epoch 1700/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0249 - accuracy: 0.9889 - val_loss: 0.1017 - val_accuracy: 0.9814\n",
      "Epoch 1701/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.1013 - val_accuracy: 0.9814\n",
      "Epoch 1702/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.1022 - val_accuracy: 0.9814\n",
      "Epoch 1703/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.1018 - val_accuracy: 0.9814\n",
      "Epoch 1704/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.1011 - val_accuracy: 0.9783\n",
      "Epoch 1705/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0257 - accuracy: 0.9899 - val_loss: 0.1002 - val_accuracy: 0.9783\n",
      "Epoch 1706/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0233 - accuracy: 0.9905 - val_loss: 0.1024 - val_accuracy: 0.9814\n",
      "Epoch 1707/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0243 - accuracy: 0.9885 - val_loss: 0.1007 - val_accuracy: 0.9814\n",
      "Epoch 1708/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0242 - accuracy: 0.9905 - val_loss: 0.0998 - val_accuracy: 0.9783\n",
      "Epoch 1709/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.0991 - val_accuracy: 0.9783\n",
      "Epoch 1710/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.1002 - val_accuracy: 0.9814\n",
      "Epoch 1711/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0231 - accuracy: 0.9916 - val_loss: 0.1016 - val_accuracy: 0.9814\n",
      "Epoch 1712/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0225 - accuracy: 0.9922 - val_loss: 0.1001 - val_accuracy: 0.9814\n",
      "Epoch 1713/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0216 - accuracy: 0.9946 - val_loss: 0.1003 - val_accuracy: 0.9814\n",
      "Epoch 1714/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0234 - accuracy: 0.9905 - val_loss: 0.1006 - val_accuracy: 0.9845\n",
      "Epoch 1715/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 0.1011 - val_accuracy: 0.9845\n",
      "Epoch 1716/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.1013 - val_accuracy: 0.9814\n",
      "Epoch 1717/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.1000 - val_accuracy: 0.9814\n",
      "Epoch 1718/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.1003 - val_accuracy: 0.9814\n",
      "Epoch 1719/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0242 - accuracy: 0.9905 - val_loss: 0.1036 - val_accuracy: 0.9783\n",
      "Epoch 1720/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0245 - accuracy: 0.9895 - val_loss: 0.1004 - val_accuracy: 0.9814\n",
      "Epoch 1721/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0215 - accuracy: 0.9952 - val_loss: 0.0999 - val_accuracy: 0.9814\n",
      "Epoch 1722/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0226 - accuracy: 0.9912 - val_loss: 0.1012 - val_accuracy: 0.9814\n",
      "Epoch 1723/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0243 - accuracy: 0.9882 - val_loss: 0.1024 - val_accuracy: 0.9814\n",
      "Epoch 1724/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0234 - accuracy: 0.9895 - val_loss: 0.0991 - val_accuracy: 0.9814\n",
      "Epoch 1725/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0221 - accuracy: 0.9912 - val_loss: 0.0999 - val_accuracy: 0.9783\n",
      "Epoch 1726/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.9912 - val_loss: 0.0994 - val_accuracy: 0.9814\n",
      "Epoch 1727/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 0.1012 - val_accuracy: 0.9814\n",
      "Epoch 1728/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0222 - accuracy: 0.9919 - val_loss: 0.1011 - val_accuracy: 0.9814\n",
      "Epoch 1729/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0220 - accuracy: 0.9949 - val_loss: 0.1018 - val_accuracy: 0.9783\n",
      "Epoch 1730/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.1019 - val_accuracy: 0.9783\n",
      "Epoch 1731/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.1043 - val_accuracy: 0.9814\n",
      "Epoch 1732/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0236 - accuracy: 0.9889 - val_loss: 0.1044 - val_accuracy: 0.9814\n",
      "Epoch 1733/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0233 - accuracy: 0.9905 - val_loss: 0.1019 - val_accuracy: 0.9814\n",
      "Epoch 1734/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.1014 - val_accuracy: 0.9814\n",
      "Epoch 1735/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.1015 - val_accuracy: 0.9814\n",
      "Epoch 1736/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 0.1003 - val_accuracy: 0.9814\n",
      "Epoch 1737/3500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0218 - accuracy: 0.9912 - val_loss: 0.1006 - val_accuracy: 0.9783\n",
      "Epoch 1738/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 0.1014 - val_accuracy: 0.9814\n",
      "Epoch 1739/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0207 - accuracy: 0.9946 - val_loss: 0.1044 - val_accuracy: 0.9814\n",
      "Epoch 1740/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0237 - accuracy: 0.9868 - val_loss: 0.1022 - val_accuracy: 0.9845\n",
      "Epoch 1741/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0222 - accuracy: 0.9919 - val_loss: 0.1062 - val_accuracy: 0.9814\n",
      "Epoch 1742/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0310 - accuracy: 0.9865 - val_loss: 0.1032 - val_accuracy: 0.9814\n",
      "Epoch 1743/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0237 - accuracy: 0.9882 - val_loss: 0.1071 - val_accuracy: 0.9783\n",
      "Epoch 1744/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.1044 - val_accuracy: 0.9783\n",
      "Epoch 1745/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.1032 - val_accuracy: 0.9783\n",
      "Epoch 1746/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0236 - accuracy: 0.9905 - val_loss: 0.1034 - val_accuracy: 0.9783\n",
      "Epoch 1747/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0246 - accuracy: 0.9899 - val_loss: 0.1039 - val_accuracy: 0.9814\n",
      "Epoch 1748/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0231 - accuracy: 0.9916 - val_loss: 0.1058 - val_accuracy: 0.9783\n",
      "Epoch 1749/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0222 - accuracy: 0.9902 - val_loss: 0.1032 - val_accuracy: 0.9814\n",
      "Epoch 1750/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.1045 - val_accuracy: 0.9814\n",
      "Epoch 1751/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.1035 - val_accuracy: 0.9814\n",
      "Epoch 1752/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0236 - accuracy: 0.9949 - val_loss: 0.1097 - val_accuracy: 0.9814\n",
      "Epoch 1753/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0255 - accuracy: 0.9872 - val_loss: 0.1032 - val_accuracy: 0.9845\n",
      "Epoch 1754/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0235 - accuracy: 0.9905 - val_loss: 0.1052 - val_accuracy: 0.9814\n",
      "Epoch 1755/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0280 - accuracy: 0.9872 - val_loss: 0.1022 - val_accuracy: 0.9814\n",
      "Epoch 1756/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.1085 - val_accuracy: 0.9752\n",
      "Epoch 1757/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0264 - accuracy: 0.9872 - val_loss: 0.1045 - val_accuracy: 0.9783\n",
      "Epoch 1758/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0222 - accuracy: 0.9912 - val_loss: 0.1026 - val_accuracy: 0.9783\n",
      "Epoch 1759/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0232 - accuracy: 0.9916 - val_loss: 0.1035 - val_accuracy: 0.9814\n",
      "Epoch 1760/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0269 - accuracy: 0.9889 - val_loss: 0.1032 - val_accuracy: 0.9845\n",
      "Epoch 1761/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0239 - accuracy: 0.9902 - val_loss: 0.1032 - val_accuracy: 0.9845\n",
      "Epoch 1762/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0227 - accuracy: 0.9878 - val_loss: 0.1025 - val_accuracy: 0.9814\n",
      "Epoch 1763/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0206 - accuracy: 0.9922 - val_loss: 0.1041 - val_accuracy: 0.9783\n",
      "Epoch 1764/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0224 - accuracy: 0.9946 - val_loss: 0.1044 - val_accuracy: 0.9814\n",
      "Epoch 1765/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.1034 - val_accuracy: 0.9814\n",
      "Epoch 1766/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0208 - accuracy: 0.9949 - val_loss: 0.1039 - val_accuracy: 0.9845\n",
      "Epoch 1767/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.1036 - val_accuracy: 0.9845\n",
      "Epoch 1768/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0221 - accuracy: 0.9916 - val_loss: 0.1051 - val_accuracy: 0.9783\n",
      "Epoch 1769/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0224 - accuracy: 0.9919 - val_loss: 0.1045 - val_accuracy: 0.9783\n",
      "Epoch 1770/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.1024 - val_accuracy: 0.9752\n",
      "Epoch 1771/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.1004 - val_accuracy: 0.9783\n",
      "Epoch 1772/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.1034 - val_accuracy: 0.9814\n",
      "Epoch 1773/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0244 - accuracy: 0.9875 - val_loss: 0.1019 - val_accuracy: 0.9845\n",
      "Epoch 1774/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0226 - accuracy: 0.9895 - val_loss: 0.1018 - val_accuracy: 0.9814\n",
      "Epoch 1775/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0280 - accuracy: 0.9889 - val_loss: 0.1014 - val_accuracy: 0.9783\n",
      "Epoch 1776/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 0.1026 - val_accuracy: 0.9783\n",
      "Epoch 1777/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0221 - accuracy: 0.9905 - val_loss: 0.1124 - val_accuracy: 0.9752\n",
      "Epoch 1778/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0297 - accuracy: 0.9868 - val_loss: 0.1012 - val_accuracy: 0.9814\n",
      "Epoch 1779/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.1099 - val_accuracy: 0.9814\n",
      "Epoch 1780/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0377 - accuracy: 0.9811 - val_loss: 0.1034 - val_accuracy: 0.9783\n",
      "Epoch 1781/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0243 - accuracy: 0.9905 - val_loss: 0.1174 - val_accuracy: 0.9752\n",
      "Epoch 1782/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0328 - accuracy: 0.9855 - val_loss: 0.1062 - val_accuracy: 0.9814\n",
      "Epoch 1783/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0238 - accuracy: 0.9899 - val_loss: 0.1123 - val_accuracy: 0.9814\n",
      "Epoch 1784/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0382 - accuracy: 0.9821 - val_loss: 0.1074 - val_accuracy: 0.9814\n",
      "Epoch 1785/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.1118 - val_accuracy: 0.9814\n",
      "Epoch 1786/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0282 - accuracy: 0.9872 - val_loss: 0.1137 - val_accuracy: 0.9814\n",
      "Epoch 1787/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0299 - accuracy: 0.9848 - val_loss: 0.1051 - val_accuracy: 0.9783\n",
      "Epoch 1788/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.1055 - val_accuracy: 0.9783\n",
      "Epoch 1789/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0233 - accuracy: 0.9905 - val_loss: 0.1083 - val_accuracy: 0.9752\n",
      "Epoch 1790/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0221 - accuracy: 0.9905 - val_loss: 0.1126 - val_accuracy: 0.9752\n",
      "Epoch 1791/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0258 - accuracy: 0.9865 - val_loss: 0.1098 - val_accuracy: 0.9783\n",
      "Epoch 1792/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0221 - accuracy: 0.9912 - val_loss: 0.1074 - val_accuracy: 0.9814\n",
      "Epoch 1793/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.1082 - val_accuracy: 0.9814\n",
      "Epoch 1794/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0242 - accuracy: 0.9878 - val_loss: 0.1059 - val_accuracy: 0.9783\n",
      "Epoch 1795/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.1088 - val_accuracy: 0.9783\n",
      "Epoch 1796/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0225 - accuracy: 0.9895 - val_loss: 0.1047 - val_accuracy: 0.9814\n",
      "Epoch 1797/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0213 - accuracy: 0.9912 - val_loss: 0.1055 - val_accuracy: 0.9814\n",
      "Epoch 1798/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.1035 - val_accuracy: 0.9814\n",
      "Epoch 1799/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 0.1128 - val_accuracy: 0.9752\n",
      "Epoch 1800/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0291 - accuracy: 0.9855 - val_loss: 0.1040 - val_accuracy: 0.9814\n",
      "Epoch 1801/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0219 - accuracy: 0.9905 - val_loss: 0.1017 - val_accuracy: 0.9783\n",
      "Epoch 1802/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0230 - accuracy: 0.9949 - val_loss: 0.1014 - val_accuracy: 0.9814\n",
      "Epoch 1803/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.1016 - val_accuracy: 0.9814\n",
      "Epoch 1804/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0208 - accuracy: 0.9966 - val_loss: 0.1026 - val_accuracy: 0.9814\n",
      "Epoch 1805/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0226 - accuracy: 0.9916 - val_loss: 0.1020 - val_accuracy: 0.9814\n",
      "Epoch 1806/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0198 - accuracy: 0.9956 - val_loss: 0.1015 - val_accuracy: 0.9752\n",
      "Epoch 1807/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0224 - accuracy: 0.9949 - val_loss: 0.1027 - val_accuracy: 0.9752\n",
      "Epoch 1808/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0248 - accuracy: 0.9932 - val_loss: 0.1017 - val_accuracy: 0.9783\n",
      "Epoch 1809/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.1041 - val_accuracy: 0.9783\n",
      "Epoch 1810/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0222 - accuracy: 0.9919 - val_loss: 0.1038 - val_accuracy: 0.9783\n",
      "Epoch 1811/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.1043 - val_accuracy: 0.9752\n",
      "Epoch 1812/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.1046 - val_accuracy: 0.9814\n",
      "Epoch 1813/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.1073 - val_accuracy: 0.9814\n",
      "Epoch 1814/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.1054 - val_accuracy: 0.9783\n",
      "Epoch 1815/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.1061 - val_accuracy: 0.9814\n",
      "Epoch 1816/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 0.1056 - val_accuracy: 0.9783\n",
      "Epoch 1817/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.1052 - val_accuracy: 0.9814\n",
      "Epoch 1818/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.1054 - val_accuracy: 0.9814\n",
      "Epoch 1819/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0201 - accuracy: 0.9946 - val_loss: 0.1039 - val_accuracy: 0.9783\n",
      "Epoch 1820/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0207 - accuracy: 0.9956 - val_loss: 0.1045 - val_accuracy: 0.9783\n",
      "Epoch 1821/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 0.1033 - val_accuracy: 0.9814\n",
      "Epoch 1822/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.1052 - val_accuracy: 0.9783\n",
      "Epoch 1823/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.1029 - val_accuracy: 0.9814\n",
      "Epoch 1824/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 0.1027 - val_accuracy: 0.9783\n",
      "Epoch 1825/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0207 - accuracy: 0.9956 - val_loss: 0.1025 - val_accuracy: 0.9783\n",
      "Epoch 1826/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0207 - accuracy: 0.9956 - val_loss: 0.1028 - val_accuracy: 0.9783\n",
      "Epoch 1827/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.9973 - val_loss: 0.1040 - val_accuracy: 0.9783\n",
      "Epoch 1828/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0194 - accuracy: 0.9966 - val_loss: 0.1036 - val_accuracy: 0.9783\n",
      "Epoch 1829/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.1038 - val_accuracy: 0.9783\n",
      "Epoch 1830/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0213 - accuracy: 0.9949 - val_loss: 0.1047 - val_accuracy: 0.9783\n",
      "Epoch 1831/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0202 - accuracy: 0.9956 - val_loss: 0.1048 - val_accuracy: 0.9783\n",
      "Epoch 1832/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 0.1042 - val_accuracy: 0.9783\n",
      "Epoch 1833/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0206 - accuracy: 0.9912 - val_loss: 0.1046 - val_accuracy: 0.9783\n",
      "Epoch 1834/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0199 - accuracy: 0.9973 - val_loss: 0.1036 - val_accuracy: 0.9783\n",
      "Epoch 1835/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.1036 - val_accuracy: 0.9752\n",
      "Epoch 1836/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0220 - accuracy: 0.9949 - val_loss: 0.1036 - val_accuracy: 0.9783\n",
      "Epoch 1837/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.1048 - val_accuracy: 0.9783\n",
      "Epoch 1838/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.1074 - val_accuracy: 0.9783\n",
      "Epoch 1839/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 0.1046 - val_accuracy: 0.9783\n",
      "Epoch 1840/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.1058 - val_accuracy: 0.9752\n",
      "Epoch 1841/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.1063 - val_accuracy: 0.9752\n",
      "Epoch 1842/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.1091 - val_accuracy: 0.9752\n",
      "Epoch 1843/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0228 - accuracy: 0.9912 - val_loss: 0.1072 - val_accuracy: 0.9783\n",
      "Epoch 1844/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.1090 - val_accuracy: 0.9783\n",
      "Epoch 1845/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.1075 - val_accuracy: 0.9783\n",
      "Epoch 1846/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0191 - accuracy: 0.9956 - val_loss: 0.1158 - val_accuracy: 0.9814\n",
      "Epoch 1847/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.1081 - val_accuracy: 0.9783\n",
      "Epoch 1848/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.1068 - val_accuracy: 0.9752\n",
      "Epoch 1849/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0200 - accuracy: 0.9973 - val_loss: 0.1061 - val_accuracy: 0.9783\n",
      "Epoch 1850/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0188 - accuracy: 0.9956 - val_loss: 0.1078 - val_accuracy: 0.9783\n",
      "Epoch 1851/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 0.1068 - val_accuracy: 0.9783\n",
      "Epoch 1852/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0202 - accuracy: 0.9946 - val_loss: 0.1088 - val_accuracy: 0.9783\n",
      "Epoch 1853/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.1091 - val_accuracy: 0.9783\n",
      "Epoch 1854/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.1171 - val_accuracy: 0.9720\n",
      "Epoch 1855/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0288 - accuracy: 0.9889 - val_loss: 0.1072 - val_accuracy: 0.9752\n",
      "Epoch 1856/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0221 - accuracy: 0.9963 - val_loss: 0.1071 - val_accuracy: 0.9752\n",
      "Epoch 1857/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0206 - accuracy: 0.9963 - val_loss: 0.1104 - val_accuracy: 0.9814\n",
      "Epoch 1858/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 0.1089 - val_accuracy: 0.9814\n",
      "Epoch 1859/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0226 - accuracy: 0.9902 - val_loss: 0.1055 - val_accuracy: 0.9783\n",
      "Epoch 1860/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.1049 - val_accuracy: 0.9783\n",
      "Epoch 1861/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0197 - accuracy: 0.9956 - val_loss: 0.1044 - val_accuracy: 0.9783\n",
      "Epoch 1862/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.1078 - val_accuracy: 0.9783\n",
      "Epoch 1863/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0217 - accuracy: 0.9909 - val_loss: 0.1046 - val_accuracy: 0.9783\n",
      "Epoch 1864/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.1063 - val_accuracy: 0.9752\n",
      "Epoch 1865/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.1033 - val_accuracy: 0.9752\n",
      "Epoch 1866/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0192 - accuracy: 0.9983 - val_loss: 0.1114 - val_accuracy: 0.9752\n",
      "Epoch 1867/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 0.1044 - val_accuracy: 0.9783\n",
      "Epoch 1868/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.1098 - val_accuracy: 0.9783\n",
      "Epoch 1869/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0298 - accuracy: 0.9889 - val_loss: 0.1053 - val_accuracy: 0.9783\n",
      "Epoch 1870/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 0.1119 - val_accuracy: 0.9752\n",
      "Epoch 1871/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0264 - accuracy: 0.9909 - val_loss: 0.1063 - val_accuracy: 0.9752\n",
      "Epoch 1872/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0235 - accuracy: 0.9902 - val_loss: 0.1109 - val_accuracy: 0.9783\n",
      "Epoch 1873/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0295 - accuracy: 0.9872 - val_loss: 0.1074 - val_accuracy: 0.9752\n",
      "Epoch 1874/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.1145 - val_accuracy: 0.9783\n",
      "Epoch 1875/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.1055 - val_accuracy: 0.9783\n",
      "Epoch 1876/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0181 - accuracy: 0.9929 - val_loss: 0.1059 - val_accuracy: 0.9814\n",
      "Epoch 1877/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.1062 - val_accuracy: 0.9814\n",
      "Epoch 1878/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.1064 - val_accuracy: 0.9783\n",
      "Epoch 1879/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.1055 - val_accuracy: 0.9783\n",
      "Epoch 1880/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.1071 - val_accuracy: 0.9720\n",
      "Epoch 1881/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 0.1065 - val_accuracy: 0.9720\n",
      "Epoch 1882/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.1043 - val_accuracy: 0.9752\n",
      "Epoch 1883/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.1033 - val_accuracy: 0.9783\n",
      "Epoch 1884/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.1034 - val_accuracy: 0.9783\n",
      "Epoch 1885/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.1032 - val_accuracy: 0.9783\n",
      "Epoch 1886/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.1044 - val_accuracy: 0.9752\n",
      "Epoch 1887/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0184 - accuracy: 0.9973 - val_loss: 0.1051 - val_accuracy: 0.9783\n",
      "Epoch 1888/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0182 - accuracy: 0.9973 - val_loss: 0.1067 - val_accuracy: 0.9783\n",
      "Epoch 1889/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.1052 - val_accuracy: 0.9783\n",
      "Epoch 1890/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0178 - accuracy: 0.9973 - val_loss: 0.1058 - val_accuracy: 0.9783\n",
      "Epoch 1891/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.1050 - val_accuracy: 0.9814\n",
      "Epoch 1892/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 0.1086 - val_accuracy: 0.9783\n",
      "Epoch 1893/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.1069 - val_accuracy: 0.9783\n",
      "Epoch 1894/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 0.1069 - val_accuracy: 0.9783\n",
      "Epoch 1895/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0183 - accuracy: 0.9956 - val_loss: 0.1068 - val_accuracy: 0.9783\n",
      "Epoch 1896/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0188 - accuracy: 0.9983 - val_loss: 0.1062 - val_accuracy: 0.9814\n",
      "Epoch 1897/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.1064 - val_accuracy: 0.9814\n",
      "Epoch 1898/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.1064 - val_accuracy: 0.9783\n",
      "Epoch 1899/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.1059 - val_accuracy: 0.9783\n",
      "Epoch 1900/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.1058 - val_accuracy: 0.9783\n",
      "Epoch 1901/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0168 - accuracy: 0.9983 - val_loss: 0.1061 - val_accuracy: 0.9752\n",
      "Epoch 1902/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0171 - accuracy: 0.9980 - val_loss: 0.1061 - val_accuracy: 0.9783\n",
      "Epoch 1903/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0178 - accuracy: 0.9956 - val_loss: 0.1123 - val_accuracy: 0.9783\n",
      "Epoch 1904/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0214 - accuracy: 0.9902 - val_loss: 0.1065 - val_accuracy: 0.9783\n",
      "Epoch 1905/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 1906/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 0.1062 - val_accuracy: 0.9752\n",
      "Epoch 1907/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0199 - accuracy: 0.9946 - val_loss: 0.1077 - val_accuracy: 0.9783\n",
      "Epoch 1908/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.1060 - val_accuracy: 0.9783\n",
      "Epoch 1909/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0179 - accuracy: 0.9973 - val_loss: 0.1049 - val_accuracy: 0.9783\n",
      "Epoch 1910/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.1051 - val_accuracy: 0.9783\n",
      "Epoch 1911/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0157 - accuracy: 0.9980 - val_loss: 0.1062 - val_accuracy: 0.9783\n",
      "Epoch 1912/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0180 - accuracy: 0.9966 - val_loss: 0.1060 - val_accuracy: 0.9783\n",
      "Epoch 1913/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.1064 - val_accuracy: 0.9752\n",
      "Epoch 1914/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.1062 - val_accuracy: 0.9783\n",
      "Epoch 1915/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.1072 - val_accuracy: 0.9783\n",
      "Epoch 1916/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.1064 - val_accuracy: 0.9783\n",
      "Epoch 1917/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.1057 - val_accuracy: 0.9783\n",
      "Epoch 1918/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0177 - accuracy: 0.9966 - val_loss: 0.1057 - val_accuracy: 0.9783\n",
      "Epoch 1919/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0173 - accuracy: 0.9973 - val_loss: 0.1065 - val_accuracy: 0.9783\n",
      "Epoch 1920/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0181 - accuracy: 0.9952 - val_loss: 0.1062 - val_accuracy: 0.9783\n",
      "Epoch 1921/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0184 - accuracy: 0.9966 - val_loss: 0.1097 - val_accuracy: 0.9814\n",
      "Epoch 1922/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.1067 - val_accuracy: 0.9783\n",
      "Epoch 1923/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0150 - accuracy: 0.9990 - val_loss: 0.1135 - val_accuracy: 0.9814\n",
      "Epoch 1924/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0217 - accuracy: 0.9902 - val_loss: 0.1084 - val_accuracy: 0.9783\n",
      "Epoch 1925/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0162 - accuracy: 0.9966 - val_loss: 0.1122 - val_accuracy: 0.9814\n",
      "Epoch 1926/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.1097 - val_accuracy: 0.9814\n",
      "Epoch 1927/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0214 - accuracy: 0.9956 - val_loss: 0.1082 - val_accuracy: 0.9783\n",
      "Epoch 1928/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0191 - accuracy: 0.9946 - val_loss: 0.1132 - val_accuracy: 0.9814\n",
      "Epoch 1929/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 0.1060 - val_accuracy: 0.9783\n",
      "Epoch 1930/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.1092 - val_accuracy: 0.9752\n",
      "Epoch 1931/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.1065 - val_accuracy: 0.9783\n",
      "Epoch 1932/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.1090 - val_accuracy: 0.9783\n",
      "Epoch 1933/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0175 - accuracy: 0.9956 - val_loss: 0.1074 - val_accuracy: 0.9783\n",
      "Epoch 1934/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.1094 - val_accuracy: 0.9752\n",
      "Epoch 1935/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0189 - accuracy: 0.9963 - val_loss: 0.1085 - val_accuracy: 0.9783\n",
      "Epoch 1936/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0161 - accuracy: 0.9929 - val_loss: 0.1148 - val_accuracy: 0.9783\n",
      "Epoch 1937/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0226 - accuracy: 0.9905 - val_loss: 0.1091 - val_accuracy: 0.9783\n",
      "Epoch 1938/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.1095 - val_accuracy: 0.9752\n",
      "Epoch 1939/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 0.1072 - val_accuracy: 0.9783\n",
      "Epoch 1940/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.1073 - val_accuracy: 0.9783\n",
      "Epoch 1941/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0181 - accuracy: 0.9966 - val_loss: 0.1074 - val_accuracy: 0.9783\n",
      "Epoch 1942/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.1068 - val_accuracy: 0.9783\n",
      "Epoch 1943/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.1072 - val_accuracy: 0.9783\n",
      "Epoch 1944/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.1074 - val_accuracy: 0.9783\n",
      "Epoch 1945/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 0.1077 - val_accuracy: 0.9783\n",
      "Epoch 1946/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.1070 - val_accuracy: 0.9783\n",
      "Epoch 1947/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0152 - accuracy: 0.9973 - val_loss: 0.1084 - val_accuracy: 0.9783\n",
      "Epoch 1948/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.1090 - val_accuracy: 0.9783\n",
      "Epoch 1949/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.1082 - val_accuracy: 0.9783\n",
      "Epoch 1950/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.1086 - val_accuracy: 0.9783\n",
      "Epoch 1951/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.1108 - val_accuracy: 0.9783\n",
      "Epoch 1952/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 0.1210 - val_accuracy: 0.9689\n",
      "Epoch 1953/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.1064 - val_accuracy: 0.9752\n",
      "Epoch 1954/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0199 - accuracy: 0.9956 - val_loss: 0.1111 - val_accuracy: 0.9814\n",
      "Epoch 1955/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.1048 - val_accuracy: 0.9783\n",
      "Epoch 1956/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.1107 - val_accuracy: 0.9752\n",
      "Epoch 1957/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0201 - accuracy: 0.9929 - val_loss: 0.1041 - val_accuracy: 0.9783\n",
      "Epoch 1958/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.1054 - val_accuracy: 0.9752\n",
      "Epoch 1959/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 0.1030 - val_accuracy: 0.9752\n",
      "Epoch 1960/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.1054 - val_accuracy: 0.9814\n",
      "Epoch 1961/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.1024 - val_accuracy: 0.9783\n",
      "Epoch 1962/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.1024 - val_accuracy: 0.9814\n",
      "Epoch 1963/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.1032 - val_accuracy: 0.9752\n",
      "Epoch 1964/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.1037 - val_accuracy: 0.9752\n",
      "Epoch 1965/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.1070 - val_accuracy: 0.9752\n",
      "Epoch 1966/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0171 - accuracy: 0.9936 - val_loss: 0.1059 - val_accuracy: 0.9752\n",
      "Epoch 1967/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.1062 - val_accuracy: 0.9752\n",
      "Epoch 1968/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.1064 - val_accuracy: 0.9783\n",
      "Epoch 1969/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.1089 - val_accuracy: 0.9783\n",
      "Epoch 1970/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.1091 - val_accuracy: 0.9783\n",
      "Epoch 1971/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.1081 - val_accuracy: 0.9752\n",
      "Epoch 1972/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.1098 - val_accuracy: 0.9783\n",
      "Epoch 1973/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0187 - accuracy: 0.9956 - val_loss: 0.1090 - val_accuracy: 0.9752\n",
      "Epoch 1974/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.1123 - val_accuracy: 0.9752\n",
      "Epoch 1975/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.1096 - val_accuracy: 0.9783\n",
      "Epoch 1976/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.1106 - val_accuracy: 0.9783\n",
      "Epoch 1977/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.1097 - val_accuracy: 0.9783\n",
      "Epoch 1978/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0159 - accuracy: 0.9966 - val_loss: 0.1100 - val_accuracy: 0.9783\n",
      "Epoch 1979/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0158 - accuracy: 0.9973 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 1980/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.1090 - val_accuracy: 0.9783\n",
      "Epoch 1981/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0171 - accuracy: 0.9966 - val_loss: 0.1078 - val_accuracy: 0.9783\n",
      "Epoch 1982/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.1079 - val_accuracy: 0.9783\n",
      "Epoch 1983/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0157 - accuracy: 0.9983 - val_loss: 0.1099 - val_accuracy: 0.9814\n",
      "Epoch 1984/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.1102 - val_accuracy: 0.9814\n",
      "Epoch 1985/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.1080 - val_accuracy: 0.9783\n",
      "Epoch 1986/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0161 - accuracy: 0.9973 - val_loss: 0.1082 - val_accuracy: 0.9783\n",
      "Epoch 1987/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.1106 - val_accuracy: 0.9783\n",
      "Epoch 1988/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 0.1092 - val_accuracy: 0.9783\n",
      "Epoch 1989/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.1092 - val_accuracy: 0.9814\n",
      "Epoch 1990/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 1991/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.1106 - val_accuracy: 0.9783\n",
      "Epoch 1992/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 0.1131 - val_accuracy: 0.9783\n",
      "Epoch 1993/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1107 - val_accuracy: 0.9783\n",
      "Epoch 1994/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.1112 - val_accuracy: 0.9752\n",
      "Epoch 1995/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.1105 - val_accuracy: 0.9783\n",
      "Epoch 1996/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.1120 - val_accuracy: 0.9783\n",
      "Epoch 1997/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.1101 - val_accuracy: 0.9783\n",
      "Epoch 1998/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.1100 - val_accuracy: 0.9814\n",
      "Epoch 1999/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.1103 - val_accuracy: 0.9783\n",
      "Epoch 2000/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 0.1102 - val_accuracy: 0.9783\n",
      "Epoch 2001/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.1096 - val_accuracy: 0.9783\n",
      "Epoch 2002/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.1098 - val_accuracy: 0.9783\n",
      "Epoch 2003/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.1096 - val_accuracy: 0.9752\n",
      "Epoch 2004/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.1095 - val_accuracy: 0.9783\n",
      "Epoch 2005/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 2006/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0157 - accuracy: 0.9973 - val_loss: 0.1091 - val_accuracy: 0.9814\n",
      "Epoch 2007/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.1105 - val_accuracy: 0.9783\n",
      "Epoch 2008/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.1097 - val_accuracy: 0.9783\n",
      "Epoch 2009/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.1124 - val_accuracy: 0.9814\n",
      "Epoch 2010/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0180 - accuracy: 0.9922 - val_loss: 0.1073 - val_accuracy: 0.9814\n",
      "Epoch 2011/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0159 - accuracy: 0.9983 - val_loss: 0.1096 - val_accuracy: 0.9783\n",
      "Epoch 2012/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0186 - accuracy: 0.9956 - val_loss: 0.1077 - val_accuracy: 0.9814\n",
      "Epoch 2013/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0151 - accuracy: 0.9973 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 2014/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0158 - accuracy: 0.9956 - val_loss: 0.1094 - val_accuracy: 0.9783\n",
      "Epoch 2015/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.1095 - val_accuracy: 0.9814\n",
      "Epoch 2016/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0156 - accuracy: 0.9983 - val_loss: 0.1103 - val_accuracy: 0.9783\n",
      "Epoch 2017/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0152 - accuracy: 0.9973 - val_loss: 0.1111 - val_accuracy: 0.9783\n",
      "Epoch 2018/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.1137 - val_accuracy: 0.9783\n",
      "Epoch 2019/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0172 - accuracy: 0.9932 - val_loss: 0.1111 - val_accuracy: 0.9783\n",
      "Epoch 2020/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.1112 - val_accuracy: 0.9783\n",
      "Epoch 2021/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0166 - accuracy: 0.9966 - val_loss: 0.1107 - val_accuracy: 0.9783\n",
      "Epoch 2022/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.1099 - val_accuracy: 0.9783\n",
      "Epoch 2023/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0157 - accuracy: 0.9966 - val_loss: 0.1098 - val_accuracy: 0.9783\n",
      "Epoch 2024/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.1097 - val_accuracy: 0.9783\n",
      "Epoch 2025/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.1087 - val_accuracy: 0.9783\n",
      "Epoch 2026/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0150 - accuracy: 0.9983 - val_loss: 0.1083 - val_accuracy: 0.9783\n",
      "Epoch 2027/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0151 - accuracy: 0.9983 - val_loss: 0.1083 - val_accuracy: 0.9783\n",
      "Epoch 2028/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0151 - accuracy: 0.9983 - val_loss: 0.1083 - val_accuracy: 0.9814\n",
      "Epoch 2029/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0157 - accuracy: 0.9966 - val_loss: 0.1084 - val_accuracy: 0.9783\n",
      "Epoch 2030/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.1082 - val_accuracy: 0.9783\n",
      "Epoch 2031/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 0.9990 - val_loss: 0.1090 - val_accuracy: 0.9783\n",
      "Epoch 2032/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.1094 - val_accuracy: 0.9783\n",
      "Epoch 2033/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 2034/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.1105 - val_accuracy: 0.9783\n",
      "Epoch 2035/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.1100 - val_accuracy: 0.9783\n",
      "Epoch 2036/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.1103 - val_accuracy: 0.9783\n",
      "Epoch 2037/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.1092 - val_accuracy: 0.9783\n",
      "Epoch 2038/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.1105 - val_accuracy: 0.9783\n",
      "Epoch 2039/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 2040/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0155 - accuracy: 0.9973 - val_loss: 0.1105 - val_accuracy: 0.9783\n",
      "Epoch 2041/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 2042/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.9990 - val_loss: 0.1120 - val_accuracy: 0.9783\n",
      "Epoch 2043/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 0.1119 - val_accuracy: 0.9814\n",
      "Epoch 2044/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0168 - accuracy: 0.9929 - val_loss: 0.1101 - val_accuracy: 0.9814\n",
      "Epoch 2045/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.1096 - val_accuracy: 0.9814\n",
      "Epoch 2046/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.9983 - val_loss: 0.1112 - val_accuracy: 0.9783\n",
      "Epoch 2047/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.1097 - val_accuracy: 0.9814\n",
      "Epoch 2048/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.1093 - val_accuracy: 0.9814\n",
      "Epoch 2049/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 0.1095 - val_accuracy: 0.9814\n",
      "Epoch 2050/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.1087 - val_accuracy: 0.9845\n",
      "Epoch 2051/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.1107 - val_accuracy: 0.9783\n",
      "Epoch 2052/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 0.1117 - val_accuracy: 0.9783\n",
      "Epoch 2053/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0160 - accuracy: 0.9973 - val_loss: 0.1100 - val_accuracy: 0.9783\n",
      "Epoch 2054/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0143 - accuracy: 0.9983 - val_loss: 0.1102 - val_accuracy: 0.9814\n",
      "Epoch 2055/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 2056/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.1102 - val_accuracy: 0.9814\n",
      "Epoch 2057/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.1103 - val_accuracy: 0.9783\n",
      "Epoch 2058/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.1087 - val_accuracy: 0.9814\n",
      "Epoch 2059/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0135 - accuracy: 0.9983 - val_loss: 0.1088 - val_accuracy: 0.9845\n",
      "Epoch 2060/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.1083 - val_accuracy: 0.9814\n",
      "Epoch 2061/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0129 - accuracy: 0.9990 - val_loss: 0.1112 - val_accuracy: 0.9783\n",
      "Epoch 2062/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.1108 - val_accuracy: 0.9752\n",
      "Epoch 2063/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
      "Epoch 2064/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0162 - accuracy: 0.9932 - val_loss: 0.1101 - val_accuracy: 0.9814\n",
      "Epoch 2065/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0159 - accuracy: 0.9966 - val_loss: 0.1099 - val_accuracy: 0.9814\n",
      "Epoch 2066/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.1106 - val_accuracy: 0.9814\n",
      "Epoch 2067/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 0.9990 - val_loss: 0.1120 - val_accuracy: 0.9814\n",
      "Epoch 2068/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.1138 - val_accuracy: 0.9783\n",
      "Epoch 2069/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.1128 - val_accuracy: 0.9814\n",
      "Epoch 2070/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.1140 - val_accuracy: 0.9783\n",
      "Epoch 2071/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.1131 - val_accuracy: 0.9814\n",
      "Epoch 2072/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.1135 - val_accuracy: 0.9783\n",
      "Epoch 2073/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 0.9983 - val_loss: 0.1136 - val_accuracy: 0.9814\n",
      "Epoch 2074/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.1132 - val_accuracy: 0.9814\n",
      "Epoch 2075/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.1118 - val_accuracy: 0.9783\n",
      "Epoch 2076/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0136 - accuracy: 0.9983 - val_loss: 0.1159 - val_accuracy: 0.9814\n",
      "Epoch 2077/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.1115 - val_accuracy: 0.9814\n",
      "Epoch 2078/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0136 - accuracy: 0.9990 - val_loss: 0.1123 - val_accuracy: 0.9783\n",
      "Epoch 2079/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 0.1109 - val_accuracy: 0.9814\n",
      "Epoch 2080/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0134 - accuracy: 0.9983 - val_loss: 0.1108 - val_accuracy: 0.9783\n",
      "Epoch 2081/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0139 - accuracy: 0.9983 - val_loss: 0.1112 - val_accuracy: 0.9814\n",
      "Epoch 2082/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0133 - accuracy: 0.9990 - val_loss: 0.1117 - val_accuracy: 0.9814\n",
      "Epoch 2083/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0131 - accuracy: 0.9990 - val_loss: 0.1128 - val_accuracy: 0.9783\n",
      "Epoch 2084/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.1134 - val_accuracy: 0.9783\n",
      "Epoch 2085/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.1125 - val_accuracy: 0.9814\n",
      "Epoch 2086/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0141 - accuracy: 0.9983 - val_loss: 0.1126 - val_accuracy: 0.9814\n",
      "Epoch 2087/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.9983 - val_loss: 0.1126 - val_accuracy: 0.9814\n",
      "Epoch 2088/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0135 - accuracy: 0.9980 - val_loss: 0.1128 - val_accuracy: 0.9783\n",
      "Epoch 2089/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.1152 - val_accuracy: 0.9783\n",
      "Epoch 2090/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.1128 - val_accuracy: 0.9783\n",
      "Epoch 2091/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.1126 - val_accuracy: 0.9783\n",
      "Epoch 2092/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.1122 - val_accuracy: 0.9814\n",
      "Epoch 2093/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.1145 - val_accuracy: 0.9814\n",
      "Epoch 2094/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 0.1114 - val_accuracy: 0.9845\n",
      "Epoch 2095/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.1135 - val_accuracy: 0.9814\n",
      "Epoch 2096/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.1111 - val_accuracy: 0.9814\n",
      "Epoch 2097/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.1199 - val_accuracy: 0.9783\n",
      "Epoch 2098/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1115 - val_accuracy: 0.9752\n",
      "Epoch 2099/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.1120 - val_accuracy: 0.9783\n",
      "Epoch 2100/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.1105 - val_accuracy: 0.9814\n",
      "Epoch 2101/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0141 - accuracy: 0.9983 - val_loss: 0.1114 - val_accuracy: 0.9783\n",
      "Epoch 2102/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 0.1107 - val_accuracy: 0.9783\n",
      "Epoch 2103/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.1108 - val_accuracy: 0.9814\n",
      "Epoch 2104/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.1103 - val_accuracy: 0.9814\n",
      "Epoch 2105/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.1114 - val_accuracy: 0.9783\n",
      "Epoch 2106/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.1108 - val_accuracy: 0.9814\n",
      "Epoch 2107/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 0.9990 - val_loss: 0.1122 - val_accuracy: 0.9783\n",
      "Epoch 2108/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 0.1112 - val_accuracy: 0.9814\n",
      "Epoch 2109/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.1129 - val_accuracy: 0.9783\n",
      "Epoch 2110/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.1108 - val_accuracy: 0.9814\n",
      "Epoch 2111/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 0.1111 - val_accuracy: 0.9845\n",
      "Epoch 2112/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.1108 - val_accuracy: 0.9845\n",
      "Epoch 2113/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0139 - accuracy: 0.9939 - val_loss: 0.1108 - val_accuracy: 0.9814\n",
      "Epoch 2114/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.1118 - val_accuracy: 0.9814\n",
      "Epoch 2115/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.1130 - val_accuracy: 0.9814\n",
      "Epoch 2116/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.1138 - val_accuracy: 0.9814\n",
      "Epoch 2117/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.1133 - val_accuracy: 0.9814\n",
      "Epoch 2118/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.1144 - val_accuracy: 0.9783\n",
      "Epoch 2119/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.1141 - val_accuracy: 0.9783\n",
      "Epoch 2120/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.1140 - val_accuracy: 0.9814\n",
      "Epoch 2121/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.1135 - val_accuracy: 0.9814\n",
      "Epoch 2122/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.1126 - val_accuracy: 0.9814\n",
      "Epoch 2123/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.1121 - val_accuracy: 0.9814\n",
      "Epoch 2124/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0138 - accuracy: 0.9983 - val_loss: 0.1116 - val_accuracy: 0.9814\n",
      "Epoch 2125/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 0.1115 - val_accuracy: 0.9814\n",
      "Epoch 2126/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.1117 - val_accuracy: 0.9814\n",
      "Epoch 2127/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 0.1111 - val_accuracy: 0.9814\n",
      "Epoch 2128/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.1114 - val_accuracy: 0.9814\n",
      "Epoch 2129/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.1150 - val_accuracy: 0.9845\n",
      "Epoch 2130/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.1136 - val_accuracy: 0.9845\n",
      "Epoch 2131/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0125 - accuracy: 0.9983 - val_loss: 0.1146 - val_accuracy: 0.9814\n",
      "Epoch 2132/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.1148 - val_accuracy: 0.9814\n",
      "Epoch 2133/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.1158 - val_accuracy: 0.9814\n",
      "Epoch 2134/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0138 - accuracy: 0.9980 - val_loss: 0.1165 - val_accuracy: 0.9814\n",
      "Epoch 2135/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.1135 - val_accuracy: 0.9814\n",
      "Epoch 2136/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.1139 - val_accuracy: 0.9783\n",
      "Epoch 2137/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.1140 - val_accuracy: 0.9814\n",
      "Epoch 2138/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1149 - val_accuracy: 0.9814\n",
      "Epoch 2139/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.1137 - val_accuracy: 0.9814\n",
      "Epoch 2140/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0119 - accuracy: 0.9990 - val_loss: 0.1141 - val_accuracy: 0.9814\n",
      "Epoch 2141/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 0.1146 - val_accuracy: 0.9814\n",
      "Epoch 2142/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.1141 - val_accuracy: 0.9814\n",
      "Epoch 2143/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0129 - accuracy: 0.9983 - val_loss: 0.1142 - val_accuracy: 0.9814\n",
      "Epoch 2144/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.1146 - val_accuracy: 0.9783\n",
      "Epoch 2145/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.1142 - val_accuracy: 0.9814\n",
      "Epoch 2146/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.1159 - val_accuracy: 0.9783\n",
      "Epoch 2147/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.1148 - val_accuracy: 0.9814\n",
      "Epoch 2148/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.1166 - val_accuracy: 0.9783\n",
      "Epoch 2149/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.1158 - val_accuracy: 0.9814\n",
      "Epoch 2150/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0145 - accuracy: 0.9939 - val_loss: 0.1211 - val_accuracy: 0.9783\n",
      "Epoch 2151/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0196 - accuracy: 0.9905 - val_loss: 0.1142 - val_accuracy: 0.9814\n",
      "Epoch 2152/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.1141 - val_accuracy: 0.9783\n",
      "Epoch 2153/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.1125 - val_accuracy: 0.9814\n",
      "Epoch 2154/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.1120 - val_accuracy: 0.9814\n",
      "Epoch 2155/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.1116 - val_accuracy: 0.9814\n",
      "Epoch 2156/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.1118 - val_accuracy: 0.9814\n",
      "Epoch 2157/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.1116 - val_accuracy: 0.9814\n",
      "Epoch 2158/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 0.9990 - val_loss: 0.1116 - val_accuracy: 0.9814\n",
      "Epoch 2159/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.1125 - val_accuracy: 0.9845\n",
      "Epoch 2160/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 0.1122 - val_accuracy: 0.9814\n",
      "Epoch 2161/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.1125 - val_accuracy: 0.9814\n",
      "Epoch 2162/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.1131 - val_accuracy: 0.9783\n",
      "Epoch 2163/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0133 - accuracy: 0.9973 - val_loss: 0.1131 - val_accuracy: 0.9814\n",
      "Epoch 2164/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0133 - accuracy: 0.9983 - val_loss: 0.1132 - val_accuracy: 0.9814\n",
      "Epoch 2165/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0114 - accuracy: 0.9990 - val_loss: 0.1132 - val_accuracy: 0.9845\n",
      "Epoch 2166/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.1137 - val_accuracy: 0.9814\n",
      "Epoch 2167/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.1140 - val_accuracy: 0.9814\n",
      "Epoch 2168/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0122 - accuracy: 0.9983 - val_loss: 0.1146 - val_accuracy: 0.9783\n",
      "Epoch 2169/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.1142 - val_accuracy: 0.9814\n",
      "Epoch 2170/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.1150 - val_accuracy: 0.9814\n",
      "Epoch 2171/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.1147 - val_accuracy: 0.9814\n",
      "Epoch 2172/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 0.9973 - val_loss: 0.1142 - val_accuracy: 0.9845\n",
      "Epoch 2173/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.1143 - val_accuracy: 0.9845\n",
      "Epoch 2174/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0143 - accuracy: 0.9939 - val_loss: 0.1137 - val_accuracy: 0.9814\n",
      "Epoch 2175/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.1139 - val_accuracy: 0.9783\n",
      "Epoch 2176/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.1137 - val_accuracy: 0.9814\n",
      "Epoch 2177/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.1135 - val_accuracy: 0.9814\n",
      "Epoch 2178/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.1133 - val_accuracy: 0.9814\n",
      "Epoch 2179/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.1128 - val_accuracy: 0.9814\n",
      "Epoch 2180/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.1131 - val_accuracy: 0.9814\n",
      "Epoch 2181/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.1131 - val_accuracy: 0.9814\n",
      "Epoch 2182/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.1135 - val_accuracy: 0.9814\n",
      "Epoch 2183/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.1140 - val_accuracy: 0.9814\n",
      "Epoch 2184/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 0.1144 - val_accuracy: 0.9814\n",
      "Epoch 2185/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.1151 - val_accuracy: 0.9814\n",
      "Epoch 2186/3500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.1153 - val_accuracy: 0.9845\n",
      "Epoch 2187/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.1154 - val_accuracy: 0.9814\n",
      "Epoch 2188/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.1155 - val_accuracy: 0.9814\n",
      "Epoch 2189/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 0.1158 - val_accuracy: 0.9814\n",
      "Epoch 2190/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.1153 - val_accuracy: 0.9814\n",
      "Epoch 2191/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0118 - accuracy: 0.9990 - val_loss: 0.1153 - val_accuracy: 0.9814\n",
      "Epoch 2192/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0123 - accuracy: 0.9949 - val_loss: 0.1157 - val_accuracy: 0.9814\n",
      "Epoch 2193/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.1153 - val_accuracy: 0.9814\n",
      "Epoch 2194/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.1155 - val_accuracy: 0.9814\n",
      "Epoch 2195/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.1152 - val_accuracy: 0.9814\n",
      "Epoch 2196/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 0.1163 - val_accuracy: 0.9814\n",
      "Epoch 2197/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.1191 - val_accuracy: 0.9814\n",
      "Epoch 2198/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.9966 - val_loss: 0.1148 - val_accuracy: 0.9814\n",
      "Epoch 2199/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.1176 - val_accuracy: 0.9814\n",
      "Epoch 2200/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.1144 - val_accuracy: 0.9814\n",
      "Epoch 2201/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.1181 - val_accuracy: 0.9814\n",
      "Epoch 2202/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0146 - accuracy: 0.9983 - val_loss: 0.1149 - val_accuracy: 0.9814\n",
      "Epoch 2203/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.1165 - val_accuracy: 0.9783\n",
      "Epoch 2204/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.1154 - val_accuracy: 0.9814\n",
      "Epoch 2205/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.1191 - val_accuracy: 0.9783\n",
      "Epoch 2206/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0136 - accuracy: 0.9983 - val_loss: 0.1160 - val_accuracy: 0.9814\n",
      "Epoch 2207/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.1165 - val_accuracy: 0.9845\n",
      "Epoch 2208/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.1161 - val_accuracy: 0.9814\n",
      "Epoch 2209/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.1202 - val_accuracy: 0.9783\n",
      "Epoch 2210/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.1170 - val_accuracy: 0.9814\n",
      "Epoch 2211/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 0.9949 - val_loss: 0.1182 - val_accuracy: 0.9783\n",
      "Epoch 2212/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.1184 - val_accuracy: 0.9814\n",
      "Epoch 2213/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.1166 - val_accuracy: 0.9814\n",
      "Epoch 2214/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.1171 - val_accuracy: 0.9814\n",
      "Epoch 2215/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.1157 - val_accuracy: 0.9814\n",
      "Epoch 2216/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.1151 - val_accuracy: 0.9814\n",
      "Epoch 2217/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.1156 - val_accuracy: 0.9814\n",
      "Epoch 2218/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.1152 - val_accuracy: 0.9814\n",
      "Epoch 2219/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.1156 - val_accuracy: 0.9814\n",
      "Epoch 2220/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.1156 - val_accuracy: 0.9814\n",
      "Epoch 2221/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.1169 - val_accuracy: 0.9814\n",
      "Epoch 2222/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.1154 - val_accuracy: 0.9845\n",
      "Epoch 2223/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0129 - accuracy: 0.9949 - val_loss: 0.1172 - val_accuracy: 0.9814\n",
      "Epoch 2224/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0129 - accuracy: 0.9983 - val_loss: 0.1151 - val_accuracy: 0.9814\n",
      "Epoch 2225/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.1144 - val_accuracy: 0.9814\n",
      "Epoch 2226/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.1148 - val_accuracy: 0.9814\n",
      "Epoch 2227/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.1151 - val_accuracy: 0.9814\n",
      "Epoch 2228/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.1164 - val_accuracy: 0.9814\n",
      "Epoch 2229/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.1156 - val_accuracy: 0.9814\n",
      "Epoch 2230/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.1159 - val_accuracy: 0.9845\n",
      "Epoch 2231/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.1161 - val_accuracy: 0.9845\n",
      "Epoch 2232/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1156 - val_accuracy: 0.9814\n",
      "Epoch 2233/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.1156 - val_accuracy: 0.9814\n",
      "Epoch 2234/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.1153 - val_accuracy: 0.9783\n",
      "Epoch 2235/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.1156 - val_accuracy: 0.9814\n",
      "Epoch 2236/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.1182 - val_accuracy: 0.9845\n",
      "Epoch 2237/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.1177 - val_accuracy: 0.9783\n",
      "Epoch 2238/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0124 - accuracy: 0.9990 - val_loss: 0.1178 - val_accuracy: 0.9783\n",
      "Epoch 2239/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.1218 - val_accuracy: 0.9845\n",
      "Epoch 2240/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0139 - accuracy: 0.9966 - val_loss: 0.1181 - val_accuracy: 0.9814\n",
      "Epoch 2241/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.1253 - val_accuracy: 0.9814\n",
      "Epoch 2242/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.1206 - val_accuracy: 0.9783\n",
      "Epoch 2243/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 0.9983 - val_loss: 0.1201 - val_accuracy: 0.9814\n",
      "Epoch 2244/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0135 - accuracy: 0.9983 - val_loss: 0.1187 - val_accuracy: 0.9814\n",
      "Epoch 2245/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.1189 - val_accuracy: 0.9783\n",
      "Epoch 2246/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.1170 - val_accuracy: 0.9783\n",
      "Epoch 2247/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9990 - val_loss: 0.1192 - val_accuracy: 0.9814\n",
      "Epoch 2248/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 0.9973 - val_loss: 0.1182 - val_accuracy: 0.9845\n",
      "Epoch 2249/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.1162 - val_accuracy: 0.9814\n",
      "Epoch 2250/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.1175 - val_accuracy: 0.9814\n",
      "Epoch 2251/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.1154 - val_accuracy: 0.9845\n",
      "Epoch 2252/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.1204 - val_accuracy: 0.9814\n",
      "Epoch 2253/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.1158 - val_accuracy: 0.9783\n",
      "Epoch 2254/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 0.1191 - val_accuracy: 0.9783\n",
      "Epoch 2255/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.1174 - val_accuracy: 0.9783\n",
      "Epoch 2256/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.1180 - val_accuracy: 0.9814\n",
      "Epoch 2257/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.1207 - val_accuracy: 0.9814\n",
      "Epoch 2258/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0130 - accuracy: 0.9990 - val_loss: 0.1161 - val_accuracy: 0.9814\n",
      "Epoch 2259/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.1183 - val_accuracy: 0.9783\n",
      "Epoch 2260/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.1153 - val_accuracy: 0.9814\n",
      "Epoch 2261/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.1168 - val_accuracy: 0.9845\n",
      "Epoch 2262/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.1149 - val_accuracy: 0.9814\n",
      "Epoch 2263/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.1175 - val_accuracy: 0.9783\n",
      "Epoch 2264/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1154 - val_accuracy: 0.9783\n",
      "Epoch 2265/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.1175 - val_accuracy: 0.9845\n",
      "Epoch 2266/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.1170 - val_accuracy: 0.9845\n",
      "Epoch 2267/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0125 - accuracy: 0.9983 - val_loss: 0.1168 - val_accuracy: 0.9845\n",
      "Epoch 2268/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.1175 - val_accuracy: 0.9845\n",
      "Epoch 2269/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 0.9932 - val_loss: 0.1198 - val_accuracy: 0.9845\n",
      "Epoch 2270/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0125 - accuracy: 0.9983 - val_loss: 0.1193 - val_accuracy: 0.9814\n",
      "Epoch 2271/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.1183 - val_accuracy: 0.9814\n",
      "Epoch 2272/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 0.1183 - val_accuracy: 0.9814\n",
      "Epoch 2273/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.1191 - val_accuracy: 0.9814\n",
      "Epoch 2274/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0118 - accuracy: 0.9949 - val_loss: 0.1180 - val_accuracy: 0.9814\n",
      "Epoch 2275/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.1183 - val_accuracy: 0.9783\n",
      "Epoch 2276/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.1175 - val_accuracy: 0.9814\n",
      "Epoch 2277/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 0.1174 - val_accuracy: 0.9814\n",
      "Epoch 2278/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1159 - val_accuracy: 0.9814\n",
      "Epoch 2279/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.1154 - val_accuracy: 0.9814\n",
      "Epoch 2280/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.1148 - val_accuracy: 0.9814\n",
      "Epoch 2281/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.1161 - val_accuracy: 0.9845\n",
      "Epoch 2282/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1157 - val_accuracy: 0.9814\n",
      "Epoch 2283/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.1160 - val_accuracy: 0.9814\n",
      "Epoch 2284/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.1164 - val_accuracy: 0.9814\n",
      "Epoch 2285/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.1171 - val_accuracy: 0.9814\n",
      "Epoch 2286/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.1177 - val_accuracy: 0.9814\n",
      "Epoch 2287/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.1188 - val_accuracy: 0.9814\n",
      "Epoch 2288/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.1195 - val_accuracy: 0.9814\n",
      "Epoch 2289/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.1194 - val_accuracy: 0.9814\n",
      "Epoch 2290/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0105 - accuracy: 0.9956 - val_loss: 0.1201 - val_accuracy: 0.9814\n",
      "Epoch 2291/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1205 - val_accuracy: 0.9783\n",
      "Epoch 2292/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.1206 - val_accuracy: 0.9814\n",
      "Epoch 2293/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9956 - val_loss: 0.1198 - val_accuracy: 0.9845\n",
      "Epoch 2294/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 0.1196 - val_accuracy: 0.9814\n",
      "Epoch 2295/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.1187 - val_accuracy: 0.9814\n",
      "Epoch 2296/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9990 - val_loss: 0.1180 - val_accuracy: 0.9814\n",
      "Epoch 2297/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1181 - val_accuracy: 0.9814\n",
      "Epoch 2298/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1173 - val_accuracy: 0.9814\n",
      "Epoch 2299/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1170 - val_accuracy: 0.9814\n",
      "Epoch 2300/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.1165 - val_accuracy: 0.9814\n",
      "Epoch 2301/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0099 - accuracy: 0.9990 - val_loss: 0.1192 - val_accuracy: 0.9845\n",
      "Epoch 2302/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.1172 - val_accuracy: 0.9814\n",
      "Epoch 2303/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.1176 - val_accuracy: 0.9814\n",
      "Epoch 2304/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.1181 - val_accuracy: 0.9814\n",
      "Epoch 2305/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.1189 - val_accuracy: 0.9814\n",
      "Epoch 2306/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1194 - val_accuracy: 0.9814\n",
      "Epoch 2307/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1196 - val_accuracy: 0.9814\n",
      "Epoch 2308/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.1195 - val_accuracy: 0.9814\n",
      "Epoch 2309/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.1194 - val_accuracy: 0.9814\n",
      "Epoch 2310/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 0.1191 - val_accuracy: 0.9814\n",
      "Epoch 2311/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.1194 - val_accuracy: 0.9814\n",
      "Epoch 2312/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1188 - val_accuracy: 0.9814\n",
      "Epoch 2313/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0098 - accuracy: 0.9990 - val_loss: 0.1184 - val_accuracy: 0.9814\n",
      "Epoch 2314/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.1189 - val_accuracy: 0.9814\n",
      "Epoch 2315/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1199 - val_accuracy: 0.9845\n",
      "Epoch 2316/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.1181 - val_accuracy: 0.9814\n",
      "Epoch 2317/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9990 - val_loss: 0.1181 - val_accuracy: 0.9814\n",
      "Epoch 2318/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0102 - accuracy: 0.9983 - val_loss: 0.1191 - val_accuracy: 0.9814\n",
      "Epoch 2319/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.1190 - val_accuracy: 0.9814\n",
      "Epoch 2320/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.1189 - val_accuracy: 0.9814\n",
      "Epoch 2321/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.1190 - val_accuracy: 0.9814\n",
      "Epoch 2322/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.1193 - val_accuracy: 0.9814\n",
      "Epoch 2323/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.1195 - val_accuracy: 0.9814\n",
      "Epoch 2324/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.1217 - val_accuracy: 0.9814\n",
      "Epoch 2325/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.1207 - val_accuracy: 0.9814\n",
      "Epoch 2326/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1198 - val_accuracy: 0.9814\n",
      "Epoch 2327/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.1197 - val_accuracy: 0.9814\n",
      "Epoch 2328/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.1201 - val_accuracy: 0.9814\n",
      "Epoch 2329/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.1204 - val_accuracy: 0.9814\n",
      "Epoch 2330/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9990 - val_loss: 0.1205 - val_accuracy: 0.9845\n",
      "Epoch 2331/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1214 - val_accuracy: 0.9814\n",
      "Epoch 2332/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.1212 - val_accuracy: 0.9814\n",
      "Epoch 2333/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0097 - accuracy: 0.9956 - val_loss: 0.1201 - val_accuracy: 0.9814\n",
      "Epoch 2334/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.1201 - val_accuracy: 0.9783\n",
      "Epoch 2335/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 0.1211 - val_accuracy: 0.9814\n",
      "Epoch 2336/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.1203 - val_accuracy: 0.9845\n",
      "Epoch 2337/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 0.9949 - val_loss: 0.1248 - val_accuracy: 0.9814\n",
      "Epoch 2338/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.1201 - val_accuracy: 0.9845\n",
      "Epoch 2339/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.1277 - val_accuracy: 0.9783\n",
      "Epoch 2340/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.1247 - val_accuracy: 0.9783\n",
      "Epoch 2341/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.1193 - val_accuracy: 0.9752\n",
      "Epoch 2342/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.1220 - val_accuracy: 0.9783\n",
      "Epoch 2343/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 0.1182 - val_accuracy: 0.9814\n",
      "Epoch 2344/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.1180 - val_accuracy: 0.9783\n",
      "Epoch 2345/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1196 - val_accuracy: 0.9783\n",
      "Epoch 2346/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.1171 - val_accuracy: 0.9783\n",
      "Epoch 2347/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.1190 - val_accuracy: 0.9814\n",
      "Epoch 2348/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 0.1166 - val_accuracy: 0.9814\n",
      "Epoch 2349/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.1169 - val_accuracy: 0.9845\n",
      "Epoch 2350/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0121 - accuracy: 0.9949 - val_loss: 0.1172 - val_accuracy: 0.9845\n",
      "Epoch 2351/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1182 - val_accuracy: 0.9814\n",
      "Epoch 2352/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0093 - accuracy: 0.9990 - val_loss: 0.1185 - val_accuracy: 0.9814\n",
      "Epoch 2353/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.1190 - val_accuracy: 0.9814\n",
      "Epoch 2354/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.1204 - val_accuracy: 0.9783\n",
      "Epoch 2355/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.1219 - val_accuracy: 0.9783\n",
      "Epoch 2356/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.1216 - val_accuracy: 0.9814\n",
      "Epoch 2357/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.1221 - val_accuracy: 0.9814\n",
      "Epoch 2358/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.1216 - val_accuracy: 0.9783\n",
      "Epoch 2359/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.1217 - val_accuracy: 0.9783\n",
      "Epoch 2360/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.1205 - val_accuracy: 0.9814\n",
      "Epoch 2361/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.1229 - val_accuracy: 0.9845\n",
      "Epoch 2362/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 0.1214 - val_accuracy: 0.9814\n",
      "Epoch 2363/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0102 - accuracy: 0.9983 - val_loss: 0.1220 - val_accuracy: 0.9845\n",
      "Epoch 2364/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1211 - val_accuracy: 0.9814\n",
      "Epoch 2365/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.1214 - val_accuracy: 0.9814\n",
      "Epoch 2366/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.1214 - val_accuracy: 0.9814\n",
      "Epoch 2367/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.1219 - val_accuracy: 0.9814\n",
      "Epoch 2368/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.1224 - val_accuracy: 0.9814\n",
      "Epoch 2369/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9990 - val_loss: 0.1233 - val_accuracy: 0.9845\n",
      "Epoch 2370/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0103 - accuracy: 0.9990 - val_loss: 0.1266 - val_accuracy: 0.9845\n",
      "Epoch 2371/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0130 - accuracy: 0.9983 - val_loss: 0.1216 - val_accuracy: 0.9814\n",
      "Epoch 2372/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.1223 - val_accuracy: 0.9783\n",
      "Epoch 2373/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.1210 - val_accuracy: 0.9814\n",
      "Epoch 2374/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.1233 - val_accuracy: 0.9845\n",
      "Epoch 2375/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1219 - val_accuracy: 0.9845\n",
      "Epoch 2376/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.1220 - val_accuracy: 0.9814\n",
      "Epoch 2377/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.1220 - val_accuracy: 0.9783\n",
      "Epoch 2378/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.1219 - val_accuracy: 0.9814\n",
      "Epoch 2379/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.1227 - val_accuracy: 0.9814\n",
      "Epoch 2380/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1224 - val_accuracy: 0.9814\n",
      "Epoch 2381/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.1233 - val_accuracy: 0.9845\n",
      "Epoch 2382/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.1229 - val_accuracy: 0.9814\n",
      "Epoch 2383/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.1248 - val_accuracy: 0.9845\n",
      "Epoch 2384/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.1218 - val_accuracy: 0.9814\n",
      "Epoch 2385/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.1237 - val_accuracy: 0.9814\n",
      "Epoch 2386/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.1210 - val_accuracy: 0.9814\n",
      "Epoch 2387/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.1278 - val_accuracy: 0.9783\n",
      "Epoch 2388/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.1200 - val_accuracy: 0.9814\n",
      "Epoch 2389/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.1199 - val_accuracy: 0.9814\n",
      "Epoch 2390/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.1220 - val_accuracy: 0.9845\n",
      "Epoch 2391/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.1224 - val_accuracy: 0.9845\n",
      "Epoch 2392/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.1219 - val_accuracy: 0.9814\n",
      "Epoch 2393/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.1227 - val_accuracy: 0.9814\n",
      "Epoch 2394/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.1234 - val_accuracy: 0.9814\n",
      "Epoch 2395/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.1228 - val_accuracy: 0.9814\n",
      "Epoch 2396/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.1236 - val_accuracy: 0.9783\n",
      "Epoch 2397/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1218 - val_accuracy: 0.9814\n",
      "Epoch 2398/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.1231 - val_accuracy: 0.9845\n",
      "Epoch 2399/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.1216 - val_accuracy: 0.9814\n",
      "Epoch 2400/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.1214 - val_accuracy: 0.9814\n",
      "Epoch 2401/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.1224 - val_accuracy: 0.9814\n",
      "Epoch 2402/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 0.9949 - val_loss: 0.1232 - val_accuracy: 0.9783\n",
      "Epoch 2403/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.1231 - val_accuracy: 0.9783\n",
      "Epoch 2404/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.1226 - val_accuracy: 0.9814\n",
      "Epoch 2405/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.1268 - val_accuracy: 0.9845\n",
      "Epoch 2406/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 0.1250 - val_accuracy: 0.9845\n",
      "Epoch 2407/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.1256 - val_accuracy: 0.9814\n",
      "Epoch 2408/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1225 - val_accuracy: 0.9814\n",
      "Epoch 2409/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.1272 - val_accuracy: 0.9814\n",
      "Epoch 2410/3500\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.1207 - val_accuracy: 0.9783\n",
      "Epoch 2411/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1216 - val_accuracy: 0.9783\n",
      "Epoch 2412/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0116 - accuracy: 0.9983 - val_loss: 0.1190 - val_accuracy: 0.9814\n",
      "Epoch 2413/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.1224 - val_accuracy: 0.9814\n",
      "Epoch 2414/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.1197 - val_accuracy: 0.9845\n",
      "Epoch 2415/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1204 - val_accuracy: 0.9814\n",
      "Epoch 2416/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.1210 - val_accuracy: 0.9814\n",
      "Epoch 2417/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.1224 - val_accuracy: 0.9814\n",
      "Epoch 2418/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 0.9956 - val_loss: 0.1221 - val_accuracy: 0.9814\n",
      "Epoch 2419/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1230 - val_accuracy: 0.9814\n",
      "Epoch 2420/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.1232 - val_accuracy: 0.9814\n",
      "Epoch 2421/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.1237 - val_accuracy: 0.9814\n",
      "Epoch 2422/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.1244 - val_accuracy: 0.9814\n",
      "Epoch 2423/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9814\n",
      "Epoch 2424/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.1247 - val_accuracy: 0.9814\n",
      "Epoch 2425/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.1242 - val_accuracy: 0.9814\n",
      "Epoch 2426/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.1257 - val_accuracy: 0.9845\n",
      "Epoch 2427/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.1238 - val_accuracy: 0.9814\n",
      "Epoch 2428/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.1240 - val_accuracy: 0.9783\n",
      "Epoch 2429/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0092 - accuracy: 0.9990 - val_loss: 0.1247 - val_accuracy: 0.9814\n",
      "Epoch 2430/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.1251 - val_accuracy: 0.9814\n",
      "Epoch 2431/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.1244 - val_accuracy: 0.9814\n",
      "Epoch 2432/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.1241 - val_accuracy: 0.9814\n",
      "Epoch 2433/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.1231 - val_accuracy: 0.9814\n",
      "Epoch 2434/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.1236 - val_accuracy: 0.9814\n",
      "Epoch 2435/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.1246 - val_accuracy: 0.9845\n",
      "Epoch 2436/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.1229 - val_accuracy: 0.9814\n",
      "Epoch 2437/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.1244 - val_accuracy: 0.9814\n",
      "Epoch 2438/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.1228 - val_accuracy: 0.9845\n",
      "Epoch 2439/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1228 - val_accuracy: 0.9845\n",
      "Epoch 2440/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9814\n",
      "Epoch 2441/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.1216 - val_accuracy: 0.9814\n",
      "Epoch 2442/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.1226 - val_accuracy: 0.9845\n",
      "Epoch 2443/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.1236 - val_accuracy: 0.9845\n",
      "Epoch 2444/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9845\n",
      "Epoch 2445/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.1238 - val_accuracy: 0.9814\n",
      "Epoch 2446/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.1256 - val_accuracy: 0.9783\n",
      "Epoch 2447/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 0.1267 - val_accuracy: 0.9845\n",
      "Epoch 2448/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.1296 - val_accuracy: 0.9845\n",
      "Epoch 2449/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.1273 - val_accuracy: 0.9845\n",
      "Epoch 2450/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.1285 - val_accuracy: 0.9814\n",
      "Epoch 2451/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.1257 - val_accuracy: 0.9783\n",
      "Epoch 2452/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.1246 - val_accuracy: 0.9814\n",
      "Epoch 2453/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.1239 - val_accuracy: 0.9814\n",
      "Epoch 2454/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.1225 - val_accuracy: 0.9814\n",
      "Epoch 2455/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.1223 - val_accuracy: 0.9814\n",
      "Epoch 2456/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.1240 - val_accuracy: 0.9845\n",
      "Epoch 2457/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9814\n",
      "Epoch 2458/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 0.1237 - val_accuracy: 0.9814\n",
      "Epoch 2459/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.1260 - val_accuracy: 0.9814\n",
      "Epoch 2460/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9990 - val_loss: 0.1268 - val_accuracy: 0.9845\n",
      "Epoch 2461/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1303 - val_accuracy: 0.9783\n",
      "Epoch 2462/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.1258 - val_accuracy: 0.9783\n",
      "Epoch 2463/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.1312 - val_accuracy: 0.9783\n",
      "Epoch 2464/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.1251 - val_accuracy: 0.9814\n",
      "Epoch 2465/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.1300 - val_accuracy: 0.9783\n",
      "Epoch 2466/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.1244 - val_accuracy: 0.9814\n",
      "Epoch 2467/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.1251 - val_accuracy: 0.9814\n",
      "Epoch 2468/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1229 - val_accuracy: 0.9783\n",
      "Epoch 2469/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.1236 - val_accuracy: 0.9814\n",
      "Epoch 2470/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 0.1243 - val_accuracy: 0.9814\n",
      "Epoch 2471/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.1241 - val_accuracy: 0.9783\n",
      "Epoch 2472/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 0.9990 - val_loss: 0.1242 - val_accuracy: 0.9814\n",
      "Epoch 2473/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.1267 - val_accuracy: 0.9845\n",
      "Epoch 2474/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.1255 - val_accuracy: 0.9814\n",
      "Epoch 2475/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1272 - val_accuracy: 0.9814\n",
      "Epoch 2476/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.1279 - val_accuracy: 0.9814\n",
      "Epoch 2477/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.1264 - val_accuracy: 0.9814\n",
      "Epoch 2478/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9845\n",
      "Epoch 2479/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.1261 - val_accuracy: 0.9783\n",
      "Epoch 2480/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.1279 - val_accuracy: 0.9814\n",
      "Epoch 2481/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.1261 - val_accuracy: 0.9814\n",
      "Epoch 2482/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9783\n",
      "Epoch 2483/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.1265 - val_accuracy: 0.9814\n",
      "Epoch 2484/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9783\n",
      "Epoch 2485/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.1281 - val_accuracy: 0.9783\n",
      "Epoch 2486/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.1272 - val_accuracy: 0.9814\n",
      "Epoch 2487/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1285 - val_accuracy: 0.9845\n",
      "Epoch 2488/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.1288 - val_accuracy: 0.9783\n",
      "Epoch 2489/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1274 - val_accuracy: 0.9783\n",
      "Epoch 2490/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.1280 - val_accuracy: 0.9845\n",
      "Epoch 2491/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.1284 - val_accuracy: 0.9845\n",
      "Epoch 2492/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.1264 - val_accuracy: 0.9814\n",
      "Epoch 2493/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1280 - val_accuracy: 0.9845\n",
      "Epoch 2494/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.1276 - val_accuracy: 0.9845\n",
      "Epoch 2495/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.1275 - val_accuracy: 0.9814\n",
      "Epoch 2496/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.1273 - val_accuracy: 0.9814\n",
      "Epoch 2497/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 0.9956 - val_loss: 0.1269 - val_accuracy: 0.9814\n",
      "Epoch 2498/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9949 - val_loss: 0.1268 - val_accuracy: 0.9814\n",
      "Epoch 2499/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0090 - accuracy: 0.9949 - val_loss: 0.1273 - val_accuracy: 0.9814\n",
      "Epoch 2500/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9966 - val_loss: 0.1271 - val_accuracy: 0.9814\n",
      "Epoch 2501/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.1268 - val_accuracy: 0.9814\n",
      "Epoch 2502/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.1265 - val_accuracy: 0.9814\n",
      "Epoch 2503/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0086 - accuracy: 0.9966 - val_loss: 0.1259 - val_accuracy: 0.9814\n",
      "Epoch 2504/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1257 - val_accuracy: 0.9814\n",
      "Epoch 2505/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.1257 - val_accuracy: 0.9814\n",
      "Epoch 2506/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.1263 - val_accuracy: 0.9783\n",
      "Epoch 2507/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.1255 - val_accuracy: 0.9814\n",
      "Epoch 2508/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.1251 - val_accuracy: 0.9814\n",
      "Epoch 2509/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.1247 - val_accuracy: 0.9814\n",
      "Epoch 2510/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1253 - val_accuracy: 0.9845\n",
      "Epoch 2511/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1256 - val_accuracy: 0.9783\n",
      "Epoch 2512/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.1254 - val_accuracy: 0.9814\n",
      "Epoch 2513/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1268 - val_accuracy: 0.9845\n",
      "Epoch 2514/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1271 - val_accuracy: 0.9845\n",
      "Epoch 2515/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 0.1288 - val_accuracy: 0.9814\n",
      "Epoch 2516/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 0.1275 - val_accuracy: 0.9814\n",
      "Epoch 2517/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1297 - val_accuracy: 0.9814\n",
      "Epoch 2518/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1285 - val_accuracy: 0.9783\n",
      "Epoch 2519/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.1300 - val_accuracy: 0.9783\n",
      "Epoch 2520/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.1283 - val_accuracy: 0.9814\n",
      "Epoch 2521/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.1321 - val_accuracy: 0.9845\n",
      "Epoch 2522/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.1292 - val_accuracy: 0.9814\n",
      "Epoch 2523/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1293 - val_accuracy: 0.9783\n",
      "Epoch 2524/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.1290 - val_accuracy: 0.9783\n",
      "Epoch 2525/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.1284 - val_accuracy: 0.9814\n",
      "Epoch 2526/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.1301 - val_accuracy: 0.9845\n",
      "Epoch 2527/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.1300 - val_accuracy: 0.9845\n",
      "Epoch 2528/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0110 - accuracy: 0.9949 - val_loss: 0.1286 - val_accuracy: 0.9845\n",
      "Epoch 2529/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.1293 - val_accuracy: 0.9845\n",
      "Epoch 2530/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.1265 - val_accuracy: 0.9814\n",
      "Epoch 2531/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.1270 - val_accuracy: 0.9783\n",
      "Epoch 2532/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.1258 - val_accuracy: 0.9814\n",
      "Epoch 2533/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.1287 - val_accuracy: 0.9814\n",
      "Epoch 2534/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0091 - accuracy: 0.9990 - val_loss: 0.1269 - val_accuracy: 0.9845\n",
      "Epoch 2535/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9814\n",
      "Epoch 2536/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.1272 - val_accuracy: 0.9814\n",
      "Epoch 2537/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.1281 - val_accuracy: 0.9845\n",
      "Epoch 2538/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.1311 - val_accuracy: 0.9783\n",
      "Epoch 2539/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.1285 - val_accuracy: 0.9814\n",
      "Epoch 2540/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.1292 - val_accuracy: 0.9814\n",
      "Epoch 2541/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.1279 - val_accuracy: 0.9814\n",
      "Epoch 2542/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9845\n",
      "Epoch 2543/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.1277 - val_accuracy: 0.9814\n",
      "Epoch 2544/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.1285 - val_accuracy: 0.9783\n",
      "Epoch 2545/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1282 - val_accuracy: 0.9814\n",
      "Epoch 2546/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.1288 - val_accuracy: 0.9814\n",
      "Epoch 2547/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9814\n",
      "Epoch 2548/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.1280 - val_accuracy: 0.9814\n",
      "Epoch 2549/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1281 - val_accuracy: 0.9814\n",
      "Epoch 2550/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9814\n",
      "Epoch 2551/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.1278 - val_accuracy: 0.9845\n",
      "Epoch 2552/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.1271 - val_accuracy: 0.9814\n",
      "Epoch 2553/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.1310 - val_accuracy: 0.9752\n",
      "Epoch 2554/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1274 - val_accuracy: 0.9783\n",
      "Epoch 2555/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.1286 - val_accuracy: 0.9783\n",
      "Epoch 2556/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0112 - accuracy: 0.9949 - val_loss: 0.1277 - val_accuracy: 0.9783\n",
      "Epoch 2557/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.1277 - val_accuracy: 0.9845\n",
      "Epoch 2558/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1286 - val_accuracy: 0.9845\n",
      "Epoch 2559/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.1288 - val_accuracy: 0.9814\n",
      "Epoch 2560/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.1292 - val_accuracy: 0.9783\n",
      "Epoch 2561/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.1286 - val_accuracy: 0.9814\n",
      "Epoch 2562/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9845\n",
      "Epoch 2563/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.1288 - val_accuracy: 0.9814\n",
      "Epoch 2564/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.1295 - val_accuracy: 0.9783\n",
      "Epoch 2565/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1283 - val_accuracy: 0.9814\n",
      "Epoch 2566/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1289 - val_accuracy: 0.9814\n",
      "Epoch 2567/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9814\n",
      "Epoch 2568/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9814\n",
      "Epoch 2569/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9990 - val_loss: 0.1281 - val_accuracy: 0.9814\n",
      "Epoch 2570/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.1308 - val_accuracy: 0.9814\n",
      "Epoch 2571/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0093 - accuracy: 0.9990 - val_loss: 0.1302 - val_accuracy: 0.9814\n",
      "Epoch 2572/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9814\n",
      "Epoch 2573/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.1341 - val_accuracy: 0.9814\n",
      "Epoch 2574/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1324 - val_accuracy: 0.9814\n",
      "Epoch 2575/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.1313 - val_accuracy: 0.9814\n",
      "Epoch 2576/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.1311 - val_accuracy: 0.9783\n",
      "Epoch 2577/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.1309 - val_accuracy: 0.9783\n",
      "Epoch 2578/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.1299 - val_accuracy: 0.9783\n",
      "Epoch 2579/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.1325 - val_accuracy: 0.9752\n",
      "Epoch 2580/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.1290 - val_accuracy: 0.9783\n",
      "Epoch 2581/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.1315 - val_accuracy: 0.9814\n",
      "Epoch 2582/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.1300 - val_accuracy: 0.9845\n",
      "Epoch 2583/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 0.9990 - val_loss: 0.1348 - val_accuracy: 0.9752\n",
      "Epoch 2584/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.1288 - val_accuracy: 0.9783\n",
      "Epoch 2585/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.1342 - val_accuracy: 0.9783\n",
      "Epoch 2586/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.1291 - val_accuracy: 0.9814\n",
      "Epoch 2587/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1369 - val_accuracy: 0.9783\n",
      "Epoch 2588/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.1304 - val_accuracy: 0.9814\n",
      "Epoch 2589/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.1330 - val_accuracy: 0.9814\n",
      "Epoch 2590/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1293 - val_accuracy: 0.9814\n",
      "Epoch 2591/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.1329 - val_accuracy: 0.9783\n",
      "Epoch 2592/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.1286 - val_accuracy: 0.9814\n",
      "Epoch 2593/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.1328 - val_accuracy: 0.9814\n",
      "Epoch 2594/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.1304 - val_accuracy: 0.9845\n",
      "Epoch 2595/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1320 - val_accuracy: 0.9845\n",
      "Epoch 2596/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.1312 - val_accuracy: 0.9783\n",
      "Epoch 2597/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.1323 - val_accuracy: 0.9783\n",
      "Epoch 2598/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 0.9983 - val_loss: 0.1312 - val_accuracy: 0.9814\n",
      "Epoch 2599/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.1319 - val_accuracy: 0.9845\n",
      "Epoch 2600/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.1311 - val_accuracy: 0.9814\n",
      "Epoch 2601/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.1307 - val_accuracy: 0.9814\n",
      "Epoch 2602/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.1303 - val_accuracy: 0.9814\n",
      "Epoch 2603/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1301 - val_accuracy: 0.9814\n",
      "Epoch 2604/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.1314 - val_accuracy: 0.9845\n",
      "Epoch 2605/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.1312 - val_accuracy: 0.9845\n",
      "Epoch 2606/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9814\n",
      "Epoch 2607/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.1331 - val_accuracy: 0.9845\n",
      "Epoch 2608/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.1349 - val_accuracy: 0.9814\n",
      "Epoch 2609/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.1326 - val_accuracy: 0.9814\n",
      "Epoch 2610/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.1320 - val_accuracy: 0.9783\n",
      "Epoch 2611/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.1320 - val_accuracy: 0.9814\n",
      "Epoch 2612/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1324 - val_accuracy: 0.9814\n",
      "Epoch 2613/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 0.1322 - val_accuracy: 0.9814\n",
      "Epoch 2614/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.1320 - val_accuracy: 0.9783\n",
      "Epoch 2615/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1319 - val_accuracy: 0.9845\n",
      "Epoch 2616/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.1345 - val_accuracy: 0.9814\n",
      "Epoch 2617/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.1297 - val_accuracy: 0.9814\n",
      "Epoch 2618/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.1303 - val_accuracy: 0.9783\n",
      "Epoch 2619/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.1312 - val_accuracy: 0.9845\n",
      "Epoch 2620/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9990 - val_loss: 0.1328 - val_accuracy: 0.9814\n",
      "Epoch 2621/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9845\n",
      "Epoch 2622/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.1332 - val_accuracy: 0.9814\n",
      "Epoch 2623/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.1295 - val_accuracy: 0.9814\n",
      "Epoch 2624/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1302 - val_accuracy: 0.9814\n",
      "Epoch 2625/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.1317 - val_accuracy: 0.9845\n",
      "Epoch 2626/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.1316 - val_accuracy: 0.9845\n",
      "Epoch 2627/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.1335 - val_accuracy: 0.9814\n",
      "Epoch 2628/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.1315 - val_accuracy: 0.9814\n",
      "Epoch 2629/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.1320 - val_accuracy: 0.9783\n",
      "Epoch 2630/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1311 - val_accuracy: 0.9783\n",
      "Epoch 2631/3500\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1322 - val_accuracy: 0.9845\n",
      "Epoch 2632/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1334 - val_accuracy: 0.9845\n",
      "Epoch 2633/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.1321 - val_accuracy: 0.9814\n",
      "Epoch 2634/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9783\n",
      "Epoch 2635/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.1318 - val_accuracy: 0.9783\n",
      "Epoch 2636/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.1328 - val_accuracy: 0.9814\n",
      "Epoch 2637/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.1314 - val_accuracy: 0.9814\n",
      "Epoch 2638/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.1318 - val_accuracy: 0.9814\n",
      "Epoch 2639/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1315 - val_accuracy: 0.9814\n",
      "Epoch 2640/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.9845\n",
      "Epoch 2641/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 0.9966 - val_loss: 0.1323 - val_accuracy: 0.9783\n",
      "Epoch 2642/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.1347 - val_accuracy: 0.9783\n",
      "Epoch 2643/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 0.9946 - val_loss: 0.1319 - val_accuracy: 0.9814\n",
      "Epoch 2644/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1356 - val_accuracy: 0.9783\n",
      "Epoch 2645/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.1331 - val_accuracy: 0.9783\n",
      "Epoch 2646/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.1322 - val_accuracy: 0.9814\n",
      "Epoch 2647/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.1330 - val_accuracy: 0.9814\n",
      "Epoch 2648/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9814\n",
      "Epoch 2649/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.1335 - val_accuracy: 0.9845\n",
      "Epoch 2650/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0079 - accuracy: 0.9966 - val_loss: 0.1324 - val_accuracy: 0.9814\n",
      "Epoch 2651/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.1341 - val_accuracy: 0.9845\n",
      "Epoch 2652/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1349 - val_accuracy: 0.9814\n",
      "Epoch 2653/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.1324 - val_accuracy: 0.9814\n",
      "Epoch 2654/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.1340 - val_accuracy: 0.9783\n",
      "Epoch 2655/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.1346 - val_accuracy: 0.9814\n",
      "Epoch 2656/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1366 - val_accuracy: 0.9814\n",
      "Epoch 2657/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.1355 - val_accuracy: 0.9814\n",
      "Epoch 2658/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.1346 - val_accuracy: 0.9814\n",
      "Epoch 2659/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1333 - val_accuracy: 0.9845\n",
      "Epoch 2660/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.1338 - val_accuracy: 0.9814\n",
      "Epoch 2661/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.1317 - val_accuracy: 0.9783\n",
      "Epoch 2662/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.1340 - val_accuracy: 0.9783\n",
      "Epoch 2663/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.1320 - val_accuracy: 0.9814\n",
      "Epoch 2664/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.1381 - val_accuracy: 0.9783\n",
      "Epoch 2665/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.1302 - val_accuracy: 0.9814\n",
      "Epoch 2666/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.1359 - val_accuracy: 0.9783\n",
      "Epoch 2667/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.1306 - val_accuracy: 0.9783\n",
      "Epoch 2668/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 0.9966 - val_loss: 0.1346 - val_accuracy: 0.9814\n",
      "Epoch 2669/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1309 - val_accuracy: 0.9783\n",
      "Epoch 2670/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0079 - accuracy: 0.9956 - val_loss: 0.1304 - val_accuracy: 0.9814\n",
      "Epoch 2671/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.1322 - val_accuracy: 0.9814\n",
      "Epoch 2672/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.1312 - val_accuracy: 0.9814\n",
      "Epoch 2673/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1319 - val_accuracy: 0.9783\n",
      "Epoch 2674/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.1321 - val_accuracy: 0.9783\n",
      "Epoch 2675/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.1323 - val_accuracy: 0.9814\n",
      "Epoch 2676/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1323 - val_accuracy: 0.9845\n",
      "Epoch 2677/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.1340 - val_accuracy: 0.9783\n",
      "Epoch 2678/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1337 - val_accuracy: 0.9814\n",
      "Epoch 2679/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9783\n",
      "Epoch 2680/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.1345 - val_accuracy: 0.9814\n",
      "Epoch 2681/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0081 - accuracy: 0.9990 - val_loss: 0.1374 - val_accuracy: 0.9814\n",
      "Epoch 2682/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.1334 - val_accuracy: 0.9814\n",
      "Epoch 2683/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9845\n",
      "Epoch 2684/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.1332 - val_accuracy: 0.9814\n",
      "Epoch 2685/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9814\n",
      "Epoch 2686/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.1336 - val_accuracy: 0.9845\n",
      "Epoch 2687/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9814\n",
      "Epoch 2688/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.1333 - val_accuracy: 0.9845\n",
      "Epoch 2689/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.1348 - val_accuracy: 0.9783\n",
      "Epoch 2690/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.1357 - val_accuracy: 0.9814\n",
      "Epoch 2691/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9990 - val_loss: 0.1359 - val_accuracy: 0.9845\n",
      "Epoch 2692/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.1434 - val_accuracy: 0.9752\n",
      "Epoch 2693/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1348 - val_accuracy: 0.9814\n",
      "Epoch 2694/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9783\n",
      "Epoch 2695/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.1341 - val_accuracy: 0.9814\n",
      "Epoch 2696/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.1356 - val_accuracy: 0.9814\n",
      "Epoch 2697/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.1337 - val_accuracy: 0.9783\n",
      "Epoch 2698/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1340 - val_accuracy: 0.9783\n",
      "Epoch 2699/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.1319 - val_accuracy: 0.9814\n",
      "Epoch 2700/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9752\n",
      "Epoch 2701/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.1286 - val_accuracy: 0.9814\n",
      "Epoch 2702/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.1280 - val_accuracy: 0.9783\n",
      "Epoch 2703/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.1279 - val_accuracy: 0.9814\n",
      "Epoch 2704/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.1313 - val_accuracy: 0.9783\n",
      "Epoch 2705/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9783\n",
      "Epoch 2706/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1301 - val_accuracy: 0.9783\n",
      "Epoch 2707/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.1311 - val_accuracy: 0.9783\n",
      "Epoch 2708/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.1321 - val_accuracy: 0.9845\n",
      "Epoch 2709/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.1336 - val_accuracy: 0.9845\n",
      "Epoch 2710/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0101 - accuracy: 0.9949 - val_loss: 0.1335 - val_accuracy: 0.9845\n",
      "Epoch 2711/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.1334 - val_accuracy: 0.9814\n",
      "Epoch 2712/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.1333 - val_accuracy: 0.9814\n",
      "Epoch 2713/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1337 - val_accuracy: 0.9814\n",
      "Epoch 2714/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.1340 - val_accuracy: 0.9814\n",
      "Epoch 2715/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9845\n",
      "Epoch 2716/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1364 - val_accuracy: 0.9845\n",
      "Epoch 2717/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1354 - val_accuracy: 0.9814\n",
      "Epoch 2718/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9814\n",
      "Epoch 2719/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1361 - val_accuracy: 0.9783\n",
      "Epoch 2720/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1369 - val_accuracy: 0.9814\n",
      "Epoch 2721/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.1364 - val_accuracy: 0.9814\n",
      "Epoch 2722/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9845\n",
      "Epoch 2723/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.1345 - val_accuracy: 0.9814\n",
      "Epoch 2724/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.1343 - val_accuracy: 0.9783\n",
      "Epoch 2725/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0081 - accuracy: 0.9966 - val_loss: 0.1342 - val_accuracy: 0.9783\n",
      "Epoch 2726/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.1343 - val_accuracy: 0.9814\n",
      "Epoch 2727/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1356 - val_accuracy: 0.9845\n",
      "Epoch 2728/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9845\n",
      "Epoch 2729/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9814\n",
      "Epoch 2730/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.1345 - val_accuracy: 0.9814\n",
      "Epoch 2731/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1352 - val_accuracy: 0.9814\n",
      "Epoch 2732/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.1368 - val_accuracy: 0.9814\n",
      "Epoch 2733/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1365 - val_accuracy: 0.9814\n",
      "Epoch 2734/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.1380 - val_accuracy: 0.9814\n",
      "Epoch 2735/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.1368 - val_accuracy: 0.9814\n",
      "Epoch 2736/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1365 - val_accuracy: 0.9814\n",
      "Epoch 2737/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.1361 - val_accuracy: 0.9814\n",
      "Epoch 2738/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9814\n",
      "Epoch 2739/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1375 - val_accuracy: 0.9814\n",
      "Epoch 2740/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.1367 - val_accuracy: 0.9845\n",
      "Epoch 2741/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9845\n",
      "Epoch 2742/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1355 - val_accuracy: 0.9814\n",
      "Epoch 2743/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9814\n",
      "Epoch 2744/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1352 - val_accuracy: 0.9814\n",
      "Epoch 2745/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1363 - val_accuracy: 0.9783\n",
      "Epoch 2746/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1373 - val_accuracy: 0.9845\n",
      "Epoch 2747/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1379 - val_accuracy: 0.9814\n",
      "Epoch 2748/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.1389 - val_accuracy: 0.9814\n",
      "Epoch 2749/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.1356 - val_accuracy: 0.9814\n",
      "Epoch 2750/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9783\n",
      "Epoch 2751/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1354 - val_accuracy: 0.9783\n",
      "Epoch 2752/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1403 - val_accuracy: 0.9752\n",
      "Epoch 2753/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1368 - val_accuracy: 0.9814\n",
      "Epoch 2754/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.1370 - val_accuracy: 0.9814\n",
      "Epoch 2755/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0079 - accuracy: 0.9966 - val_loss: 0.1392 - val_accuracy: 0.9814\n",
      "Epoch 2756/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.1369 - val_accuracy: 0.9814\n",
      "Epoch 2757/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1420 - val_accuracy: 0.9783\n",
      "Epoch 2758/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.1373 - val_accuracy: 0.9814\n",
      "Epoch 2759/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.1402 - val_accuracy: 0.9783\n",
      "Epoch 2760/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.1391 - val_accuracy: 0.9783\n",
      "Epoch 2761/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1379 - val_accuracy: 0.9814\n",
      "Epoch 2762/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1387 - val_accuracy: 0.9814\n",
      "Epoch 2763/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1371 - val_accuracy: 0.9845\n",
      "Epoch 2764/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9814\n",
      "Epoch 2765/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1359 - val_accuracy: 0.9845\n",
      "Epoch 2766/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1359 - val_accuracy: 0.9845\n",
      "Epoch 2767/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.1350 - val_accuracy: 0.9845\n",
      "Epoch 2768/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9845\n",
      "Epoch 2769/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9845\n",
      "Epoch 2770/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1365 - val_accuracy: 0.9876\n",
      "Epoch 2771/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.1349 - val_accuracy: 0.9783\n",
      "Epoch 2772/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1335 - val_accuracy: 0.9752\n",
      "Epoch 2773/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1320 - val_accuracy: 0.9752\n",
      "Epoch 2774/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.1306 - val_accuracy: 0.9814\n",
      "Epoch 2775/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9814\n",
      "Epoch 2776/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.1318 - val_accuracy: 0.9845\n",
      "Epoch 2777/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9752\n",
      "Epoch 2778/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1356 - val_accuracy: 0.9752\n",
      "Epoch 2779/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 0.1324 - val_accuracy: 0.9783\n",
      "Epoch 2780/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 0.9966 - val_loss: 0.1363 - val_accuracy: 0.9752\n",
      "Epoch 2781/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.1340 - val_accuracy: 0.9845\n",
      "Epoch 2782/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.1449 - val_accuracy: 0.9814\n",
      "Epoch 2783/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0204 - accuracy: 0.9916 - val_loss: 0.1348 - val_accuracy: 0.9783\n",
      "Epoch 2784/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0078 - accuracy: 0.9966 - val_loss: 0.1375 - val_accuracy: 0.9752\n",
      "Epoch 2785/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.1346 - val_accuracy: 0.9783\n",
      "Epoch 2786/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9783\n",
      "Epoch 2787/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1344 - val_accuracy: 0.9814\n",
      "Epoch 2788/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.1347 - val_accuracy: 0.9814\n",
      "Epoch 2789/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9814\n",
      "Epoch 2790/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.1358 - val_accuracy: 0.9845\n",
      "Epoch 2791/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1383 - val_accuracy: 0.9783\n",
      "Epoch 2792/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1362 - val_accuracy: 0.9845\n",
      "Epoch 2793/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9783\n",
      "Epoch 2794/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1375 - val_accuracy: 0.9783\n",
      "Epoch 2795/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1384 - val_accuracy: 0.9814\n",
      "Epoch 2796/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9845\n",
      "Epoch 2797/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.1392 - val_accuracy: 0.9814\n",
      "Epoch 2798/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9814\n",
      "Epoch 2799/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.1383 - val_accuracy: 0.9814\n",
      "Epoch 2800/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9814\n",
      "Epoch 2801/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.1392 - val_accuracy: 0.9845\n",
      "Epoch 2802/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9814\n",
      "Epoch 2803/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.1405 - val_accuracy: 0.9845\n",
      "Epoch 2804/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1405 - val_accuracy: 0.9814\n",
      "Epoch 2805/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1381 - val_accuracy: 0.9814\n",
      "Epoch 2806/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1379 - val_accuracy: 0.9783\n",
      "Epoch 2807/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.1374 - val_accuracy: 0.9814\n",
      "Epoch 2808/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 0.9966 - val_loss: 0.1399 - val_accuracy: 0.9845\n",
      "Epoch 2809/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9876\n",
      "Epoch 2810/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1397 - val_accuracy: 0.9845\n",
      "Epoch 2811/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1390 - val_accuracy: 0.9845\n",
      "Epoch 2812/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1387 - val_accuracy: 0.9845\n",
      "Epoch 2813/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.1379 - val_accuracy: 0.9814\n",
      "Epoch 2814/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.1391 - val_accuracy: 0.9814\n",
      "Epoch 2815/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1420 - val_accuracy: 0.9876\n",
      "Epoch 2816/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.1437 - val_accuracy: 0.9814\n",
      "Epoch 2817/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.1409 - val_accuracy: 0.9845\n",
      "Epoch 2818/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1404 - val_accuracy: 0.9783\n",
      "Epoch 2819/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1390 - val_accuracy: 0.9814\n",
      "Epoch 2820/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0079 - accuracy: 0.9966 - val_loss: 0.1424 - val_accuracy: 0.9814\n",
      "Epoch 2821/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.1399 - val_accuracy: 0.9845\n",
      "Epoch 2822/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9845\n",
      "Epoch 2823/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1412 - val_accuracy: 0.9814\n",
      "Epoch 2824/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.1410 - val_accuracy: 0.9845\n",
      "Epoch 2825/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9783\n",
      "Epoch 2826/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9814\n",
      "Epoch 2827/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1399 - val_accuracy: 0.9783\n",
      "Epoch 2828/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.1398 - val_accuracy: 0.9845\n",
      "Epoch 2829/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1395 - val_accuracy: 0.9845\n",
      "Epoch 2830/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1383 - val_accuracy: 0.9814\n",
      "Epoch 2831/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.1390 - val_accuracy: 0.9814\n",
      "Epoch 2832/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1393 - val_accuracy: 0.9814\n",
      "Epoch 2833/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9783\n",
      "Epoch 2834/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9845\n",
      "Epoch 2835/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9814\n",
      "Epoch 2836/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1410 - val_accuracy: 0.9783\n",
      "Epoch 2837/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1409 - val_accuracy: 0.9814\n",
      "Epoch 2838/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9814\n",
      "Epoch 2839/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9845\n",
      "Epoch 2840/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9814\n",
      "Epoch 2841/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.1403 - val_accuracy: 0.9845\n",
      "Epoch 2842/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.1413 - val_accuracy: 0.9814\n",
      "Epoch 2843/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1409 - val_accuracy: 0.9814\n",
      "Epoch 2844/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.1423 - val_accuracy: 0.9814\n",
      "Epoch 2845/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1419 - val_accuracy: 0.9814\n",
      "Epoch 2846/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.1405 - val_accuracy: 0.9814\n",
      "Epoch 2847/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9973 - val_loss: 0.1404 - val_accuracy: 0.9783\n",
      "Epoch 2848/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1402 - val_accuracy: 0.9814\n",
      "Epoch 2849/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9814\n",
      "Epoch 2850/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9845\n",
      "Epoch 2851/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9845\n",
      "Epoch 2852/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1402 - val_accuracy: 0.9845\n",
      "Epoch 2853/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9814\n",
      "Epoch 2854/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9845\n",
      "Epoch 2855/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.1395 - val_accuracy: 0.9814\n",
      "Epoch 2856/3500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.1405 - val_accuracy: 0.9845\n",
      "Epoch 2857/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1436 - val_accuracy: 0.9783\n",
      "Epoch 2858/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.1403 - val_accuracy: 0.9783\n",
      "Epoch 2859/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1444 - val_accuracy: 0.9814\n",
      "Epoch 2860/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.1405 - val_accuracy: 0.9814\n",
      "Epoch 2861/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9814\n",
      "Epoch 2862/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 0.1411 - val_accuracy: 0.9814\n",
      "Epoch 2863/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9814\n",
      "Epoch 2864/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 0.9966 - val_loss: 0.1423 - val_accuracy: 0.9845\n",
      "Epoch 2865/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9845\n",
      "Epoch 2866/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.1403 - val_accuracy: 0.9814\n",
      "Epoch 2867/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.1416 - val_accuracy: 0.9814\n",
      "Epoch 2868/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1404 - val_accuracy: 0.9814\n",
      "Epoch 2869/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9783\n",
      "Epoch 2870/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1402 - val_accuracy: 0.9845\n",
      "Epoch 2871/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9783\n",
      "Epoch 2872/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1391 - val_accuracy: 0.9845\n",
      "Epoch 2873/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9783\n",
      "Epoch 2874/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1413 - val_accuracy: 0.9814\n",
      "Epoch 2875/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1427 - val_accuracy: 0.9783\n",
      "Epoch 2876/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1426 - val_accuracy: 0.9814\n",
      "Epoch 2877/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9814\n",
      "Epoch 2878/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9783\n",
      "Epoch 2879/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9783\n",
      "Epoch 2880/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9783\n",
      "Epoch 2881/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.1459 - val_accuracy: 0.9814\n",
      "Epoch 2882/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.1431 - val_accuracy: 0.9876\n",
      "Epoch 2883/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9752\n",
      "Epoch 2884/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0141 - accuracy: 0.9932 - val_loss: 0.1402 - val_accuracy: 0.9814\n",
      "Epoch 2885/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9783\n",
      "Epoch 2886/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1405 - val_accuracy: 0.9845\n",
      "Epoch 2887/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.1440 - val_accuracy: 0.9783\n",
      "Epoch 2888/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0081 - accuracy: 0.9966 - val_loss: 0.1417 - val_accuracy: 0.9814\n",
      "Epoch 2889/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 0.1417 - val_accuracy: 0.9845\n",
      "Epoch 2890/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1478 - val_accuracy: 0.9783\n",
      "Epoch 2891/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.1432 - val_accuracy: 0.9814\n",
      "Epoch 2892/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9814\n",
      "Epoch 2893/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.1437 - val_accuracy: 0.9783\n",
      "Epoch 2894/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1440 - val_accuracy: 0.9752\n",
      "Epoch 2895/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.1432 - val_accuracy: 0.9783\n",
      "Epoch 2896/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1434 - val_accuracy: 0.9783\n",
      "Epoch 2897/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1433 - val_accuracy: 0.9783\n",
      "Epoch 2898/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.1458 - val_accuracy: 0.9783\n",
      "Epoch 2899/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.1431 - val_accuracy: 0.9783\n",
      "Epoch 2900/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9814\n",
      "Epoch 2901/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0130 - accuracy: 0.9939 - val_loss: 0.1422 - val_accuracy: 0.9814\n",
      "Epoch 2902/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9973 - val_loss: 0.1533 - val_accuracy: 0.9752\n",
      "Epoch 2903/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 0.1409 - val_accuracy: 0.9814\n",
      "Epoch 2904/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1537 - val_accuracy: 0.9814\n",
      "Epoch 2905/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.1404 - val_accuracy: 0.9814\n",
      "Epoch 2906/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.1576 - val_accuracy: 0.9720\n",
      "Epoch 2907/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0150 - accuracy: 0.9899 - val_loss: 0.1426 - val_accuracy: 0.9845\n",
      "Epoch 2908/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1452 - val_accuracy: 0.9814\n",
      "Epoch 2909/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1490 - val_accuracy: 0.9783\n",
      "Epoch 2910/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9956 - val_loss: 0.1412 - val_accuracy: 0.9814\n",
      "Epoch 2911/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9783\n",
      "Epoch 2912/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.1426 - val_accuracy: 0.9783\n",
      "Epoch 2913/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.1482 - val_accuracy: 0.9752\n",
      "Epoch 2914/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1426 - val_accuracy: 0.9783\n",
      "Epoch 2915/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9814\n",
      "Epoch 2916/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0083 - accuracy: 0.9966 - val_loss: 0.1457 - val_accuracy: 0.9814\n",
      "Epoch 2917/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.1471 - val_accuracy: 0.9814\n",
      "Epoch 2918/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.1438 - val_accuracy: 0.9814\n",
      "Epoch 2919/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.1426 - val_accuracy: 0.9783\n",
      "Epoch 2920/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0072 - accuracy: 0.9966 - val_loss: 0.1424 - val_accuracy: 0.9783\n",
      "Epoch 2921/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9973 - val_loss: 0.1428 - val_accuracy: 0.9814\n",
      "Epoch 2922/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.1467 - val_accuracy: 0.9783\n",
      "Epoch 2923/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1433 - val_accuracy: 0.9845\n",
      "Epoch 2924/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9814\n",
      "Epoch 2925/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.1442 - val_accuracy: 0.9814\n",
      "Epoch 2926/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.1426 - val_accuracy: 0.9814\n",
      "Epoch 2927/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9752\n",
      "Epoch 2928/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9966 - val_loss: 0.1435 - val_accuracy: 0.9814\n",
      "Epoch 2929/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1416 - val_accuracy: 0.9814\n",
      "Epoch 2930/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9783\n",
      "Epoch 2931/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1420 - val_accuracy: 0.9845\n",
      "Epoch 2932/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9814\n",
      "Epoch 2933/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.1420 - val_accuracy: 0.9845\n",
      "Epoch 2934/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9783\n",
      "Epoch 2935/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.1434 - val_accuracy: 0.9814\n",
      "Epoch 2936/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9783\n",
      "Epoch 2937/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.1437 - val_accuracy: 0.9814\n",
      "Epoch 2938/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9814\n",
      "Epoch 2939/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.1430 - val_accuracy: 0.9814\n",
      "Epoch 2940/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9752\n",
      "Epoch 2941/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.1438 - val_accuracy: 0.9783\n",
      "Epoch 2942/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9814\n",
      "Epoch 2943/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9956 - val_loss: 0.1442 - val_accuracy: 0.9783\n",
      "Epoch 2944/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1460 - val_accuracy: 0.9783\n",
      "Epoch 2945/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.1447 - val_accuracy: 0.9783\n",
      "Epoch 2946/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.1425 - val_accuracy: 0.9783\n",
      "Epoch 2947/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1435 - val_accuracy: 0.9845\n",
      "Epoch 2948/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9845\n",
      "Epoch 2949/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9845\n",
      "Epoch 2950/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9876\n",
      "Epoch 2951/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9814\n",
      "Epoch 2952/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9814\n",
      "Epoch 2953/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1428 - val_accuracy: 0.9814\n",
      "Epoch 2954/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1431 - val_accuracy: 0.9814\n",
      "Epoch 2955/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9814\n",
      "Epoch 2956/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1447 - val_accuracy: 0.9814\n",
      "Epoch 2957/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.9814\n",
      "Epoch 2958/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.1458 - val_accuracy: 0.9783\n",
      "Epoch 2959/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9814\n",
      "Epoch 2960/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9814\n",
      "Epoch 2961/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1449 - val_accuracy: 0.9814\n",
      "Epoch 2962/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9814\n",
      "Epoch 2963/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.1451 - val_accuracy: 0.9783\n",
      "Epoch 2964/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9783\n",
      "Epoch 2965/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.1439 - val_accuracy: 0.9814\n",
      "Epoch 2966/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9783\n",
      "Epoch 2967/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1430 - val_accuracy: 0.9783\n",
      "Epoch 2968/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.1437 - val_accuracy: 0.9814\n",
      "Epoch 2969/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9814\n",
      "Epoch 2970/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9814\n",
      "Epoch 2971/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9814\n",
      "Epoch 2972/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9845\n",
      "Epoch 2973/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1452 - val_accuracy: 0.9845\n",
      "Epoch 2974/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9783\n",
      "Epoch 2975/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.1456 - val_accuracy: 0.9845\n",
      "Epoch 2976/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9814\n",
      "Epoch 2977/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.1471 - val_accuracy: 0.9814\n",
      "Epoch 2978/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1448 - val_accuracy: 0.9814\n",
      "Epoch 2979/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9752\n",
      "Epoch 2980/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1444 - val_accuracy: 0.9814\n",
      "Epoch 2981/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9814\n",
      "Epoch 2982/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9814\n",
      "Epoch 2983/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9814\n",
      "Epoch 2984/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9814\n",
      "Epoch 2985/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9783\n",
      "Epoch 2986/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.1418 - val_accuracy: 0.9814\n",
      "Epoch 2987/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9783\n",
      "Epoch 2988/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9814\n",
      "Epoch 2989/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9783\n",
      "Epoch 2990/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1446 - val_accuracy: 0.9783\n",
      "Epoch 2991/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.1439 - val_accuracy: 0.9783\n",
      "Epoch 2992/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9752\n",
      "Epoch 2993/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.1456 - val_accuracy: 0.9783\n",
      "Epoch 2994/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9783\n",
      "Epoch 2995/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.1475 - val_accuracy: 0.9814\n",
      "Epoch 2996/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.1511 - val_accuracy: 0.9783\n",
      "Epoch 2997/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1470 - val_accuracy: 0.9814\n",
      "Epoch 2998/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9814\n",
      "Epoch 2999/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.1468 - val_accuracy: 0.9783\n",
      "Epoch 3000/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1524 - val_accuracy: 0.9783\n",
      "Epoch 3001/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 0.9966 - val_loss: 0.1498 - val_accuracy: 0.9783\n",
      "Epoch 3002/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9814\n",
      "Epoch 3003/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.1477 - val_accuracy: 0.9845\n",
      "Epoch 3004/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1611 - val_accuracy: 0.9752\n",
      "Epoch 3005/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.1461 - val_accuracy: 0.9845\n",
      "Epoch 3006/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.1533 - val_accuracy: 0.9783\n",
      "Epoch 3007/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.1463 - val_accuracy: 0.9783\n",
      "Epoch 3008/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9966 - val_loss: 0.1540 - val_accuracy: 0.9720\n",
      "Epoch 3009/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.1478 - val_accuracy: 0.9783\n",
      "Epoch 3010/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1520 - val_accuracy: 0.9814\n",
      "Epoch 3011/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.1479 - val_accuracy: 0.9814\n",
      "Epoch 3012/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 0.9966 - val_loss: 0.1517 - val_accuracy: 0.9783\n",
      "Epoch 3013/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.1463 - val_accuracy: 0.9814\n",
      "Epoch 3014/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.1487 - val_accuracy: 0.9783\n",
      "Epoch 3015/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.1451 - val_accuracy: 0.9783\n",
      "Epoch 3016/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1539 - val_accuracy: 0.9783\n",
      "Epoch 3017/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.1471 - val_accuracy: 0.9814\n",
      "Epoch 3018/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9973 - val_loss: 0.1458 - val_accuracy: 0.9783\n",
      "Epoch 3019/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.1444 - val_accuracy: 0.9814\n",
      "Epoch 3020/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1480 - val_accuracy: 0.9783\n",
      "Epoch 3021/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1465 - val_accuracy: 0.9845\n",
      "Epoch 3022/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9814\n",
      "Epoch 3023/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1467 - val_accuracy: 0.9845\n",
      "Epoch 3024/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9845\n",
      "Epoch 3025/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9845\n",
      "Epoch 3026/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9814\n",
      "Epoch 3027/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.1466 - val_accuracy: 0.9814\n",
      "Epoch 3028/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9783\n",
      "Epoch 3029/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9814\n",
      "Epoch 3030/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9814\n",
      "Epoch 3031/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.1482 - val_accuracy: 0.9783\n",
      "Epoch 3032/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.1471 - val_accuracy: 0.9814\n",
      "Epoch 3033/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9783\n",
      "Epoch 3034/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9814\n",
      "Epoch 3035/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9783\n",
      "Epoch 3036/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9814\n",
      "Epoch 3037/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9814\n",
      "Epoch 3038/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9814\n",
      "Epoch 3039/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9814\n",
      "Epoch 3040/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9814\n",
      "Epoch 3041/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9814\n",
      "Epoch 3042/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9783\n",
      "Epoch 3043/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9814\n",
      "Epoch 3044/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9814\n",
      "Epoch 3045/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9783\n",
      "Epoch 3046/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9814\n",
      "Epoch 3047/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9845\n",
      "Epoch 3048/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9845\n",
      "Epoch 3049/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9845\n",
      "Epoch 3050/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9814\n",
      "Epoch 3051/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9814\n",
      "Epoch 3052/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.1471 - val_accuracy: 0.9814\n",
      "Epoch 3053/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.1479 - val_accuracy: 0.9783\n",
      "Epoch 3054/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9814\n",
      "Epoch 3055/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9814\n",
      "Epoch 3056/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1495 - val_accuracy: 0.9814\n",
      "Epoch 3057/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9783\n",
      "Epoch 3058/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9752\n",
      "Epoch 3059/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1485 - val_accuracy: 0.9752\n",
      "Epoch 3060/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9814\n",
      "Epoch 3061/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.1515 - val_accuracy: 0.9814\n",
      "Epoch 3062/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9783\n",
      "Epoch 3063/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1495 - val_accuracy: 0.9814\n",
      "Epoch 3064/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1474 - val_accuracy: 0.9783\n",
      "Epoch 3065/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0061 - accuracy: 0.9973 - val_loss: 0.1484 - val_accuracy: 0.9783\n",
      "Epoch 3066/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9814\n",
      "Epoch 3067/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9783\n",
      "Epoch 3068/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1467 - val_accuracy: 0.9814\n",
      "Epoch 3069/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9783\n",
      "Epoch 3070/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1461 - val_accuracy: 0.9783\n",
      "Epoch 3071/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.1478 - val_accuracy: 0.9752\n",
      "Epoch 3072/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9845\n",
      "Epoch 3073/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 0.1464 - val_accuracy: 0.9845\n",
      "Epoch 3074/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9752\n",
      "Epoch 3075/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.1475 - val_accuracy: 0.9783\n",
      "Epoch 3076/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9783\n",
      "Epoch 3077/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.1505 - val_accuracy: 0.9814\n",
      "Epoch 3078/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0076 - accuracy: 0.9966 - val_loss: 0.1501 - val_accuracy: 0.9783\n",
      "Epoch 3079/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.1528 - val_accuracy: 0.9783\n",
      "Epoch 3080/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1473 - val_accuracy: 0.9814\n",
      "Epoch 3081/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9783\n",
      "Epoch 3082/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1483 - val_accuracy: 0.9814\n",
      "Epoch 3083/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9814\n",
      "Epoch 3084/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9814\n",
      "Epoch 3085/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9814\n",
      "Epoch 3086/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9814\n",
      "Epoch 3087/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9814\n",
      "Epoch 3088/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9814\n",
      "Epoch 3089/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9814\n",
      "Epoch 3090/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9814\n",
      "Epoch 3091/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9814\n",
      "Epoch 3092/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9783\n",
      "Epoch 3093/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9783\n",
      "Epoch 3094/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9814\n",
      "Epoch 3095/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9814\n",
      "Epoch 3096/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9783\n",
      "Epoch 3097/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9783\n",
      "Epoch 3098/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9814\n",
      "Epoch 3099/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9814\n",
      "Epoch 3100/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9783\n",
      "Epoch 3101/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9814\n",
      "Epoch 3102/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1514 - val_accuracy: 0.9783\n",
      "Epoch 3103/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9783\n",
      "Epoch 3104/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9783\n",
      "Epoch 3105/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9783\n",
      "Epoch 3106/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9845\n",
      "Epoch 3107/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9814\n",
      "Epoch 3108/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1500 - val_accuracy: 0.9814\n",
      "Epoch 3109/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.1519 - val_accuracy: 0.9783\n",
      "Epoch 3110/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9783\n",
      "Epoch 3111/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9845\n",
      "Epoch 3112/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9845\n",
      "Epoch 3113/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9783\n",
      "Epoch 3114/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9814\n",
      "Epoch 3115/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9845\n",
      "Epoch 3116/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9814\n",
      "Epoch 3117/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9814\n",
      "Epoch 3118/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9752\n",
      "Epoch 3119/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 0.9966 - val_loss: 0.1501 - val_accuracy: 0.9783\n",
      "Epoch 3120/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9783\n",
      "Epoch 3121/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1504 - val_accuracy: 0.9783\n",
      "Epoch 3122/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.1499 - val_accuracy: 0.9814\n",
      "Epoch 3123/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9752\n",
      "Epoch 3124/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1486 - val_accuracy: 0.9814\n",
      "Epoch 3125/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9783\n",
      "Epoch 3126/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1489 - val_accuracy: 0.9814\n",
      "Epoch 3127/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9783\n",
      "Epoch 3128/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9814\n",
      "Epoch 3129/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9814\n",
      "Epoch 3130/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9814\n",
      "Epoch 3131/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9814\n",
      "Epoch 3132/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9783\n",
      "Epoch 3133/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9783\n",
      "Epoch 3134/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9814\n",
      "Epoch 3135/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9814\n",
      "Epoch 3136/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9814\n",
      "Epoch 3137/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9814\n",
      "Epoch 3138/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1553 - val_accuracy: 0.9814\n",
      "Epoch 3139/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1527 - val_accuracy: 0.9814\n",
      "Epoch 3140/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9814\n",
      "Epoch 3141/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9814\n",
      "Epoch 3142/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9783\n",
      "Epoch 3143/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9845\n",
      "Epoch 3144/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9845\n",
      "Epoch 3145/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9814\n",
      "Epoch 3146/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9814\n",
      "Epoch 3147/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9783\n",
      "Epoch 3148/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9783\n",
      "Epoch 3149/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9845\n",
      "Epoch 3150/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.1584 - val_accuracy: 0.9814\n",
      "Epoch 3151/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.1585 - val_accuracy: 0.9783\n",
      "Epoch 3152/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.1529 - val_accuracy: 0.9814\n",
      "Epoch 3153/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9783\n",
      "Epoch 3154/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.1525 - val_accuracy: 0.9814\n",
      "Epoch 3155/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.1576 - val_accuracy: 0.9783\n",
      "Epoch 3156/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9845\n",
      "Epoch 3157/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.1564 - val_accuracy: 0.9814\n",
      "Epoch 3158/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9966 - val_loss: 0.1529 - val_accuracy: 0.9845\n",
      "Epoch 3159/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9783\n",
      "Epoch 3160/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.1515 - val_accuracy: 0.9814\n",
      "Epoch 3161/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0061 - accuracy: 0.9973 - val_loss: 0.1514 - val_accuracy: 0.9814\n",
      "Epoch 3162/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1533 - val_accuracy: 0.9814\n",
      "Epoch 3163/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9845\n",
      "Epoch 3164/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9814\n",
      "Epoch 3165/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1562 - val_accuracy: 0.9814\n",
      "Epoch 3166/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9783\n",
      "Epoch 3167/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9783\n",
      "Epoch 3168/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1526 - val_accuracy: 0.9783\n",
      "Epoch 3169/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1524 - val_accuracy: 0.9783\n",
      "Epoch 3170/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.1533 - val_accuracy: 0.9783\n",
      "Epoch 3171/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9814\n",
      "Epoch 3172/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.1569 - val_accuracy: 0.9783\n",
      "Epoch 3173/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9783\n",
      "Epoch 3174/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1563 - val_accuracy: 0.9752\n",
      "Epoch 3175/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.1547 - val_accuracy: 0.9752\n",
      "Epoch 3176/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.1567 - val_accuracy: 0.9814\n",
      "Epoch 3177/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 0.9966 - val_loss: 0.1600 - val_accuracy: 0.9845\n",
      "Epoch 3178/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1619 - val_accuracy: 0.9783\n",
      "Epoch 3179/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.1585 - val_accuracy: 0.9814\n",
      "Epoch 3180/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1556 - val_accuracy: 0.9783\n",
      "Epoch 3181/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1555 - val_accuracy: 0.9783\n",
      "Epoch 3182/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.1527 - val_accuracy: 0.9752\n",
      "Epoch 3183/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1524 - val_accuracy: 0.9783\n",
      "Epoch 3184/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9783\n",
      "Epoch 3185/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9814\n",
      "Epoch 3186/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.1519 - val_accuracy: 0.9814\n",
      "Epoch 3187/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9814\n",
      "Epoch 3188/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0102 - accuracy: 0.9949 - val_loss: 0.1508 - val_accuracy: 0.9783\n",
      "Epoch 3189/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9752\n",
      "Epoch 3190/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1516 - val_accuracy: 0.9783\n",
      "Epoch 3191/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1598 - val_accuracy: 0.9814\n",
      "Epoch 3192/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1546 - val_accuracy: 0.9814\n",
      "Epoch 3193/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9783\n",
      "Epoch 3194/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.1561 - val_accuracy: 0.9814\n",
      "Epoch 3195/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1577 - val_accuracy: 0.9814\n",
      "Epoch 3196/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0070 - accuracy: 0.9963 - val_loss: 0.1524 - val_accuracy: 0.9814\n",
      "Epoch 3197/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.1663 - val_accuracy: 0.9752\n",
      "Epoch 3198/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.1511 - val_accuracy: 0.9783\n",
      "Epoch 3199/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1569 - val_accuracy: 0.9814\n",
      "Epoch 3200/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 0.9939 - val_loss: 0.1527 - val_accuracy: 0.9814\n",
      "Epoch 3201/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0092 - accuracy: 0.9956 - val_loss: 0.1593 - val_accuracy: 0.9720\n",
      "Epoch 3202/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.1467 - val_accuracy: 0.9783\n",
      "Epoch 3203/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1499 - val_accuracy: 0.9783\n",
      "Epoch 3204/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1482 - val_accuracy: 0.9783\n",
      "Epoch 3205/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.1534 - val_accuracy: 0.9752\n",
      "Epoch 3206/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.9966 - val_loss: 0.1463 - val_accuracy: 0.9814\n",
      "Epoch 3207/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9814\n",
      "Epoch 3208/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.9966 - val_loss: 0.1494 - val_accuracy: 0.9845\n",
      "Epoch 3209/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.1554 - val_accuracy: 0.9783\n",
      "Epoch 3210/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.1535 - val_accuracy: 0.9783\n",
      "Epoch 3211/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.1534 - val_accuracy: 0.9783\n",
      "Epoch 3212/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1556 - val_accuracy: 0.9783\n",
      "Epoch 3213/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1543 - val_accuracy: 0.9752\n",
      "Epoch 3214/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9814\n",
      "Epoch 3215/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9783\n",
      "Epoch 3216/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9752\n",
      "Epoch 3217/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9783\n",
      "Epoch 3218/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9783\n",
      "Epoch 3219/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9783\n",
      "Epoch 3220/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9814\n",
      "Epoch 3221/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9845\n",
      "Epoch 3222/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9845\n",
      "Epoch 3223/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9783\n",
      "Epoch 3224/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9783\n",
      "Epoch 3225/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9814\n",
      "Epoch 3226/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9783\n",
      "Epoch 3227/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9783\n",
      "Epoch 3228/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9783\n",
      "Epoch 3229/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9814\n",
      "Epoch 3230/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.1572 - val_accuracy: 0.9814\n",
      "Epoch 3231/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9783\n",
      "Epoch 3232/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1575 - val_accuracy: 0.9783\n",
      "Epoch 3233/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9783\n",
      "Epoch 3234/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.1564 - val_accuracy: 0.9783\n",
      "Epoch 3235/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.1563 - val_accuracy: 0.9783\n",
      "Epoch 3236/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9783\n",
      "Epoch 3237/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9845\n",
      "Epoch 3238/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9814\n",
      "Epoch 3239/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.1553 - val_accuracy: 0.9783\n",
      "Epoch 3240/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.1633 - val_accuracy: 0.9783\n",
      "Epoch 3241/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.1615 - val_accuracy: 0.9814\n",
      "Epoch 3242/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9956 - val_loss: 0.1632 - val_accuracy: 0.9814\n",
      "Epoch 3243/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.1562 - val_accuracy: 0.9814\n",
      "Epoch 3244/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.1597 - val_accuracy: 0.9752\n",
      "Epoch 3245/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1559 - val_accuracy: 0.9783\n",
      "Epoch 3246/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9814\n",
      "Epoch 3247/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.1579 - val_accuracy: 0.9814\n",
      "Epoch 3248/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.1614 - val_accuracy: 0.9783\n",
      "Epoch 3249/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1552 - val_accuracy: 0.9814\n",
      "Epoch 3250/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1571 - val_accuracy: 0.9783\n",
      "Epoch 3251/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.1550 - val_accuracy: 0.9783\n",
      "Epoch 3252/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.1740 - val_accuracy: 0.9720\n",
      "Epoch 3253/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0139 - accuracy: 0.9932 - val_loss: 0.1598 - val_accuracy: 0.9845\n",
      "Epoch 3254/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.1643 - val_accuracy: 0.9814\n",
      "Epoch 3255/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0129 - accuracy: 0.9949 - val_loss: 0.1591 - val_accuracy: 0.9783\n",
      "Epoch 3256/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.1583 - val_accuracy: 0.9752\n",
      "Epoch 3257/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.1576 - val_accuracy: 0.9783\n",
      "Epoch 3258/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.1546 - val_accuracy: 0.9814\n",
      "Epoch 3259/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1642 - val_accuracy: 0.9783\n",
      "Epoch 3260/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9845\n",
      "Epoch 3261/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.1571 - val_accuracy: 0.9845\n",
      "Epoch 3262/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1563 - val_accuracy: 0.9752\n",
      "Epoch 3263/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9752\n",
      "Epoch 3264/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.1526 - val_accuracy: 0.9783\n",
      "Epoch 3265/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9973 - val_loss: 0.1510 - val_accuracy: 0.9783\n",
      "Epoch 3266/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1514 - val_accuracy: 0.9720\n",
      "Epoch 3267/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9752\n",
      "Epoch 3268/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9783\n",
      "Epoch 3269/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9752\n",
      "Epoch 3270/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9720\n",
      "Epoch 3271/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9752\n",
      "Epoch 3272/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9783\n",
      "Epoch 3273/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9845\n",
      "Epoch 3274/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1518 - val_accuracy: 0.9783\n",
      "Epoch 3275/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9783\n",
      "Epoch 3276/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9752\n",
      "Epoch 3277/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9752\n",
      "Epoch 3278/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9783\n",
      "Epoch 3279/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9845\n",
      "Epoch 3280/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1565 - val_accuracy: 0.9845\n",
      "Epoch 3281/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1556 - val_accuracy: 0.9752\n",
      "Epoch 3282/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9783\n",
      "Epoch 3283/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9814\n",
      "Epoch 3284/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.1567 - val_accuracy: 0.9783\n",
      "Epoch 3285/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1578 - val_accuracy: 0.9783\n",
      "Epoch 3286/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9814\n",
      "Epoch 3287/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9814\n",
      "Epoch 3288/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9814\n",
      "Epoch 3289/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9783\n",
      "Epoch 3290/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9783\n",
      "Epoch 3291/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.1576 - val_accuracy: 0.9814\n",
      "Epoch 3292/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9783\n",
      "Epoch 3293/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9783\n",
      "Epoch 3294/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9783\n",
      "Epoch 3295/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 0.1603 - val_accuracy: 0.9783\n",
      "Epoch 3296/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.9814\n",
      "Epoch 3297/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1597 - val_accuracy: 0.9783\n",
      "Epoch 3298/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1580 - val_accuracy: 0.9783\n",
      "Epoch 3299/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9783\n",
      "Epoch 3300/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9783\n",
      "Epoch 3301/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9814\n",
      "Epoch 3302/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9783\n",
      "Epoch 3303/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9783\n",
      "Epoch 3304/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9845\n",
      "Epoch 3305/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9814\n",
      "Epoch 3306/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9814\n",
      "Epoch 3307/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9814\n",
      "Epoch 3308/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9783\n",
      "Epoch 3309/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9783\n",
      "Epoch 3310/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9814\n",
      "Epoch 3311/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9814\n",
      "Epoch 3312/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9814\n",
      "Epoch 3313/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9814\n",
      "Epoch 3314/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9814\n",
      "Epoch 3315/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9783\n",
      "Epoch 3316/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.1591 - val_accuracy: 0.9752\n",
      "Epoch 3317/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9783\n",
      "Epoch 3318/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9783\n",
      "Epoch 3319/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9814\n",
      "Epoch 3320/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9814\n",
      "Epoch 3321/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9783\n",
      "Epoch 3322/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9783\n",
      "Epoch 3323/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9814\n",
      "Epoch 3324/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9783\n",
      "Epoch 3325/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9814\n",
      "Epoch 3326/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9814\n",
      "Epoch 3327/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9845\n",
      "Epoch 3328/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9845\n",
      "Epoch 3329/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9783\n",
      "Epoch 3330/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9814\n",
      "Epoch 3331/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9845\n",
      "Epoch 3332/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9814\n",
      "Epoch 3333/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9783\n",
      "Epoch 3334/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9814\n",
      "Epoch 3335/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9783\n",
      "Epoch 3336/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9814\n",
      "Epoch 3337/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9814\n",
      "Epoch 3338/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.1586 - val_accuracy: 0.9783\n",
      "Epoch 3339/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9783\n",
      "Epoch 3340/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9783\n",
      "Epoch 3341/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9783\n",
      "Epoch 3342/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9783\n",
      "Epoch 3343/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9783\n",
      "Epoch 3344/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9814\n",
      "Epoch 3345/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9783\n",
      "Epoch 3346/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9783\n",
      "Epoch 3347/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9814\n",
      "Epoch 3348/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9814\n",
      "Epoch 3349/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9814\n",
      "Epoch 3350/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9783\n",
      "Epoch 3351/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1624 - val_accuracy: 0.9752\n",
      "Epoch 3352/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1591 - val_accuracy: 0.9814\n",
      "Epoch 3353/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9814\n",
      "Epoch 3354/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9814\n",
      "Epoch 3355/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9783\n",
      "Epoch 3356/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9814\n",
      "Epoch 3357/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9752\n",
      "Epoch 3358/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9752\n",
      "Epoch 3359/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9814\n",
      "Epoch 3360/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9814\n",
      "Epoch 3361/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9814\n",
      "Epoch 3362/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9814\n",
      "Epoch 3363/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9783\n",
      "Epoch 3364/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9783\n",
      "Epoch 3365/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9783\n",
      "Epoch 3366/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9783\n",
      "Epoch 3367/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9814\n",
      "Epoch 3368/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9783\n",
      "Epoch 3369/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9783\n",
      "Epoch 3370/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9814\n",
      "Epoch 3371/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9814\n",
      "Epoch 3372/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9783\n",
      "Epoch 3373/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9845\n",
      "Epoch 3374/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9814\n",
      "Epoch 3375/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9845\n",
      "Epoch 3376/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9814\n",
      "Epoch 3377/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9814\n",
      "Epoch 3378/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9814\n",
      "Epoch 3379/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.1634 - val_accuracy: 0.9814\n",
      "Epoch 3380/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9814\n",
      "Epoch 3381/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9814\n",
      "Epoch 3382/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9783\n",
      "Epoch 3383/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9783\n",
      "Epoch 3384/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9845\n",
      "Epoch 3385/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9814\n",
      "Epoch 3386/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9814\n",
      "Epoch 3387/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1636 - val_accuracy: 0.9814\n",
      "Epoch 3388/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9783\n",
      "Epoch 3389/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.1609 - val_accuracy: 0.9814\n",
      "Epoch 3390/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.1610 - val_accuracy: 0.9783\n",
      "Epoch 3391/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9814\n",
      "Epoch 3392/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9814\n",
      "Epoch 3393/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9783\n",
      "Epoch 3394/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9783\n",
      "Epoch 3395/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9783\n",
      "Epoch 3396/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.1617 - val_accuracy: 0.9783\n",
      "Epoch 3397/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9783\n",
      "Epoch 3398/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1677 - val_accuracy: 0.9814\n",
      "Epoch 3399/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.1689 - val_accuracy: 0.9814\n",
      "Epoch 3400/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1631 - val_accuracy: 0.9783\n",
      "Epoch 3401/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.1636 - val_accuracy: 0.9752\n",
      "Epoch 3402/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.1620 - val_accuracy: 0.9783\n",
      "Epoch 3403/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1608 - val_accuracy: 0.9752\n",
      "Epoch 3404/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.1617 - val_accuracy: 0.9783\n",
      "Epoch 3405/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9845\n",
      "Epoch 3406/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9783\n",
      "Epoch 3407/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9783\n",
      "Epoch 3408/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9783\n",
      "Epoch 3409/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.1597 - val_accuracy: 0.9783\n",
      "Epoch 3410/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9783\n",
      "Epoch 3411/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9783\n",
      "Epoch 3412/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9814\n",
      "Epoch 3413/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9814\n",
      "Epoch 3414/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9814\n",
      "Epoch 3415/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9783\n",
      "Epoch 3416/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9783\n",
      "Epoch 3417/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9783\n",
      "Epoch 3418/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9783\n",
      "Epoch 3419/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9783\n",
      "Epoch 3420/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9783\n",
      "Epoch 3421/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1639 - val_accuracy: 0.9814\n",
      "Epoch 3422/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9814\n",
      "Epoch 3423/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9783\n",
      "Epoch 3424/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1611 - val_accuracy: 0.9783\n",
      "Epoch 3425/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.1655 - val_accuracy: 0.9783\n",
      "Epoch 3426/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1610 - val_accuracy: 0.9814\n",
      "Epoch 3427/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9814\n",
      "Epoch 3428/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1625 - val_accuracy: 0.9814\n",
      "Epoch 3429/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9783\n",
      "Epoch 3430/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9814\n",
      "Epoch 3431/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9814\n",
      "Epoch 3432/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.1611 - val_accuracy: 0.9814\n",
      "Epoch 3433/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9783\n",
      "Epoch 3434/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9814\n",
      "Epoch 3435/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.1638 - val_accuracy: 0.9814\n",
      "Epoch 3436/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9783\n",
      "Epoch 3437/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9783\n",
      "Epoch 3438/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.1667 - val_accuracy: 0.9783\n",
      "Epoch 3439/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9752\n",
      "Epoch 3440/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9783\n",
      "Epoch 3441/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9814\n",
      "Epoch 3442/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9783\n",
      "Epoch 3443/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9752\n",
      "Epoch 3444/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9752\n",
      "Epoch 3445/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9814\n",
      "Epoch 3446/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9814\n",
      "Epoch 3447/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9783\n",
      "Epoch 3448/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9814\n",
      "Epoch 3449/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9783\n",
      "Epoch 3450/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9814\n",
      "Epoch 3451/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9814\n",
      "Epoch 3452/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9752\n",
      "Epoch 3453/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9783\n",
      "Epoch 3454/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9752\n",
      "Epoch 3455/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9783\n",
      "Epoch 3456/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9814\n",
      "Epoch 3457/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9814\n",
      "Epoch 3458/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.1657 - val_accuracy: 0.9814\n",
      "Epoch 3459/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9814\n",
      "Epoch 3460/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.1632 - val_accuracy: 0.9783\n",
      "Epoch 3461/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9814\n",
      "Epoch 3462/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9814\n",
      "Epoch 3463/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9966 - val_loss: 0.1714 - val_accuracy: 0.9814\n",
      "Epoch 3464/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0065 - accuracy: 0.9973 - val_loss: 0.1650 - val_accuracy: 0.9814\n",
      "Epoch 3465/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9783\n",
      "Epoch 3466/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.1636 - val_accuracy: 0.9752\n",
      "Epoch 3467/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.1634 - val_accuracy: 0.9814\n",
      "Epoch 3468/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.1661 - val_accuracy: 0.9783\n",
      "Epoch 3469/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9845\n",
      "Epoch 3470/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.1745 - val_accuracy: 0.9814\n",
      "Epoch 3471/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0134 - accuracy: 0.9966 - val_loss: 0.1720 - val_accuracy: 0.9845\n",
      "Epoch 3472/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1681 - val_accuracy: 0.9783\n",
      "Epoch 3473/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9783\n",
      "Epoch 3474/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1672 - val_accuracy: 0.9783\n",
      "Epoch 3475/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1656 - val_accuracy: 0.9783\n",
      "Epoch 3476/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9814\n",
      "Epoch 3477/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.1757 - val_accuracy: 0.9783\n",
      "Epoch 3478/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.1655 - val_accuracy: 0.9783\n",
      "Epoch 3479/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.1672 - val_accuracy: 0.9783\n",
      "Epoch 3480/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0071 - accuracy: 0.9966 - val_loss: 0.1650 - val_accuracy: 0.9783\n",
      "Epoch 3481/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1656 - val_accuracy: 0.9783\n",
      "Epoch 3482/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.1674 - val_accuracy: 0.9814\n",
      "Epoch 3483/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9783\n",
      "Epoch 3484/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.1667 - val_accuracy: 0.9783\n",
      "Epoch 3485/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9752\n",
      "Epoch 3486/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.1667 - val_accuracy: 0.9752\n",
      "Epoch 3487/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.1563 - val_accuracy: 0.9783\n",
      "Epoch 3488/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.1801 - val_accuracy: 0.9783\n",
      "Epoch 3489/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0189 - accuracy: 0.9899 - val_loss: 0.1593 - val_accuracy: 0.9814\n",
      "Epoch 3490/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 0.1668 - val_accuracy: 0.9814\n",
      "Epoch 3491/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0141 - accuracy: 0.9932 - val_loss: 0.1591 - val_accuracy: 0.9752\n",
      "Epoch 3492/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.1657 - val_accuracy: 0.9752\n",
      "Epoch 3493/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.1609 - val_accuracy: 0.9752\n",
      "Epoch 3494/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.1646 - val_accuracy: 0.9783\n",
      "Epoch 3495/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.1712 - val_accuracy: 0.9752\n",
      "Epoch 3496/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.1663 - val_accuracy: 0.9814\n",
      "Epoch 3497/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.1673 - val_accuracy: 0.9752\n",
      "Epoch 3498/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1688 - val_accuracy: 0.9752\n",
      "Epoch 3499/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.1668 - val_accuracy: 0.9720\n",
      "Epoch 3500/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.1651 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df_pre = pd.read_csv(\"wine.csv\", header = None)\n",
    "df = df_pre.sample(frac = 0.15)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:12].astype(float)\n",
    "Y = dataset[:,12]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 12, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss',\n",
    "                               verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X, Y, validation_split = 0.33, epochs = 3500, batch_size = 500)\n",
    "\n",
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy'] # not ['acc']\n",
    "x_len = numpy.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c = \"red\", markersize = 3)\n",
    "plt.plot(x_len, y_acc, \"o\", c = \"blue\", markersize = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31aa490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3500\n",
      "2/2 [==============================] - 1s 210ms/step - loss: 2.1001 - accuracy: 0.7251 - val_loss: 1.2069 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.20689, saving model to ./model\\01-1.2069.hdf5\n",
      "Epoch 2/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5713 - accuracy: 0.7224 - val_loss: 0.8604 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.20689 to 0.86037, saving model to ./model\\02-0.8604.hdf5\n",
      "Epoch 3/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0754 - accuracy: 0.7304 - val_loss: 0.5777 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.86037 to 0.57772, saving model to ./model\\03-0.5777.hdf5\n",
      "Epoch 4/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7344 - accuracy: 0.7207 - val_loss: 0.7209 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.57772\n",
      "Epoch 5/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7390 - accuracy: 0.5978 - val_loss: 0.8500 - val_accuracy: 0.4615\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.57772\n",
      "Epoch 6/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7672 - accuracy: 0.5388 - val_loss: 0.5361 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.57772 to 0.53607, saving model to ./model\\06-0.5361.hdf5\n",
      "Epoch 7/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5686 - accuracy: 0.7112 - val_loss: 0.4439 - val_accuracy: 0.7692\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.53607 to 0.44392, saving model to ./model\\07-0.4439.hdf5\n",
      "Epoch 8/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5590 - accuracy: 0.7201 - val_loss: 0.4426 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.44392 to 0.44263, saving model to ./model\\08-0.4426.hdf5\n",
      "Epoch 9/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5889 - accuracy: 0.7229 - val_loss: 0.4358 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.44263 to 0.43578, saving model to ./model\\09-0.4358.hdf5\n",
      "Epoch 10/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5770 - accuracy: 0.7229 - val_loss: 0.4106 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.43578 to 0.41058, saving model to ./model\\10-0.4106.hdf5\n",
      "Epoch 11/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5272 - accuracy: 0.7277 - val_loss: 0.3788 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.41058 to 0.37877, saving model to ./model\\11-0.3788.hdf5\n",
      "Epoch 12/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4756 - accuracy: 0.7450 - val_loss: 0.3649 - val_accuracy: 0.7846\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.37877 to 0.36487, saving model to ./model\\12-0.3649.hdf5\n",
      "Epoch 13/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4454 - accuracy: 0.7610 - val_loss: 0.3944 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.36487\n",
      "Epoch 14/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4450 - accuracy: 0.7876 - val_loss: 0.4339 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.36487\n",
      "Epoch 15/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4489 - accuracy: 0.8107 - val_loss: 0.4091 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.36487\n",
      "Epoch 16/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4232 - accuracy: 0.8258 - val_loss: 0.3522 - val_accuracy: 0.8308\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.36487 to 0.35215, saving model to ./model\\16-0.3522.hdf5\n",
      "Epoch 17/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3891 - accuracy: 0.8446 - val_loss: 0.3153 - val_accuracy: 0.8410\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.35215 to 0.31528, saving model to ./model\\17-0.3153.hdf5\n",
      "Epoch 18/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3907 - accuracy: 0.8389 - val_loss: 0.2991 - val_accuracy: 0.8718\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.31528 to 0.29911, saving model to ./model\\18-0.2991.hdf5\n",
      "Epoch 19/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3765 - accuracy: 0.8551 - val_loss: 0.2899 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.29911 to 0.28986, saving model to ./model\\19-0.2899.hdf5\n",
      "Epoch 20/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3768 - accuracy: 0.8504 - val_loss: 0.2832 - val_accuracy: 0.8821\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.28986 to 0.28323, saving model to ./model\\20-0.2832.hdf5\n",
      "Epoch 21/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3754 - accuracy: 0.8614 - val_loss: 0.2817 - val_accuracy: 0.8974\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.28323 to 0.28166, saving model to ./model\\21-0.2817.hdf5\n",
      "Epoch 22/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3442 - accuracy: 0.8736 - val_loss: 0.2866 - val_accuracy: 0.9026\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.28166\n",
      "Epoch 23/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3419 - accuracy: 0.8842 - val_loss: 0.2946 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.28166\n",
      "Epoch 24/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3442 - accuracy: 0.8954 - val_loss: 0.2955 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.28166\n",
      "Epoch 25/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3367 - accuracy: 0.8981 - val_loss: 0.2852 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.28166\n",
      "Epoch 26/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3265 - accuracy: 0.8990 - val_loss: 0.2693 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.28166 to 0.26935, saving model to ./model\\26-0.2693.hdf5\n",
      "Epoch 27/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3171 - accuracy: 0.9047 - val_loss: 0.2567 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.26935 to 0.25668, saving model to ./model\\27-0.2567.hdf5\n",
      "Epoch 28/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3145 - accuracy: 0.9037 - val_loss: 0.2482 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.25668 to 0.24824, saving model to ./model\\28-0.2482.hdf5\n",
      "Epoch 29/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3176 - accuracy: 0.9006 - val_loss: 0.2430 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.24824 to 0.24302, saving model to ./model\\29-0.2430.hdf5\n",
      "Epoch 30/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3124 - accuracy: 0.9074 - val_loss: 0.2398 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.24302 to 0.23980, saving model to ./model\\30-0.2398.hdf5\n",
      "Epoch 31/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3035 - accuracy: 0.9052 - val_loss: 0.2385 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.23980 to 0.23846, saving model to ./model\\31-0.2385.hdf5\n",
      "Epoch 32/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3033 - accuracy: 0.9061 - val_loss: 0.2387 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.23846\n",
      "Epoch 33/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3124 - accuracy: 0.8994 - val_loss: 0.2393 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.23846\n",
      "Epoch 34/3500\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3041 - accuracy: 0.9066 - val_loss: 0.2371 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.23846 to 0.23710, saving model to ./model\\34-0.2371.hdf5\n",
      "Epoch 35/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2906 - accuracy: 0.9111 - val_loss: 0.2329 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.23710 to 0.23291, saving model to ./model\\35-0.2329.hdf5\n",
      "Epoch 36/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3050 - accuracy: 0.9078 - val_loss: 0.2279 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.23291 to 0.22793, saving model to ./model\\36-0.2279.hdf5\n",
      "Epoch 37/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2933 - accuracy: 0.9076 - val_loss: 0.2227 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00037: val_loss improved from 0.22793 to 0.22266, saving model to ./model\\37-0.2227.hdf5\n",
      "Epoch 38/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2942 - accuracy: 0.9076 - val_loss: 0.2185 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.22266 to 0.21854, saving model to ./model\\38-0.2185.hdf5\n",
      "Epoch 39/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2996 - accuracy: 0.9029 - val_loss: 0.2162 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.21854 to 0.21621, saving model to ./model\\39-0.2162.hdf5\n",
      "Epoch 40/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2887 - accuracy: 0.9069 - val_loss: 0.2140 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.21621 to 0.21398, saving model to ./model\\40-0.2140.hdf5\n",
      "Epoch 41/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2931 - accuracy: 0.9036 - val_loss: 0.2133 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.21398 to 0.21335, saving model to ./model\\41-0.2133.hdf5\n",
      "Epoch 42/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2913 - accuracy: 0.9075 - val_loss: 0.2126 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.21335 to 0.21262, saving model to ./model\\42-0.2126.hdf5\n",
      "Epoch 43/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2841 - accuracy: 0.9117 - val_loss: 0.2117 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.21262 to 0.21169, saving model to ./model\\43-0.2117.hdf5\n",
      "Epoch 44/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2707 - accuracy: 0.9137 - val_loss: 0.2100 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.21169 to 0.20995, saving model to ./model\\44-0.2100.hdf5\n",
      "Epoch 45/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2799 - accuracy: 0.9110 - val_loss: 0.2081 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.20995 to 0.20813, saving model to ./model\\45-0.2081.hdf5\n",
      "Epoch 46/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2872 - accuracy: 0.9084 - val_loss: 0.2066 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.20813 to 0.20665, saving model to ./model\\46-0.2066.hdf5\n",
      "Epoch 47/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2855 - accuracy: 0.9090 - val_loss: 0.2026 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.20665 to 0.20257, saving model to ./model\\47-0.2026.hdf5\n",
      "Epoch 48/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2844 - accuracy: 0.9104 - val_loss: 0.1981 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.20257 to 0.19806, saving model to ./model\\48-0.1981.hdf5\n",
      "Epoch 49/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2691 - accuracy: 0.9108 - val_loss: 0.1945 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.19806 to 0.19452, saving model to ./model\\49-0.1945.hdf5\n",
      "Epoch 50/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2809 - accuracy: 0.9082 - val_loss: 0.1923 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.19452 to 0.19231, saving model to ./model\\50-0.1923.hdf5\n",
      "Epoch 51/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2696 - accuracy: 0.9112 - val_loss: 0.1916 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.19231 to 0.19156, saving model to ./model\\51-0.1916.hdf5\n",
      "Epoch 52/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2601 - accuracy: 0.9164 - val_loss: 0.1921 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.19156\n",
      "Epoch 53/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2635 - accuracy: 0.9123 - val_loss: 0.1942 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.19156\n",
      "Epoch 54/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2561 - accuracy: 0.9176 - val_loss: 0.1956 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.19156\n",
      "Epoch 55/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2718 - accuracy: 0.9138 - val_loss: 0.1970 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.19156\n",
      "Epoch 56/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2566 - accuracy: 0.9136 - val_loss: 0.1968 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.19156\n",
      "Epoch 57/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2581 - accuracy: 0.9163 - val_loss: 0.1954 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.19156\n",
      "Epoch 58/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2615 - accuracy: 0.9163 - val_loss: 0.1922 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.19156\n",
      "Epoch 59/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2451 - accuracy: 0.9161 - val_loss: 0.1901 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.19156 to 0.19009, saving model to ./model\\59-0.1901.hdf5\n",
      "Epoch 60/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2640 - accuracy: 0.9141 - val_loss: 0.1905 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.19009\n",
      "Epoch 61/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2440 - accuracy: 0.9174 - val_loss: 0.1906 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.19009\n",
      "Epoch 62/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2604 - accuracy: 0.9141 - val_loss: 0.1917 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.19009\n",
      "Epoch 63/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2604 - accuracy: 0.9121 - val_loss: 0.1931 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.19009\n",
      "Epoch 64/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2560 - accuracy: 0.9147 - val_loss: 0.1920 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.19009\n",
      "Epoch 65/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2588 - accuracy: 0.9121 - val_loss: 0.1918 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.19009\n",
      "Epoch 66/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2471 - accuracy: 0.9169 - val_loss: 0.1906 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.19009\n",
      "Epoch 67/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2598 - accuracy: 0.9143 - val_loss: 0.1904 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.19009\n",
      "Epoch 68/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2444 - accuracy: 0.9191 - val_loss: 0.1892 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.19009 to 0.18922, saving model to ./model\\68-0.1892.hdf5\n",
      "Epoch 69/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2527 - accuracy: 0.9163 - val_loss: 0.1881 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.18922 to 0.18814, saving model to ./model\\69-0.1881.hdf5\n",
      "Epoch 70/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2474 - accuracy: 0.9183 - val_loss: 0.1884 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.18814\n",
      "Epoch 71/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2571 - accuracy: 0.9129 - val_loss: 0.1885 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.18814\n",
      "Epoch 72/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2471 - accuracy: 0.9164 - val_loss: 0.1884 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.18814\n",
      "Epoch 73/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2490 - accuracy: 0.9184 - val_loss: 0.1880 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.18814 to 0.18798, saving model to ./model\\73-0.1880.hdf5\n",
      "Epoch 74/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2490 - accuracy: 0.9151 - val_loss: 0.1874 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.18798 to 0.18742, saving model to ./model\\74-0.1874.hdf5\n",
      "Epoch 75/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2477 - accuracy: 0.9171 - val_loss: 0.1866 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.18742 to 0.18655, saving model to ./model\\75-0.1866.hdf5\n",
      "Epoch 76/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2482 - accuracy: 0.9158 - val_loss: 0.1861 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.18655 to 0.18611, saving model to ./model\\76-0.1861.hdf5\n",
      "Epoch 77/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2408 - accuracy: 0.9180 - val_loss: 0.1851 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.18611 to 0.18515, saving model to ./model\\77-0.1851.hdf5\n",
      "Epoch 78/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2436 - accuracy: 0.9200 - val_loss: 0.1852 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.18515\n",
      "Epoch 79/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2466 - accuracy: 0.9208 - val_loss: 0.1851 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.18515 to 0.18508, saving model to ./model\\79-0.1851.hdf5\n",
      "Epoch 80/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2249 - accuracy: 0.9240 - val_loss: 0.1851 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.18508 to 0.18505, saving model to ./model\\80-0.1851.hdf5\n",
      "Epoch 81/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2440 - accuracy: 0.9164 - val_loss: 0.1862 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.18505\n",
      "Epoch 82/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2339 - accuracy: 0.9186 - val_loss: 0.1869 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.18505\n",
      "Epoch 83/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2415 - accuracy: 0.9195 - val_loss: 0.1873 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.18505\n",
      "Epoch 84/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2500 - accuracy: 0.9188 - val_loss: 0.1864 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.18505\n",
      "Epoch 85/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2280 - accuracy: 0.9208 - val_loss: 0.1852 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.18505\n",
      "Epoch 86/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2446 - accuracy: 0.9175 - val_loss: 0.1848 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.18505 to 0.18482, saving model to ./model\\86-0.1848.hdf5\n",
      "Epoch 87/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2435 - accuracy: 0.9182 - val_loss: 0.1837 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.18482 to 0.18375, saving model to ./model\\87-0.1837.hdf5\n",
      "Epoch 88/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2304 - accuracy: 0.9219 - val_loss: 0.1824 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.18375 to 0.18235, saving model to ./model\\88-0.1824.hdf5\n",
      "Epoch 89/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2440 - accuracy: 0.9212 - val_loss: 0.1828 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.18235\n",
      "Epoch 90/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2487 - accuracy: 0.9194 - val_loss: 0.1827 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.18235\n",
      "Epoch 91/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2436 - accuracy: 0.9207 - val_loss: 0.1827 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.18235\n",
      "Epoch 92/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2449 - accuracy: 0.9227 - val_loss: 0.1837 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.18235\n",
      "Epoch 93/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2359 - accuracy: 0.9239 - val_loss: 0.1833 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.18235\n",
      "Epoch 94/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2308 - accuracy: 0.9239 - val_loss: 0.1830 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.18235\n",
      "Epoch 95/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2458 - accuracy: 0.9192 - val_loss: 0.1830 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.18235\n",
      "Epoch 96/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2351 - accuracy: 0.9214 - val_loss: 0.1819 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.18235 to 0.18188, saving model to ./model\\96-0.1819.hdf5\n",
      "Epoch 97/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2342 - accuracy: 0.9227 - val_loss: 0.1808 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.18188 to 0.18076, saving model to ./model\\97-0.1808.hdf5\n",
      "Epoch 98/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2399 - accuracy: 0.9187 - val_loss: 0.1803 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.18076 to 0.18033, saving model to ./model\\98-0.1803.hdf5\n",
      "Epoch 99/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2329 - accuracy: 0.9187 - val_loss: 0.1799 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.18033 to 0.17991, saving model to ./model\\99-0.1799.hdf5\n",
      "Epoch 100/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2370 - accuracy: 0.9247 - val_loss: 0.1794 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.17991 to 0.17939, saving model to ./model\\100-0.1794.hdf5\n",
      "Epoch 101/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2453 - accuracy: 0.9194 - val_loss: 0.1786 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.17939 to 0.17864, saving model to ./model\\101-0.1786.hdf5\n",
      "Epoch 102/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2180 - accuracy: 0.9292 - val_loss: 0.1768 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.17864 to 0.17680, saving model to ./model\\102-0.1768.hdf5\n",
      "Epoch 103/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2325 - accuracy: 0.9212 - val_loss: 0.1769 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.17680\n",
      "Epoch 104/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2410 - accuracy: 0.9187 - val_loss: 0.1774 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.17680\n",
      "Epoch 105/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2333 - accuracy: 0.9214 - val_loss: 0.1775 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.17680\n",
      "Epoch 106/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2369 - accuracy: 0.9234 - val_loss: 0.1778 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.17680\n",
      "Epoch 107/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2269 - accuracy: 0.9247 - val_loss: 0.1772 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.17680\n",
      "Epoch 108/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2375 - accuracy: 0.9214 - val_loss: 0.1785 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.17680\n",
      "Epoch 109/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2224 - accuracy: 0.9247 - val_loss: 0.1793 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.17680\n",
      "Epoch 110/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2275 - accuracy: 0.9221 - val_loss: 0.1795 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.17680\n",
      "Epoch 111/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2174 - accuracy: 0.9274 - val_loss: 0.1787 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.17680\n",
      "Epoch 112/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2260 - accuracy: 0.9247 - val_loss: 0.1786 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.17680\n",
      "Epoch 113/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2306 - accuracy: 0.9234 - val_loss: 0.1768 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.17680 to 0.17677, saving model to ./model\\113-0.1768.hdf5\n",
      "Epoch 114/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2301 - accuracy: 0.9207 - val_loss: 0.1746 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.17677 to 0.17463, saving model to ./model\\114-0.1746.hdf5\n",
      "Epoch 115/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2311 - accuracy: 0.9199 - val_loss: 0.1729 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.17463 to 0.17291, saving model to ./model\\115-0.1729.hdf5\n",
      "Epoch 116/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2276 - accuracy: 0.9192 - val_loss: 0.1726 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.17291 to 0.17257, saving model to ./model\\116-0.1726.hdf5\n",
      "Epoch 117/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2295 - accuracy: 0.9185 - val_loss: 0.1742 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.17257\n",
      "Epoch 118/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2242 - accuracy: 0.9234 - val_loss: 0.1758 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.17257\n",
      "Epoch 119/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2256 - accuracy: 0.9214 - val_loss: 0.1778 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.17257\n",
      "Epoch 120/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2291 - accuracy: 0.9207 - val_loss: 0.1784 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.17257\n",
      "Epoch 121/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2196 - accuracy: 0.9241 - val_loss: 0.1764 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.17257\n",
      "Epoch 122/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2242 - accuracy: 0.9207 - val_loss: 0.1742 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.17257\n",
      "Epoch 123/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2188 - accuracy: 0.9254 - val_loss: 0.1733 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.17257\n",
      "Epoch 124/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2104 - accuracy: 0.9296 - val_loss: 0.1726 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.17257\n",
      "Epoch 125/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2229 - accuracy: 0.9244 - val_loss: 0.1743 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.17257\n",
      "Epoch 126/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2125 - accuracy: 0.9267 - val_loss: 0.1763 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.17257\n",
      "Epoch 127/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2278 - accuracy: 0.9214 - val_loss: 0.1777 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.17257\n",
      "Epoch 128/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2230 - accuracy: 0.9214 - val_loss: 0.1761 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.17257\n",
      "Epoch 129/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2226 - accuracy: 0.9221 - val_loss: 0.1734 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.17257\n",
      "Epoch 130/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2088 - accuracy: 0.9289 - val_loss: 0.1700 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.17257 to 0.16996, saving model to ./model\\130-0.1700.hdf5\n",
      "Epoch 131/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2267 - accuracy: 0.9244 - val_loss: 0.1696 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.16996 to 0.16958, saving model to ./model\\131-0.1696.hdf5\n",
      "Epoch 132/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2215 - accuracy: 0.9231 - val_loss: 0.1694 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.16958 to 0.16945, saving model to ./model\\132-0.1694.hdf5\n",
      "Epoch 133/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2125 - accuracy: 0.9258 - val_loss: 0.1690 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.16945 to 0.16900, saving model to ./model\\133-0.1690.hdf5\n",
      "Epoch 134/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2188 - accuracy: 0.9231 - val_loss: 0.1708 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16900\n",
      "Epoch 135/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2128 - accuracy: 0.9284 - val_loss: 0.1714 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.16900\n",
      "Epoch 136/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2115 - accuracy: 0.9264 - val_loss: 0.1718 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16900\n",
      "Epoch 137/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2125 - accuracy: 0.9262 - val_loss: 0.1712 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16900\n",
      "Epoch 138/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2120 - accuracy: 0.9256 - val_loss: 0.1706 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.16900\n",
      "Epoch 139/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2170 - accuracy: 0.9242 - val_loss: 0.1696 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16900\n",
      "Epoch 140/3500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2226 - accuracy: 0.9216 - val_loss: 0.1683 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.16900 to 0.16835, saving model to ./model\\140-0.1683.hdf5\n",
      "Epoch 141/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2081 - accuracy: 0.9291 - val_loss: 0.1662 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.16835 to 0.16618, saving model to ./model\\141-0.1662.hdf5\n",
      "Epoch 142/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2137 - accuracy: 0.9278 - val_loss: 0.1657 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.16618 to 0.16566, saving model to ./model\\142-0.1657.hdf5\n",
      "Epoch 143/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2094 - accuracy: 0.9293 - val_loss: 0.1651 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.16566 to 0.16512, saving model to ./model\\143-0.1651.hdf5\n",
      "Epoch 144/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2093 - accuracy: 0.9279 - val_loss: 0.1658 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16512\n",
      "Epoch 145/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2032 - accuracy: 0.9262 - val_loss: 0.1689 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16512\n",
      "Epoch 146/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2049 - accuracy: 0.9242 - val_loss: 0.1715 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16512\n",
      "Epoch 147/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2063 - accuracy: 0.9256 - val_loss: 0.1724 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16512\n",
      "Epoch 148/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2139 - accuracy: 0.9262 - val_loss: 0.1716 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16512\n",
      "Epoch 149/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2106 - accuracy: 0.9273 - val_loss: 0.1669 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16512\n",
      "Epoch 150/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1983 - accuracy: 0.9321 - val_loss: 0.1645 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.16512 to 0.16451, saving model to ./model\\150-0.1645.hdf5\n",
      "Epoch 151/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2107 - accuracy: 0.9259 - val_loss: 0.1661 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16451\n",
      "Epoch 152/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2046 - accuracy: 0.9291 - val_loss: 0.1653 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16451\n",
      "Epoch 153/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2073 - accuracy: 0.9258 - val_loss: 0.1640 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.16451 to 0.16404, saving model to ./model\\153-0.1640.hdf5\n",
      "Epoch 154/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2106 - accuracy: 0.9259 - val_loss: 0.1646 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16404\n",
      "Epoch 155/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2048 - accuracy: 0.9268 - val_loss: 0.1650 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16404\n",
      "Epoch 156/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2014 - accuracy: 0.9290 - val_loss: 0.1655 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16404\n",
      "Epoch 157/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2051 - accuracy: 0.9281 - val_loss: 0.1642 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16404\n",
      "Epoch 158/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2029 - accuracy: 0.9323 - val_loss: 0.1624 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.16404 to 0.16237, saving model to ./model\\158-0.1624.hdf5\n",
      "Epoch 159/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2079 - accuracy: 0.9266 - val_loss: 0.1642 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16237\n",
      "Epoch 160/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2042 - accuracy: 0.9283 - val_loss: 0.1638 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16237\n",
      "Epoch 161/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2022 - accuracy: 0.9310 - val_loss: 0.1635 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16237\n",
      "Epoch 162/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2072 - accuracy: 0.9305 - val_loss: 0.1618 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.16237 to 0.16176, saving model to ./model\\162-0.1618.hdf5\n",
      "Epoch 163/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2022 - accuracy: 0.9268 - val_loss: 0.1591 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.16176 to 0.15907, saving model to ./model\\163-0.1591.hdf5\n",
      "Epoch 164/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1960 - accuracy: 0.9357 - val_loss: 0.1610 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.15907\n",
      "Epoch 165/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2110 - accuracy: 0.9265 - val_loss: 0.1635 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.15907\n",
      "Epoch 166/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2065 - accuracy: 0.9314 - val_loss: 0.1616 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.15907\n",
      "Epoch 167/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2049 - accuracy: 0.9298 - val_loss: 0.1573 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.15907 to 0.15732, saving model to ./model\\167-0.1573.hdf5\n",
      "Epoch 168/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2081 - accuracy: 0.9268 - val_loss: 0.1545 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.15732 to 0.15448, saving model to ./model\\168-0.1545.hdf5\n",
      "Epoch 169/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2030 - accuracy: 0.9259 - val_loss: 0.1539 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.15448 to 0.15390, saving model to ./model\\169-0.1539.hdf5\n",
      "Epoch 170/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1979 - accuracy: 0.9295 - val_loss: 0.1568 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.15390\n",
      "Epoch 171/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2015 - accuracy: 0.9320 - val_loss: 0.1621 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.15390\n",
      "Epoch 172/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1996 - accuracy: 0.9314 - val_loss: 0.1636 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.15390\n",
      "Epoch 173/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1923 - accuracy: 0.9342 - val_loss: 0.1574 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.15390\n",
      "Epoch 174/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1957 - accuracy: 0.9312 - val_loss: 0.1544 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.15390\n",
      "Epoch 175/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2015 - accuracy: 0.9322 - val_loss: 0.1537 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.15390 to 0.15369, saving model to ./model\\175-0.1537.hdf5\n",
      "Epoch 176/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1943 - accuracy: 0.9336 - val_loss: 0.1550 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.15369\n",
      "Epoch 177/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1957 - accuracy: 0.9342 - val_loss: 0.1577 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.15369\n",
      "Epoch 178/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1995 - accuracy: 0.9324 - val_loss: 0.1596 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.15369\n",
      "Epoch 179/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2009 - accuracy: 0.9344 - val_loss: 0.1558 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.15369\n",
      "Epoch 180/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1953 - accuracy: 0.9357 - val_loss: 0.1508 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.15369 to 0.15077, saving model to ./model\\180-0.1508.hdf5\n",
      "Epoch 181/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1981 - accuracy: 0.9316 - val_loss: 0.1486 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.15077 to 0.14863, saving model to ./model\\181-0.1486.hdf5\n",
      "Epoch 182/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1952 - accuracy: 0.9309 - val_loss: 0.1504 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.14863\n",
      "Epoch 183/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2001 - accuracy: 0.9331 - val_loss: 0.1534 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.14863\n",
      "Epoch 184/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1913 - accuracy: 0.9353 - val_loss: 0.1533 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.14863\n",
      "Epoch 185/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1794 - accuracy: 0.9406 - val_loss: 0.1529 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.14863\n",
      "Epoch 186/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1957 - accuracy: 0.9346 - val_loss: 0.1528 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.14863\n",
      "Epoch 187/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1899 - accuracy: 0.9353 - val_loss: 0.1506 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.14863\n",
      "Epoch 188/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1908 - accuracy: 0.9381 - val_loss: 0.1493 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.14863\n",
      "Epoch 189/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1976 - accuracy: 0.9335 - val_loss: 0.1495 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.14863\n",
      "Epoch 190/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1842 - accuracy: 0.9375 - val_loss: 0.1506 - val_accuracy: 0.9487\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.14863\n",
      "Epoch 191/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1857 - accuracy: 0.9410 - val_loss: 0.1506 - val_accuracy: 0.9487\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.14863\n",
      "Epoch 192/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1959 - accuracy: 0.9363 - val_loss: 0.1486 - val_accuracy: 0.9487\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.14863 to 0.14858, saving model to ./model\\192-0.1486.hdf5\n",
      "Epoch 193/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1838 - accuracy: 0.9414 - val_loss: 0.1452 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.14858 to 0.14524, saving model to ./model\\193-0.1452.hdf5\n",
      "Epoch 194/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1817 - accuracy: 0.9427 - val_loss: 0.1448 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.14524 to 0.14476, saving model to ./model\\194-0.1448.hdf5\n",
      "Epoch 195/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1888 - accuracy: 0.9407 - val_loss: 0.1475 - val_accuracy: 0.9487\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.14476\n",
      "Epoch 196/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1875 - accuracy: 0.9392 - val_loss: 0.1508 - val_accuracy: 0.9487\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.14476\n",
      "Epoch 197/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1898 - accuracy: 0.9392 - val_loss: 0.1486 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.14476\n",
      "Epoch 198/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1878 - accuracy: 0.9412 - val_loss: 0.1437 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.14476 to 0.14372, saving model to ./model\\198-0.1437.hdf5\n",
      "Epoch 199/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1776 - accuracy: 0.9395 - val_loss: 0.1420 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.14372 to 0.14204, saving model to ./model\\199-0.1420.hdf5\n",
      "Epoch 200/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1814 - accuracy: 0.9416 - val_loss: 0.1466 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.14204\n",
      "Epoch 201/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1759 - accuracy: 0.9440 - val_loss: 0.1513 - val_accuracy: 0.9487\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.14204\n",
      "Epoch 202/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1858 - accuracy: 0.9442 - val_loss: 0.1493 - val_accuracy: 0.9487\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.14204\n",
      "Epoch 203/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1831 - accuracy: 0.9442 - val_loss: 0.1431 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.14204\n",
      "Epoch 204/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1868 - accuracy: 0.9402 - val_loss: 0.1403 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.14204 to 0.14026, saving model to ./model\\204-0.1403.hdf5\n",
      "Epoch 205/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1784 - accuracy: 0.9442 - val_loss: 0.1399 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.14026 to 0.13991, saving model to ./model\\205-0.1399.hdf5\n",
      "Epoch 206/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1792 - accuracy: 0.9457 - val_loss: 0.1424 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.13991\n",
      "Epoch 207/3500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1740 - accuracy: 0.9449 - val_loss: 0.1468 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.13991\n",
      "Epoch 208/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1805 - accuracy: 0.9444 - val_loss: 0.1469 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.13991\n",
      "Epoch 209/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1791 - accuracy: 0.9479 - val_loss: 0.1399 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.13991 to 0.13989, saving model to ./model\\209-0.1399.hdf5\n",
      "Epoch 210/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1770 - accuracy: 0.9457 - val_loss: 0.1369 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.13989 to 0.13688, saving model to ./model\\210-0.1369.hdf5\n",
      "Epoch 211/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1799 - accuracy: 0.9437 - val_loss: 0.1373 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.13688\n",
      "Epoch 212/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1796 - accuracy: 0.9461 - val_loss: 0.1406 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.13688\n",
      "Epoch 213/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1766 - accuracy: 0.9459 - val_loss: 0.1399 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.13688\n",
      "Epoch 214/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1752 - accuracy: 0.9505 - val_loss: 0.1359 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.13688 to 0.13586, saving model to ./model\\214-0.1359.hdf5\n",
      "Epoch 215/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1784 - accuracy: 0.9461 - val_loss: 0.1355 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.13586 to 0.13550, saving model to ./model\\215-0.1355.hdf5\n",
      "Epoch 216/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1766 - accuracy: 0.9470 - val_loss: 0.1383 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.13550\n",
      "Epoch 217/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1758 - accuracy: 0.9485 - val_loss: 0.1406 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.13550\n",
      "Epoch 218/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1801 - accuracy: 0.9450 - val_loss: 0.1380 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.13550\n",
      "Epoch 219/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1770 - accuracy: 0.9478 - val_loss: 0.1347 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.13550 to 0.13472, saving model to ./model\\219-0.1347.hdf5\n",
      "Epoch 220/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1752 - accuracy: 0.9471 - val_loss: 0.1348 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.13472\n",
      "Epoch 221/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1797 - accuracy: 0.9465 - val_loss: 0.1354 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.13472\n",
      "Epoch 222/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1728 - accuracy: 0.9485 - val_loss: 0.1351 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.13472\n",
      "Epoch 223/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1733 - accuracy: 0.9458 - val_loss: 0.1355 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.13472\n",
      "Epoch 224/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1662 - accuracy: 0.9505 - val_loss: 0.1362 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.13472\n",
      "Epoch 225/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1709 - accuracy: 0.9478 - val_loss: 0.1360 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.13472\n",
      "Epoch 226/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1722 - accuracy: 0.9507 - val_loss: 0.1346 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.13472 to 0.13456, saving model to ./model\\226-0.1346.hdf5\n",
      "Epoch 227/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1685 - accuracy: 0.9500 - val_loss: 0.1323 - val_accuracy: 0.9538\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.13456 to 0.13226, saving model to ./model\\227-0.1323.hdf5\n",
      "Epoch 228/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1676 - accuracy: 0.9487 - val_loss: 0.1334 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.13226\n",
      "Epoch 229/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1655 - accuracy: 0.9507 - val_loss: 0.1355 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.13226\n",
      "Epoch 230/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1680 - accuracy: 0.9513 - val_loss: 0.1383 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.13226\n",
      "Epoch 231/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1736 - accuracy: 0.9489 - val_loss: 0.1371 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.13226\n",
      "Epoch 232/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1647 - accuracy: 0.9530 - val_loss: 0.1325 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.13226\n",
      "Epoch 233/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1681 - accuracy: 0.9509 - val_loss: 0.1294 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.13226 to 0.12941, saving model to ./model\\233-0.1294.hdf5\n",
      "Epoch 234/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1651 - accuracy: 0.9522 - val_loss: 0.1303 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.12941\n",
      "Epoch 235/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1673 - accuracy: 0.9493 - val_loss: 0.1325 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.12941\n",
      "Epoch 236/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1703 - accuracy: 0.9510 - val_loss: 0.1317 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.12941\n",
      "Epoch 237/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1631 - accuracy: 0.9509 - val_loss: 0.1269 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.12941 to 0.12691, saving model to ./model\\237-0.1269.hdf5\n",
      "Epoch 238/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1607 - accuracy: 0.9522 - val_loss: 0.1262 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.12691 to 0.12621, saving model to ./model\\238-0.1262.hdf5\n",
      "Epoch 239/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1594 - accuracy: 0.9516 - val_loss: 0.1283 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.12621\n",
      "Epoch 240/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1679 - accuracy: 0.9495 - val_loss: 0.1386 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.12621\n",
      "Epoch 241/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1584 - accuracy: 0.9535 - val_loss: 0.1349 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.12621\n",
      "Epoch 242/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1686 - accuracy: 0.9482 - val_loss: 0.1278 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.12621\n",
      "Epoch 243/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9469 - val_loss: 0.1220 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.12621 to 0.12201, saving model to ./model\\243-0.1220.hdf5\n",
      "Epoch 244/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1686 - accuracy: 0.9463 - val_loss: 0.1214 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.12201 to 0.12142, saving model to ./model\\244-0.1214.hdf5\n",
      "Epoch 245/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1633 - accuracy: 0.9503 - val_loss: 0.1260 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.12142\n",
      "Epoch 246/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1644 - accuracy: 0.9532 - val_loss: 0.1368 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.12142\n",
      "Epoch 247/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1593 - accuracy: 0.9529 - val_loss: 0.1305 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.12142\n",
      "Epoch 248/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1655 - accuracy: 0.9502 - val_loss: 0.1224 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.12142\n",
      "Epoch 249/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1646 - accuracy: 0.9478 - val_loss: 0.1201 - val_accuracy: 0.9641\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.12142 to 0.12007, saving model to ./model\\249-0.1201.hdf5\n",
      "Epoch 250/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1641 - accuracy: 0.9456 - val_loss: 0.1245 - val_accuracy: 0.9641\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.12007\n",
      "Epoch 251/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1570 - accuracy: 0.9500 - val_loss: 0.1312 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.12007\n",
      "Epoch 252/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1531 - accuracy: 0.9555 - val_loss: 0.1291 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.12007\n",
      "Epoch 253/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1614 - accuracy: 0.9517 - val_loss: 0.1218 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.12007\n",
      "Epoch 254/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1616 - accuracy: 0.9480 - val_loss: 0.1181 - val_accuracy: 0.9641\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.12007 to 0.11811, saving model to ./model\\254-0.1181.hdf5\n",
      "Epoch 255/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1555 - accuracy: 0.9476 - val_loss: 0.1204 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.11811\n",
      "Epoch 256/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1528 - accuracy: 0.9552 - val_loss: 0.1305 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.11811\n",
      "Epoch 257/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1581 - accuracy: 0.9482 - val_loss: 0.1280 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.11811\n",
      "Epoch 258/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1563 - accuracy: 0.9476 - val_loss: 0.1187 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.11811\n",
      "Epoch 259/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1543 - accuracy: 0.9485 - val_loss: 0.1193 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.11811\n",
      "Epoch 260/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1628 - accuracy: 0.9458 - val_loss: 0.1258 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.11811\n",
      "Epoch 261/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1559 - accuracy: 0.9504 - val_loss: 0.1248 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.11811\n",
      "Epoch 262/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1513 - accuracy: 0.9552 - val_loss: 0.1196 - val_accuracy: 0.9641\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.11811\n",
      "Epoch 263/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1573 - accuracy: 0.9480 - val_loss: 0.1194 - val_accuracy: 0.9641\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.11811\n",
      "Epoch 264/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1529 - accuracy: 0.9487 - val_loss: 0.1207 - val_accuracy: 0.9641\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.11811\n",
      "Epoch 265/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1482 - accuracy: 0.9520 - val_loss: 0.1258 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.11811\n",
      "Epoch 266/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1560 - accuracy: 0.9510 - val_loss: 0.1253 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.11811\n",
      "Epoch 267/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1449 - accuracy: 0.9550 - val_loss: 0.1197 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.11811\n",
      "Epoch 268/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1522 - accuracy: 0.9529 - val_loss: 0.1184 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.11811\n",
      "Epoch 269/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1474 - accuracy: 0.9529 - val_loss: 0.1196 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.11811\n",
      "Epoch 270/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1485 - accuracy: 0.9522 - val_loss: 0.1215 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.11811\n",
      "Epoch 271/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1478 - accuracy: 0.9552 - val_loss: 0.1202 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.11811\n",
      "Epoch 272/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1527 - accuracy: 0.9524 - val_loss: 0.1188 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.11811\n",
      "Epoch 273/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1507 - accuracy: 0.9537 - val_loss: 0.1191 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.11811\n",
      "Epoch 274/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1491 - accuracy: 0.9552 - val_loss: 0.1221 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.11811\n",
      "Epoch 275/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1494 - accuracy: 0.9548 - val_loss: 0.1221 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.11811\n",
      "Epoch 276/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1459 - accuracy: 0.9554 - val_loss: 0.1201 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.11811\n",
      "Epoch 277/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1423 - accuracy: 0.9568 - val_loss: 0.1175 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.11811 to 0.11750, saving model to ./model\\277-0.1175.hdf5\n",
      "Epoch 278/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1464 - accuracy: 0.9532 - val_loss: 0.1168 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.11750 to 0.11685, saving model to ./model\\278-0.1168.hdf5\n",
      "Epoch 279/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1470 - accuracy: 0.9554 - val_loss: 0.1180 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.11685\n",
      "Epoch 280/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1456 - accuracy: 0.9563 - val_loss: 0.1174 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.11685\n",
      "Epoch 281/3500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1457 - accuracy: 0.9556 - val_loss: 0.1172 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.11685\n",
      "Epoch 282/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1395 - accuracy: 0.9576 - val_loss: 0.1174 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.11685\n",
      "Epoch 283/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1426 - accuracy: 0.9543 - val_loss: 0.1180 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.11685\n",
      "Epoch 284/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1441 - accuracy: 0.9549 - val_loss: 0.1164 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.11685 to 0.11643, saving model to ./model\\284-0.1164.hdf5\n",
      "Epoch 285/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1445 - accuracy: 0.9563 - val_loss: 0.1160 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.11643 to 0.11600, saving model to ./model\\285-0.1160.hdf5\n",
      "Epoch 286/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1402 - accuracy: 0.9563 - val_loss: 0.1158 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.11600 to 0.11584, saving model to ./model\\286-0.1158.hdf5\n",
      "Epoch 287/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1402 - accuracy: 0.9606 - val_loss: 0.1141 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.11584 to 0.11411, saving model to ./model\\287-0.1141.hdf5\n",
      "Epoch 288/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1378 - accuracy: 0.9574 - val_loss: 0.1115 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.11411 to 0.11153, saving model to ./model\\288-0.1115.hdf5\n",
      "Epoch 289/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1416 - accuracy: 0.9539 - val_loss: 0.1154 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.11153\n",
      "Epoch 290/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1434 - accuracy: 0.9566 - val_loss: 0.1158 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.11153\n",
      "Epoch 291/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1488 - accuracy: 0.9551 - val_loss: 0.1106 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.11153 to 0.11065, saving model to ./model\\291-0.1106.hdf5\n",
      "Epoch 292/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1394 - accuracy: 0.9537 - val_loss: 0.1095 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.11065 to 0.10952, saving model to ./model\\292-0.1095.hdf5\n",
      "Epoch 293/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1361 - accuracy: 0.9548 - val_loss: 0.1144 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.10952\n",
      "Epoch 294/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1341 - accuracy: 0.9608 - val_loss: 0.1144 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.10952\n",
      "Epoch 295/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1419 - accuracy: 0.9582 - val_loss: 0.1110 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.10952\n",
      "Epoch 296/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1445 - accuracy: 0.9541 - val_loss: 0.1074 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00296: val_loss improved from 0.10952 to 0.10737, saving model to ./model\\296-0.1074.hdf5\n",
      "Epoch 297/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1462 - accuracy: 0.9489 - val_loss: 0.1104 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.10737\n",
      "Epoch 298/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1331 - accuracy: 0.9613 - val_loss: 0.1180 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.10737\n",
      "Epoch 299/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1423 - accuracy: 0.9636 - val_loss: 0.1139 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.10737\n",
      "Epoch 300/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1353 - accuracy: 0.9602 - val_loss: 0.1060 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.10737 to 0.10599, saving model to ./model\\300-0.1060.hdf5\n",
      "Epoch 301/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1385 - accuracy: 0.9524 - val_loss: 0.1072 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.10599\n",
      "Epoch 302/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1318 - accuracy: 0.9556 - val_loss: 0.1151 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.10599\n",
      "Epoch 303/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1357 - accuracy: 0.9663 - val_loss: 0.1159 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.10599\n",
      "Epoch 304/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1322 - accuracy: 0.9661 - val_loss: 0.1107 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.10599\n",
      "Epoch 305/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1352 - accuracy: 0.9585 - val_loss: 0.1091 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.10599\n",
      "Epoch 306/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1379 - accuracy: 0.9578 - val_loss: 0.1082 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.10599\n",
      "Epoch 307/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1393 - accuracy: 0.9558 - val_loss: 0.1114 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.10599\n",
      "Epoch 308/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1305 - accuracy: 0.9669 - val_loss: 0.1098 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.10599\n",
      "Epoch 309/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1347 - accuracy: 0.9588 - val_loss: 0.1075 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.10599\n",
      "Epoch 310/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1317 - accuracy: 0.9600 - val_loss: 0.1072 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.10599\n",
      "Epoch 311/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1301 - accuracy: 0.9593 - val_loss: 0.1085 - val_accuracy: 0.9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00311: val_loss did not improve from 0.10599\n",
      "Epoch 312/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1385 - accuracy: 0.9588 - val_loss: 0.1087 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.10599\n",
      "Epoch 313/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1373 - accuracy: 0.9588 - val_loss: 0.1075 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.10599\n",
      "Epoch 314/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1291 - accuracy: 0.9613 - val_loss: 0.1083 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.10599\n",
      "Epoch 315/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1283 - accuracy: 0.9654 - val_loss: 0.1149 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.10599\n",
      "Epoch 316/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1340 - accuracy: 0.9666 - val_loss: 0.1088 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.10599\n",
      "Epoch 317/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1305 - accuracy: 0.9644 - val_loss: 0.1029 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00317: val_loss improved from 0.10599 to 0.10293, saving model to ./model\\317-0.1029.hdf5\n",
      "Epoch 318/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1310 - accuracy: 0.9583 - val_loss: 0.1062 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.10293\n",
      "Epoch 319/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1282 - accuracy: 0.9632 - val_loss: 0.1126 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.10293\n",
      "Epoch 320/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1313 - accuracy: 0.9673 - val_loss: 0.1054 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.10293\n",
      "Epoch 321/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1332 - accuracy: 0.9582 - val_loss: 0.1019 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.10293 to 0.10192, saving model to ./model\\321-0.1019.hdf5\n",
      "Epoch 322/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1337 - accuracy: 0.9571 - val_loss: 0.1065 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.10192\n",
      "Epoch 323/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1288 - accuracy: 0.9664 - val_loss: 0.1128 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.10192\n",
      "Epoch 324/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1268 - accuracy: 0.9676 - val_loss: 0.1079 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.10192\n",
      "Epoch 325/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1279 - accuracy: 0.9652 - val_loss: 0.1046 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.10192\n",
      "Epoch 326/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1315 - accuracy: 0.9597 - val_loss: 0.1041 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.10192\n",
      "Epoch 327/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1259 - accuracy: 0.9615 - val_loss: 0.1029 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.10192\n",
      "Epoch 328/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1274 - accuracy: 0.9610 - val_loss: 0.1068 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.10192\n",
      "Epoch 329/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1259 - accuracy: 0.9678 - val_loss: 0.1047 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.10192\n",
      "Epoch 330/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1276 - accuracy: 0.9634 - val_loss: 0.1049 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.10192\n",
      "Epoch 331/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1247 - accuracy: 0.9634 - val_loss: 0.1047 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.10192\n",
      "Epoch 332/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1298 - accuracy: 0.9624 - val_loss: 0.1030 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.10192\n",
      "Epoch 333/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1264 - accuracy: 0.9595 - val_loss: 0.1049 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.10192\n",
      "Epoch 334/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1248 - accuracy: 0.9649 - val_loss: 0.1040 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.10192\n",
      "Epoch 335/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1242 - accuracy: 0.9663 - val_loss: 0.1036 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.10192\n",
      "Epoch 336/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1262 - accuracy: 0.9654 - val_loss: 0.1047 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.10192\n",
      "Epoch 337/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1266 - accuracy: 0.9666 - val_loss: 0.1057 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.10192\n",
      "Epoch 338/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1271 - accuracy: 0.9666 - val_loss: 0.1015 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00338: val_loss improved from 0.10192 to 0.10146, saving model to ./model\\338-0.1015.hdf5\n",
      "Epoch 339/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1247 - accuracy: 0.9622 - val_loss: 0.1007 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00339: val_loss improved from 0.10146 to 0.10067, saving model to ./model\\339-0.1007.hdf5\n",
      "Epoch 340/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1201 - accuracy: 0.9630 - val_loss: 0.1053 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.10067\n",
      "Epoch 341/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1233 - accuracy: 0.9695 - val_loss: 0.1039 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.10067\n",
      "Epoch 342/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1193 - accuracy: 0.9674 - val_loss: 0.0986 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00342: val_loss improved from 0.10067 to 0.09864, saving model to ./model\\342-0.0986.hdf5\n",
      "Epoch 343/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1266 - accuracy: 0.9602 - val_loss: 0.1002 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.09864\n",
      "Epoch 344/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1182 - accuracy: 0.9650 - val_loss: 0.1048 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.09864\n",
      "Epoch 345/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1205 - accuracy: 0.9695 - val_loss: 0.1090 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.09864\n",
      "Epoch 346/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1222 - accuracy: 0.9717 - val_loss: 0.1003 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.09864\n",
      "Epoch 347/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1245 - accuracy: 0.9645 - val_loss: 0.0970 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.09864 to 0.09696, saving model to ./model\\347-0.0970.hdf5\n",
      "Epoch 348/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1229 - accuracy: 0.9602 - val_loss: 0.1007 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.09696\n",
      "Epoch 349/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1253 - accuracy: 0.9651 - val_loss: 0.1071 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.09696\n",
      "Epoch 350/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1287 - accuracy: 0.9683 - val_loss: 0.0989 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.09696\n",
      "Epoch 351/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1251 - accuracy: 0.9612 - val_loss: 0.0947 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00351: val_loss improved from 0.09696 to 0.09470, saving model to ./model\\351-0.0947.hdf5\n",
      "Epoch 352/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1283 - accuracy: 0.9595 - val_loss: 0.0995 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.09470\n",
      "Epoch 353/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1164 - accuracy: 0.9693 - val_loss: 0.1096 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.09470\n",
      "Epoch 354/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1185 - accuracy: 0.9732 - val_loss: 0.0990 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.09470\n",
      "Epoch 355/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1179 - accuracy: 0.9645 - val_loss: 0.0942 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00355: val_loss improved from 0.09470 to 0.09418, saving model to ./model\\355-0.0942.hdf5\n",
      "Epoch 356/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1234 - accuracy: 0.9617 - val_loss: 0.0980 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.09418\n",
      "Epoch 357/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1190 - accuracy: 0.9678 - val_loss: 0.1049 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.09418\n",
      "Epoch 358/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1214 - accuracy: 0.9690 - val_loss: 0.1055 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.09418\n",
      "Epoch 359/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1250 - accuracy: 0.9675 - val_loss: 0.0949 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.09418\n",
      "Epoch 360/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1188 - accuracy: 0.9648 - val_loss: 0.0944 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.09418\n",
      "Epoch 361/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1180 - accuracy: 0.9636 - val_loss: 0.1072 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.09418\n",
      "Epoch 362/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1199 - accuracy: 0.9725 - val_loss: 0.1035 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.09418\n",
      "Epoch 363/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1169 - accuracy: 0.9726 - val_loss: 0.0947 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.09418\n",
      "Epoch 364/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1215 - accuracy: 0.9643 - val_loss: 0.0979 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.09418\n",
      "Epoch 365/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1134 - accuracy: 0.9686 - val_loss: 0.0997 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.09418\n",
      "Epoch 366/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1234 - accuracy: 0.9662 - val_loss: 0.0986 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.09418\n",
      "Epoch 367/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1133 - accuracy: 0.9684 - val_loss: 0.0959 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.09418\n",
      "Epoch 368/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1175 - accuracy: 0.9671 - val_loss: 0.0992 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.09418\n",
      "Epoch 369/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1181 - accuracy: 0.9710 - val_loss: 0.0998 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.09418\n",
      "Epoch 370/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1152 - accuracy: 0.9693 - val_loss: 0.0957 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.09418\n",
      "Epoch 371/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1169 - accuracy: 0.9671 - val_loss: 0.0972 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.09418\n",
      "Epoch 372/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1188 - accuracy: 0.9680 - val_loss: 0.0998 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.09418\n",
      "Epoch 373/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1154 - accuracy: 0.9732 - val_loss: 0.0964 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.09418\n",
      "Epoch 374/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1199 - accuracy: 0.9688 - val_loss: 0.0981 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.09418\n",
      "Epoch 375/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1089 - accuracy: 0.9737 - val_loss: 0.0970 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.09418\n",
      "Epoch 376/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1225 - accuracy: 0.9677 - val_loss: 0.0955 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.09418\n",
      "Epoch 377/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1117 - accuracy: 0.9708 - val_loss: 0.0945 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.09418\n",
      "Epoch 378/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1159 - accuracy: 0.9673 - val_loss: 0.0959 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.09418\n",
      "Epoch 379/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1142 - accuracy: 0.9688 - val_loss: 0.0952 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.09418\n",
      "Epoch 380/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1129 - accuracy: 0.9702 - val_loss: 0.0963 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.09418\n",
      "Epoch 381/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1119 - accuracy: 0.9710 - val_loss: 0.0988 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.09418\n",
      "Epoch 382/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1094 - accuracy: 0.9717 - val_loss: 0.0967 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.09418\n",
      "Epoch 383/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1120 - accuracy: 0.9725 - val_loss: 0.0950 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.09418\n",
      "Epoch 384/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1186 - accuracy: 0.9697 - val_loss: 0.0940 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00384: val_loss improved from 0.09418 to 0.09399, saving model to ./model\\384-0.0940.hdf5\n",
      "Epoch 385/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1208 - accuracy: 0.9655 - val_loss: 0.0931 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00385: val_loss improved from 0.09399 to 0.09305, saving model to ./model\\385-0.0931.hdf5\n",
      "Epoch 386/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1082 - accuracy: 0.9713 - val_loss: 0.0950 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.09305\n",
      "Epoch 387/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1189 - accuracy: 0.9705 - val_loss: 0.1004 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.09305\n",
      "Epoch 388/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1106 - accuracy: 0.9739 - val_loss: 0.0931 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.09305\n",
      "Epoch 389/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1204 - accuracy: 0.9648 - val_loss: 0.0904 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00389: val_loss improved from 0.09305 to 0.09037, saving model to ./model\\389-0.0904.hdf5\n",
      "Epoch 390/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1145 - accuracy: 0.9647 - val_loss: 0.0912 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.09037\n",
      "Epoch 391/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1183 - accuracy: 0.9660 - val_loss: 0.0980 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.09037\n",
      "Epoch 392/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1134 - accuracy: 0.9690 - val_loss: 0.0955 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.09037\n",
      "Epoch 393/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1083 - accuracy: 0.9708 - val_loss: 0.0903 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00393: val_loss improved from 0.09037 to 0.09027, saving model to ./model\\393-0.0903.hdf5\n",
      "Epoch 394/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1171 - accuracy: 0.9651 - val_loss: 0.0918 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.09027\n",
      "Epoch 395/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1153 - accuracy: 0.9680 - val_loss: 0.0953 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.09027\n",
      "Epoch 396/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1095 - accuracy: 0.9710 - val_loss: 0.1000 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.09027\n",
      "Epoch 397/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1147 - accuracy: 0.9712 - val_loss: 0.0917 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.09027\n",
      "Epoch 398/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1084 - accuracy: 0.9696 - val_loss: 0.0889 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00398: val_loss improved from 0.09027 to 0.08892, saving model to ./model\\398-0.0889.hdf5\n",
      "Epoch 399/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1127 - accuracy: 0.9666 - val_loss: 0.0984 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.08892\n",
      "Epoch 400/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1152 - accuracy: 0.9707 - val_loss: 0.0988 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.08892\n",
      "Epoch 401/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1104 - accuracy: 0.9710 - val_loss: 0.0891 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.08892\n",
      "Epoch 402/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1131 - accuracy: 0.9664 - val_loss: 0.0887 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00402: val_loss improved from 0.08892 to 0.08869, saving model to ./model\\402-0.0887.hdf5\n",
      "Epoch 403/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1058 - accuracy: 0.9695 - val_loss: 0.0975 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.08869\n",
      "Epoch 404/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1136 - accuracy: 0.9725 - val_loss: 0.0979 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.08869\n",
      "Epoch 405/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1036 - accuracy: 0.9745 - val_loss: 0.0888 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.08869\n",
      "Epoch 406/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1151 - accuracy: 0.9673 - val_loss: 0.0873 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00406: val_loss improved from 0.08869 to 0.08727, saving model to ./model\\406-0.0873.hdf5\n",
      "Epoch 407/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1186 - accuracy: 0.9638 - val_loss: 0.0914 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.08727\n",
      "Epoch 408/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1082 - accuracy: 0.9710 - val_loss: 0.0952 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.08727\n",
      "Epoch 409/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1043 - accuracy: 0.9739 - val_loss: 0.0905 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.08727\n",
      "Epoch 410/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1110 - accuracy: 0.9705 - val_loss: 0.0872 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00410: val_loss improved from 0.08727 to 0.08718, saving model to ./model\\410-0.0872.hdf5\n",
      "Epoch 411/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1076 - accuracy: 0.9680 - val_loss: 0.0897 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.08718\n",
      "Epoch 412/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1106 - accuracy: 0.9719 - val_loss: 0.0958 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.08718\n",
      "Epoch 413/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1053 - accuracy: 0.9732 - val_loss: 0.0920 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.08718\n",
      "Epoch 414/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1062 - accuracy: 0.9697 - val_loss: 0.0878 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.08718\n",
      "Epoch 415/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1070 - accuracy: 0.9695 - val_loss: 0.0900 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.08718\n",
      "Epoch 416/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1033 - accuracy: 0.9725 - val_loss: 0.0947 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.08718\n",
      "Epoch 417/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1110 - accuracy: 0.9705 - val_loss: 0.0897 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.08718\n",
      "Epoch 418/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1075 - accuracy: 0.9710 - val_loss: 0.0855 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00418: val_loss improved from 0.08718 to 0.08554, saving model to ./model\\418-0.0855.hdf5\n",
      "Epoch 419/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1136 - accuracy: 0.9614 - val_loss: 0.0879 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.08554\n",
      "Epoch 420/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1093 - accuracy: 0.9712 - val_loss: 0.0940 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.08554\n",
      "Epoch 421/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1077 - accuracy: 0.9712 - val_loss: 0.0927 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.08554\n",
      "Epoch 422/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1076 - accuracy: 0.9725 - val_loss: 0.0873 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.08554\n",
      "Epoch 423/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1133 - accuracy: 0.9682 - val_loss: 0.0860 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.08554\n",
      "Epoch 424/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1041 - accuracy: 0.9680 - val_loss: 0.0896 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.08554\n",
      "Epoch 425/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1057 - accuracy: 0.9719 - val_loss: 0.0911 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.08554\n",
      "Epoch 426/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1067 - accuracy: 0.9712 - val_loss: 0.0891 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.08554\n",
      "Epoch 427/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0996 - accuracy: 0.9730 - val_loss: 0.0892 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.08554\n",
      "Epoch 428/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1071 - accuracy: 0.9697 - val_loss: 0.0937 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.08554\n",
      "Epoch 429/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1098 - accuracy: 0.9712 - val_loss: 0.0889 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.08554\n",
      "Epoch 430/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1093 - accuracy: 0.9697 - val_loss: 0.0852 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00430: val_loss improved from 0.08554 to 0.08518, saving model to ./model\\430-0.0852.hdf5\n",
      "Epoch 431/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1062 - accuracy: 0.9682 - val_loss: 0.0875 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.08518\n",
      "Epoch 432/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0997 - accuracy: 0.9739 - val_loss: 0.0933 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.08518\n",
      "Epoch 433/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0994 - accuracy: 0.9756 - val_loss: 0.0916 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.08518\n",
      "Epoch 434/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1069 - accuracy: 0.9734 - val_loss: 0.0847 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00434: val_loss improved from 0.08518 to 0.08469, saving model to ./model\\434-0.0847.hdf5\n",
      "Epoch 435/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1074 - accuracy: 0.9689 - val_loss: 0.0838 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00435: val_loss improved from 0.08469 to 0.08380, saving model to ./model\\435-0.0838.hdf5\n",
      "Epoch 436/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1045 - accuracy: 0.9680 - val_loss: 0.0907 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.08380\n",
      "Epoch 437/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1004 - accuracy: 0.9747 - val_loss: 0.0921 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.08380\n",
      "Epoch 438/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1038 - accuracy: 0.9725 - val_loss: 0.0852 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.08380\n",
      "Epoch 439/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0974 - accuracy: 0.9730 - val_loss: 0.0845 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.08380\n",
      "Epoch 440/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1017 - accuracy: 0.9741 - val_loss: 0.0900 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.08380\n",
      "Epoch 441/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0919 - accuracy: 0.9765 - val_loss: 0.0898 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.08380\n",
      "Epoch 442/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1070 - accuracy: 0.9712 - val_loss: 0.0855 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.08380\n",
      "Epoch 443/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1013 - accuracy: 0.9700 - val_loss: 0.0826 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00443: val_loss improved from 0.08380 to 0.08258, saving model to ./model\\443-0.0826.hdf5\n",
      "Epoch 444/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1080 - accuracy: 0.9675 - val_loss: 0.0883 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.08258\n",
      "Epoch 445/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1009 - accuracy: 0.9741 - val_loss: 0.0917 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.08258\n",
      "Epoch 446/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0962 - accuracy: 0.9747 - val_loss: 0.0843 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.08258\n",
      "Epoch 447/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1045 - accuracy: 0.9702 - val_loss: 0.0825 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00447: val_loss improved from 0.08258 to 0.08250, saving model to ./model\\447-0.0825.hdf5\n",
      "Epoch 448/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1071 - accuracy: 0.9688 - val_loss: 0.0855 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.08250\n",
      "Epoch 449/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1031 - accuracy: 0.9683 - val_loss: 0.0886 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.08250\n",
      "Epoch 450/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1037 - accuracy: 0.9727 - val_loss: 0.0851 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.08250\n",
      "Epoch 451/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1014 - accuracy: 0.9725 - val_loss: 0.0825 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00451: val_loss improved from 0.08250 to 0.08250, saving model to ./model\\451-0.0825.hdf5\n",
      "Epoch 452/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1138 - accuracy: 0.9663 - val_loss: 0.0843 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.08250\n",
      "Epoch 453/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1044 - accuracy: 0.9712 - val_loss: 0.0842 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.08250\n",
      "Epoch 454/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1018 - accuracy: 0.9719 - val_loss: 0.0852 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.08250\n",
      "Epoch 455/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1024 - accuracy: 0.9710 - val_loss: 0.0862 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.08250\n",
      "Epoch 456/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0974 - accuracy: 0.9710 - val_loss: 0.0859 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.08250\n",
      "Epoch 457/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1063 - accuracy: 0.9697 - val_loss: 0.0871 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.08250\n",
      "Epoch 458/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1035 - accuracy: 0.9710 - val_loss: 0.0849 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.08250\n",
      "Epoch 459/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1006 - accuracy: 0.9710 - val_loss: 0.0841 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.08250\n",
      "Epoch 460/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1006 - accuracy: 0.9714 - val_loss: 0.0862 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.08250\n",
      "Epoch 461/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1047 - accuracy: 0.9707 - val_loss: 0.0834 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.08250\n",
      "Epoch 462/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0981 - accuracy: 0.9719 - val_loss: 0.0825 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00462: val_loss improved from 0.08250 to 0.08248, saving model to ./model\\462-0.0825.hdf5\n",
      "Epoch 463/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1028 - accuracy: 0.9703 - val_loss: 0.0844 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.08248\n",
      "Epoch 464/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0996 - accuracy: 0.9719 - val_loss: 0.0849 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.08248\n",
      "Epoch 465/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1049 - accuracy: 0.9707 - val_loss: 0.0823 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00465: val_loss improved from 0.08248 to 0.08230, saving model to ./model\\465-0.0823.hdf5\n",
      "Epoch 466/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0939 - accuracy: 0.9723 - val_loss: 0.0806 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00466: val_loss improved from 0.08230 to 0.08060, saving model to ./model\\466-0.0806.hdf5\n",
      "Epoch 467/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0990 - accuracy: 0.9703 - val_loss: 0.0855 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.08060\n",
      "Epoch 468/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1034 - accuracy: 0.9707 - val_loss: 0.0874 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.08060\n",
      "Epoch 469/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0972 - accuracy: 0.9725 - val_loss: 0.0813 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.08060\n",
      "Epoch 470/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0945 - accuracy: 0.9723 - val_loss: 0.0815 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.08060\n",
      "Epoch 471/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1038 - accuracy: 0.9683 - val_loss: 0.0837 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.08060\n",
      "Epoch 472/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1017 - accuracy: 0.9734 - val_loss: 0.0828 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.08060\n",
      "Epoch 473/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1037 - accuracy: 0.9705 - val_loss: 0.0820 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.08060\n",
      "Epoch 474/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1015 - accuracy: 0.9712 - val_loss: 0.0817 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.08060\n",
      "Epoch 475/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0991 - accuracy: 0.9727 - val_loss: 0.0852 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.08060\n",
      "Epoch 476/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0985 - accuracy: 0.9727 - val_loss: 0.0837 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.08060\n",
      "Epoch 477/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0991 - accuracy: 0.9719 - val_loss: 0.0818 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.08060\n",
      "Epoch 478/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0983 - accuracy: 0.9705 - val_loss: 0.0847 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.08060\n",
      "Epoch 479/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0991 - accuracy: 0.9727 - val_loss: 0.0830 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.08060\n",
      "Epoch 480/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0944 - accuracy: 0.9719 - val_loss: 0.0812 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.08060\n",
      "Epoch 481/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0961 - accuracy: 0.9719 - val_loss: 0.0823 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.08060\n",
      "Epoch 482/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0942 - accuracy: 0.9761 - val_loss: 0.0836 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.08060\n",
      "Epoch 483/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0933 - accuracy: 0.9727 - val_loss: 0.0855 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.08060\n",
      "Epoch 484/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1001 - accuracy: 0.9721 - val_loss: 0.0819 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.08060\n",
      "Epoch 485/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1038 - accuracy: 0.9707 - val_loss: 0.0786 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00485: val_loss improved from 0.08060 to 0.07862, saving model to ./model\\485-0.0786.hdf5\n",
      "Epoch 486/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0979 - accuracy: 0.9697 - val_loss: 0.0796 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.07862\n",
      "Epoch 487/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0989 - accuracy: 0.9690 - val_loss: 0.0825 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.07862\n",
      "Epoch 488/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0972 - accuracy: 0.9741 - val_loss: 0.0832 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.07862\n",
      "Epoch 489/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0988 - accuracy: 0.9741 - val_loss: 0.0786 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00489: val_loss improved from 0.07862 to 0.07857, saving model to ./model\\489-0.0786.hdf5\n",
      "Epoch 490/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0959 - accuracy: 0.9717 - val_loss: 0.0775 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00490: val_loss improved from 0.07857 to 0.07750, saving model to ./model\\490-0.0775.hdf5\n",
      "Epoch 491/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0972 - accuracy: 0.9697 - val_loss: 0.0826 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.07750\n",
      "Epoch 492/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0940 - accuracy: 0.9747 - val_loss: 0.0831 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.07750\n",
      "Epoch 493/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0927 - accuracy: 0.9761 - val_loss: 0.0792 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.07750\n",
      "Epoch 494/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0978 - accuracy: 0.9719 - val_loss: 0.0788 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.07750\n",
      "Epoch 495/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0978 - accuracy: 0.9692 - val_loss: 0.0807 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.07750\n",
      "Epoch 496/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0978 - accuracy: 0.9714 - val_loss: 0.0810 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.07750\n",
      "Epoch 497/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0897 - accuracy: 0.9754 - val_loss: 0.0810 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.07750\n",
      "Epoch 498/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0934 - accuracy: 0.9741 - val_loss: 0.0801 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.07750\n",
      "Epoch 499/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0880 - accuracy: 0.9759 - val_loss: 0.0788 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.07750\n",
      "Epoch 500/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1001 - accuracy: 0.9701 - val_loss: 0.0803 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.07750\n",
      "Epoch 501/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0934 - accuracy: 0.9734 - val_loss: 0.0791 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.07750\n",
      "Epoch 502/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0898 - accuracy: 0.9769 - val_loss: 0.0820 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.07750\n",
      "Epoch 503/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0993 - accuracy: 0.9714 - val_loss: 0.0810 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.07750\n",
      "Epoch 504/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0927 - accuracy: 0.9734 - val_loss: 0.0760 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00504: val_loss improved from 0.07750 to 0.07601, saving model to ./model\\504-0.0760.hdf5\n",
      "Epoch 505/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0951 - accuracy: 0.9702 - val_loss: 0.0783 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.07601\n",
      "Epoch 506/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0960 - accuracy: 0.9712 - val_loss: 0.0845 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.07601\n",
      "Epoch 507/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0875 - accuracy: 0.9762 - val_loss: 0.0768 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.07601\n",
      "Epoch 508/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0966 - accuracy: 0.9697 - val_loss: 0.0757 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00508: val_loss improved from 0.07601 to 0.07574, saving model to ./model\\508-0.0757.hdf5\n",
      "Epoch 509/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0923 - accuracy: 0.9702 - val_loss: 0.0795 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.07574\n",
      "Epoch 510/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0970 - accuracy: 0.9722 - val_loss: 0.0825 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.07574\n",
      "Epoch 511/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0908 - accuracy: 0.9776 - val_loss: 0.0772 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.07574\n",
      "Epoch 512/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0918 - accuracy: 0.9739 - val_loss: 0.0774 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.07574\n",
      "Epoch 513/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0924 - accuracy: 0.9749 - val_loss: 0.0837 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.07574\n",
      "Epoch 514/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0917 - accuracy: 0.9749 - val_loss: 0.0790 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.07574\n",
      "Epoch 515/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0891 - accuracy: 0.9749 - val_loss: 0.0773 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.07574\n",
      "Epoch 516/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0902 - accuracy: 0.9762 - val_loss: 0.0795 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.07574\n",
      "Epoch 517/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0911 - accuracy: 0.9751 - val_loss: 0.0812 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.07574\n",
      "Epoch 518/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0927 - accuracy: 0.9751 - val_loss: 0.0771 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.07574\n",
      "Epoch 519/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0950 - accuracy: 0.9734 - val_loss: 0.0757 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00519: val_loss improved from 0.07574 to 0.07570, saving model to ./model\\519-0.0757.hdf5\n",
      "Epoch 520/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0905 - accuracy: 0.9727 - val_loss: 0.0790 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.07570\n",
      "Epoch 521/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0966 - accuracy: 0.9736 - val_loss: 0.0795 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.07570\n",
      "Epoch 522/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0947 - accuracy: 0.9729 - val_loss: 0.0764 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.07570\n",
      "Epoch 523/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0860 - accuracy: 0.9762 - val_loss: 0.0761 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.07570\n",
      "Epoch 524/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0939 - accuracy: 0.9742 - val_loss: 0.0787 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.07570\n",
      "Epoch 525/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0886 - accuracy: 0.9769 - val_loss: 0.0783 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.07570\n",
      "Epoch 526/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0962 - accuracy: 0.9714 - val_loss: 0.0771 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.07570\n",
      "Epoch 527/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0942 - accuracy: 0.9729 - val_loss: 0.0768 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.07570\n",
      "Epoch 528/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0892 - accuracy: 0.9756 - val_loss: 0.0759 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.07570\n",
      "Epoch 529/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0922 - accuracy: 0.9729 - val_loss: 0.0769 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.07570\n",
      "Epoch 530/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0875 - accuracy: 0.9756 - val_loss: 0.0769 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.07570\n",
      "Epoch 531/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0865 - accuracy: 0.9756 - val_loss: 0.0789 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.07570\n",
      "Epoch 532/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0930 - accuracy: 0.9722 - val_loss: 0.0773 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.07570\n",
      "Epoch 533/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0902 - accuracy: 0.9737 - val_loss: 0.0739 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00533: val_loss improved from 0.07570 to 0.07385, saving model to ./model\\533-0.0739.hdf5\n",
      "Epoch 534/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0949 - accuracy: 0.9699 - val_loss: 0.0783 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.07385\n",
      "Epoch 535/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0916 - accuracy: 0.9738 - val_loss: 0.0787 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.07385\n",
      "Epoch 536/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0853 - accuracy: 0.9756 - val_loss: 0.0749 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.07385\n",
      "Epoch 537/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0823 - accuracy: 0.9776 - val_loss: 0.0747 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.07385\n",
      "Epoch 538/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0852 - accuracy: 0.9749 - val_loss: 0.0790 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.07385\n",
      "Epoch 539/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0859 - accuracy: 0.9784 - val_loss: 0.0803 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.07385\n",
      "Epoch 540/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0868 - accuracy: 0.9756 - val_loss: 0.0755 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.07385\n",
      "Epoch 541/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0856 - accuracy: 0.9756 - val_loss: 0.0742 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.07385\n",
      "Epoch 542/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0850 - accuracy: 0.9756 - val_loss: 0.0796 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.07385\n",
      "Epoch 543/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0895 - accuracy: 0.9734 - val_loss: 0.0837 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.07385\n",
      "Epoch 544/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0904 - accuracy: 0.9744 - val_loss: 0.0733 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00544: val_loss improved from 0.07385 to 0.07329, saving model to ./model\\544-0.0733.hdf5\n",
      "Epoch 545/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0922 - accuracy: 0.9714 - val_loss: 0.0721 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00545: val_loss improved from 0.07329 to 0.07209, saving model to ./model\\545-0.0721.hdf5\n",
      "Epoch 546/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0887 - accuracy: 0.9717 - val_loss: 0.0756 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.07209\n",
      "Epoch 547/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0810 - accuracy: 0.9784 - val_loss: 0.0799 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.07209\n",
      "Epoch 548/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0862 - accuracy: 0.9751 - val_loss: 0.0770 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.07209\n",
      "Epoch 549/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0873 - accuracy: 0.9751 - val_loss: 0.0738 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.07209\n",
      "Epoch 550/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0859 - accuracy: 0.9736 - val_loss: 0.0749 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.07209\n",
      "Epoch 551/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0912 - accuracy: 0.9751 - val_loss: 0.0740 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.07209\n",
      "Epoch 552/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0803 - accuracy: 0.9767 - val_loss: 0.0737 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.07209\n",
      "Epoch 553/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0830 - accuracy: 0.9747 - val_loss: 0.0814 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.07209\n",
      "Epoch 554/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0893 - accuracy: 0.9751 - val_loss: 0.0758 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.07209\n",
      "Epoch 555/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0870 - accuracy: 0.9762 - val_loss: 0.0710 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00555: val_loss improved from 0.07209 to 0.07101, saving model to ./model\\555-0.0710.hdf5\n",
      "Epoch 556/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0956 - accuracy: 0.9690 - val_loss: 0.0729 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.07101\n",
      "Epoch 557/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0898 - accuracy: 0.9742 - val_loss: 0.0812 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.07101\n",
      "Epoch 558/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0866 - accuracy: 0.9764 - val_loss: 0.0767 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.07101\n",
      "Epoch 559/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0877 - accuracy: 0.9775 - val_loss: 0.0718 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.07101\n",
      "Epoch 560/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0927 - accuracy: 0.9716 - val_loss: 0.0716 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.07101\n",
      "Epoch 561/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0885 - accuracy: 0.9734 - val_loss: 0.0772 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.07101\n",
      "Epoch 562/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0843 - accuracy: 0.9771 - val_loss: 0.0785 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.07101\n",
      "Epoch 563/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0839 - accuracy: 0.9751 - val_loss: 0.0736 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.07101\n",
      "Epoch 564/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0883 - accuracy: 0.9758 - val_loss: 0.0720 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.07101\n",
      "Epoch 565/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0812 - accuracy: 0.9769 - val_loss: 0.0729 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.07101\n",
      "Epoch 566/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0841 - accuracy: 0.9749 - val_loss: 0.0780 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.07101\n",
      "Epoch 567/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0873 - accuracy: 0.9742 - val_loss: 0.0756 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.07101\n",
      "Epoch 568/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0841 - accuracy: 0.9758 - val_loss: 0.0742 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.07101\n",
      "Epoch 569/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0888 - accuracy: 0.9722 - val_loss: 0.0758 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.07101\n",
      "Epoch 570/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0833 - accuracy: 0.9751 - val_loss: 0.0735 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.07101\n",
      "Epoch 571/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0834 - accuracy: 0.9758 - val_loss: 0.0746 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.07101\n",
      "Epoch 572/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0855 - accuracy: 0.9751 - val_loss: 0.0745 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.07101\n",
      "Epoch 573/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0821 - accuracy: 0.9771 - val_loss: 0.0727 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.07101\n",
      "Epoch 574/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0856 - accuracy: 0.9758 - val_loss: 0.0737 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.07101\n",
      "Epoch 575/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0852 - accuracy: 0.9766 - val_loss: 0.0753 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.07101\n",
      "Epoch 576/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0815 - accuracy: 0.9779 - val_loss: 0.0743 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.07101\n",
      "Epoch 577/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0900 - accuracy: 0.9739 - val_loss: 0.0740 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.07101\n",
      "Epoch 578/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0841 - accuracy: 0.9766 - val_loss: 0.0725 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.07101\n",
      "Epoch 579/3500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0852 - accuracy: 0.9764 - val_loss: 0.0731 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.07101\n",
      "Epoch 580/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0856 - accuracy: 0.9759 - val_loss: 0.0725 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.07101\n",
      "Epoch 581/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0866 - accuracy: 0.9758 - val_loss: 0.0708 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00581: val_loss improved from 0.07101 to 0.07076, saving model to ./model\\581-0.0708.hdf5\n",
      "Epoch 582/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0820 - accuracy: 0.9756 - val_loss: 0.0730 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.07076\n",
      "Epoch 583/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0868 - accuracy: 0.9738 - val_loss: 0.0770 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.07076\n",
      "Epoch 584/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0801 - accuracy: 0.9786 - val_loss: 0.0735 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.07076\n",
      "Epoch 585/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0774 - accuracy: 0.9786 - val_loss: 0.0726 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.07076\n",
      "Epoch 586/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0806 - accuracy: 0.9758 - val_loss: 0.0738 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.07076\n",
      "Epoch 587/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0871 - accuracy: 0.9766 - val_loss: 0.0759 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.07076\n",
      "Epoch 588/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0827 - accuracy: 0.9801 - val_loss: 0.0722 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.07076\n",
      "Epoch 589/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0811 - accuracy: 0.9771 - val_loss: 0.0740 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.07076\n",
      "Epoch 590/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0809 - accuracy: 0.9773 - val_loss: 0.0736 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.07076\n",
      "Epoch 591/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0821 - accuracy: 0.9779 - val_loss: 0.0723 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.07076\n",
      "Epoch 592/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0802 - accuracy: 0.9778 - val_loss: 0.0757 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.07076\n",
      "Epoch 593/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0828 - accuracy: 0.9786 - val_loss: 0.0795 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.07076\n",
      "Epoch 594/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0835 - accuracy: 0.9773 - val_loss: 0.0730 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.07076\n",
      "Epoch 595/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0789 - accuracy: 0.9786 - val_loss: 0.0704 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00595: val_loss improved from 0.07076 to 0.07036, saving model to ./model\\595-0.0704.hdf5\n",
      "Epoch 596/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0845 - accuracy: 0.9751 - val_loss: 0.0747 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.07036\n",
      "Epoch 597/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0870 - accuracy: 0.9753 - val_loss: 0.0730 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.07036\n",
      "Epoch 598/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0844 - accuracy: 0.9766 - val_loss: 0.0717 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.07036\n",
      "Epoch 599/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0858 - accuracy: 0.9744 - val_loss: 0.0724 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.07036\n",
      "Epoch 600/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0821 - accuracy: 0.9773 - val_loss: 0.0752 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.07036\n",
      "Epoch 601/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0805 - accuracy: 0.9771 - val_loss: 0.0722 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.07036\n",
      "Epoch 602/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0766 - accuracy: 0.9776 - val_loss: 0.0703 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00602: val_loss improved from 0.07036 to 0.07035, saving model to ./model\\602-0.0703.hdf5\n",
      "Epoch 603/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0725 - accuracy: 0.9793 - val_loss: 0.0807 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.07035\n",
      "Epoch 604/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0853 - accuracy: 0.9764 - val_loss: 0.0788 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.07035\n",
      "Epoch 605/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0828 - accuracy: 0.9766 - val_loss: 0.0682 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00605: val_loss improved from 0.07035 to 0.06821, saving model to ./model\\605-0.0682.hdf5\n",
      "Epoch 606/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0823 - accuracy: 0.9732 - val_loss: 0.0683 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.06821\n",
      "Epoch 607/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0877 - accuracy: 0.9724 - val_loss: 0.0801 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.06821\n",
      "Epoch 608/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0843 - accuracy: 0.9764 - val_loss: 0.0729 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.06821\n",
      "Epoch 609/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0762 - accuracy: 0.9799 - val_loss: 0.0682 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.06821\n",
      "Epoch 610/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0866 - accuracy: 0.9744 - val_loss: 0.0720 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.06821\n",
      "Epoch 611/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0818 - accuracy: 0.9758 - val_loss: 0.0763 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.06821\n",
      "Epoch 612/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0843 - accuracy: 0.9775 - val_loss: 0.0716 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.06821\n",
      "Epoch 613/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0810 - accuracy: 0.9773 - val_loss: 0.0686 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.06821\n",
      "Epoch 614/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0779 - accuracy: 0.9773 - val_loss: 0.0712 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.06821\n",
      "Epoch 615/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0799 - accuracy: 0.9775 - val_loss: 0.0740 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.06821\n",
      "Epoch 616/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0815 - accuracy: 0.9779 - val_loss: 0.0711 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.06821\n",
      "Epoch 617/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0780 - accuracy: 0.9779 - val_loss: 0.0701 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.06821\n",
      "Epoch 618/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0780 - accuracy: 0.9773 - val_loss: 0.0730 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.06821\n",
      "Epoch 619/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0809 - accuracy: 0.9768 - val_loss: 0.0733 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.06821\n",
      "Epoch 620/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0782 - accuracy: 0.9773 - val_loss: 0.0699 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.06821\n",
      "Epoch 621/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0771 - accuracy: 0.9773 - val_loss: 0.0714 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.06821\n",
      "Epoch 622/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0725 - accuracy: 0.9786 - val_loss: 0.0732 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.06821\n",
      "Epoch 623/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0803 - accuracy: 0.9759 - val_loss: 0.0720 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.06821\n",
      "Epoch 624/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0815 - accuracy: 0.9759 - val_loss: 0.0697 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.06821\n",
      "Epoch 625/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0737 - accuracy: 0.9793 - val_loss: 0.0738 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.06821\n",
      "Epoch 626/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0761 - accuracy: 0.9779 - val_loss: 0.0766 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.06821\n",
      "Epoch 627/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0811 - accuracy: 0.9729 - val_loss: 0.0708 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.06821\n",
      "Epoch 628/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0781 - accuracy: 0.9766 - val_loss: 0.0692 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.06821\n",
      "Epoch 629/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0733 - accuracy: 0.9808 - val_loss: 0.0723 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.06821\n",
      "Epoch 630/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0733 - accuracy: 0.9801 - val_loss: 0.0786 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.06821\n",
      "Epoch 631/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0794 - accuracy: 0.9771 - val_loss: 0.0707 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.06821\n",
      "Epoch 632/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0838 - accuracy: 0.9753 - val_loss: 0.0683 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.06821\n",
      "Epoch 633/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0793 - accuracy: 0.9788 - val_loss: 0.0672 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00633: val_loss improved from 0.06821 to 0.06723, saving model to ./model\\633-0.0672.hdf5\n",
      "Epoch 634/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0777 - accuracy: 0.9773 - val_loss: 0.0695 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.06723\n",
      "Epoch 635/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0754 - accuracy: 0.9766 - val_loss: 0.0756 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.06723\n",
      "Epoch 636/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0804 - accuracy: 0.9759 - val_loss: 0.0725 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.06723\n",
      "Epoch 637/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0801 - accuracy: 0.9775 - val_loss: 0.0677 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.06723\n",
      "Epoch 638/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0792 - accuracy: 0.9781 - val_loss: 0.0668 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00638: val_loss improved from 0.06723 to 0.06685, saving model to ./model\\638-0.0668.hdf5\n",
      "Epoch 639/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0788 - accuracy: 0.9781 - val_loss: 0.0690 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.06685\n",
      "Epoch 640/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0800 - accuracy: 0.9759 - val_loss: 0.0746 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.06685\n",
      "Epoch 641/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0785 - accuracy: 0.9773 - val_loss: 0.0727 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.06685\n",
      "Epoch 642/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0754 - accuracy: 0.9788 - val_loss: 0.0696 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.06685\n",
      "Epoch 643/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0773 - accuracy: 0.9779 - val_loss: 0.0697 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.06685\n",
      "Epoch 644/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0817 - accuracy: 0.9753 - val_loss: 0.0713 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.06685\n",
      "Epoch 645/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0755 - accuracy: 0.9766 - val_loss: 0.0703 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.06685\n",
      "Epoch 646/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0783 - accuracy: 0.9759 - val_loss: 0.0691 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.06685\n",
      "Epoch 647/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0790 - accuracy: 0.9773 - val_loss: 0.0688 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.06685\n",
      "Epoch 648/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0739 - accuracy: 0.9773 - val_loss: 0.0728 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.06685\n",
      "Epoch 649/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0775 - accuracy: 0.9786 - val_loss: 0.0720 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.06685\n",
      "Epoch 650/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0719 - accuracy: 0.9815 - val_loss: 0.0696 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.06685\n",
      "Epoch 651/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0735 - accuracy: 0.9773 - val_loss: 0.0717 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.06685\n",
      "Epoch 652/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0757 - accuracy: 0.9779 - val_loss: 0.0694 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.06685\n",
      "Epoch 653/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0756 - accuracy: 0.9753 - val_loss: 0.0686 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.06685\n",
      "Epoch 654/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0822 - accuracy: 0.9746 - val_loss: 0.0688 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.06685\n",
      "Epoch 655/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0760 - accuracy: 0.9766 - val_loss: 0.0684 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.06685\n",
      "Epoch 656/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0806 - accuracy: 0.9739 - val_loss: 0.0693 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.06685\n",
      "Epoch 657/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0761 - accuracy: 0.9759 - val_loss: 0.0691 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.06685\n",
      "Epoch 658/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0791 - accuracy: 0.9773 - val_loss: 0.0705 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.06685\n",
      "Epoch 659/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0728 - accuracy: 0.9779 - val_loss: 0.0695 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.06685\n",
      "Epoch 660/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0767 - accuracy: 0.9759 - val_loss: 0.0703 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.06685\n",
      "Epoch 661/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0726 - accuracy: 0.9786 - val_loss: 0.0701 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.06685\n",
      "Epoch 662/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0735 - accuracy: 0.9793 - val_loss: 0.0719 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.06685\n",
      "Epoch 663/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0768 - accuracy: 0.9759 - val_loss: 0.0706 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.06685\n",
      "Epoch 664/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0746 - accuracy: 0.9773 - val_loss: 0.0661 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00664: val_loss improved from 0.06685 to 0.06609, saving model to ./model\\664-0.0661.hdf5\n",
      "Epoch 665/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0768 - accuracy: 0.9768 - val_loss: 0.0714 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.06609\n",
      "Epoch 666/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0735 - accuracy: 0.9788 - val_loss: 0.0696 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.06609\n",
      "Epoch 667/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0783 - accuracy: 0.9759 - val_loss: 0.0659 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00667: val_loss improved from 0.06609 to 0.06589, saving model to ./model\\667-0.0659.hdf5\n",
      "Epoch 668/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0748 - accuracy: 0.9790 - val_loss: 0.0679 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.06589\n",
      "Epoch 669/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0781 - accuracy: 0.9744 - val_loss: 0.0718 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.06589\n",
      "Epoch 670/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0775 - accuracy: 0.9775 - val_loss: 0.0678 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.06589\n",
      "Epoch 671/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0758 - accuracy: 0.9773 - val_loss: 0.0673 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.06589\n",
      "Epoch 672/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0726 - accuracy: 0.9788 - val_loss: 0.0727 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.06589\n",
      "Epoch 673/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0750 - accuracy: 0.9781 - val_loss: 0.0709 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.06589\n",
      "Epoch 674/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0720 - accuracy: 0.9788 - val_loss: 0.0675 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.06589\n",
      "Epoch 675/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0767 - accuracy: 0.9768 - val_loss: 0.0685 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.06589\n",
      "Epoch 676/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0696 - accuracy: 0.9799 - val_loss: 0.0739 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.06589\n",
      "Epoch 677/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0716 - accuracy: 0.9779 - val_loss: 0.0731 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.06589\n",
      "Epoch 678/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0716 - accuracy: 0.9795 - val_loss: 0.0673 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.06589\n",
      "Epoch 679/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0758 - accuracy: 0.9781 - val_loss: 0.0681 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.06589\n",
      "Epoch 680/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0762 - accuracy: 0.9775 - val_loss: 0.0733 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.06589\n",
      "Epoch 681/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0697 - accuracy: 0.9801 - val_loss: 0.0697 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.06589\n",
      "Epoch 682/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0769 - accuracy: 0.9761 - val_loss: 0.0660 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.06589\n",
      "Epoch 683/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0763 - accuracy: 0.9777 - val_loss: 0.0658 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00683: val_loss improved from 0.06589 to 0.06585, saving model to ./model\\683-0.0658.hdf5\n",
      "Epoch 684/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0685 - accuracy: 0.9808 - val_loss: 0.0702 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.06585\n",
      "Epoch 685/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0729 - accuracy: 0.9797 - val_loss: 0.0748 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.06585\n",
      "Epoch 686/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0705 - accuracy: 0.9773 - val_loss: 0.0676 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.06585\n",
      "Epoch 687/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0722 - accuracy: 0.9798 - val_loss: 0.0652 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00687: val_loss improved from 0.06585 to 0.06521, saving model to ./model\\687-0.0652.hdf5\n",
      "Epoch 688/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0774 - accuracy: 0.9777 - val_loss: 0.0678 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.06521\n",
      "Epoch 689/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0743 - accuracy: 0.9805 - val_loss: 0.0731 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.06521\n",
      "Epoch 690/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0756 - accuracy: 0.9770 - val_loss: 0.0696 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.06521\n",
      "Epoch 691/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0721 - accuracy: 0.9788 - val_loss: 0.0670 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.06521\n",
      "Epoch 692/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0710 - accuracy: 0.9788 - val_loss: 0.0677 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.06521\n",
      "Epoch 693/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0756 - accuracy: 0.9761 - val_loss: 0.0684 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.06521\n",
      "Epoch 694/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0767 - accuracy: 0.9768 - val_loss: 0.0665 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.06521\n",
      "Epoch 695/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0685 - accuracy: 0.9810 - val_loss: 0.0694 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.06521\n",
      "Epoch 696/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0698 - accuracy: 0.9797 - val_loss: 0.0731 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.06521\n",
      "Epoch 697/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0658 - accuracy: 0.9795 - val_loss: 0.0699 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.06521\n",
      "Epoch 698/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0667 - accuracy: 0.9795 - val_loss: 0.0695 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.06521\n",
      "Epoch 699/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0704 - accuracy: 0.9759 - val_loss: 0.0723 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.06521\n",
      "Epoch 700/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0651 - accuracy: 0.9808 - val_loss: 0.0670 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.06521\n",
      "Epoch 701/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0692 - accuracy: 0.9818 - val_loss: 0.0673 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.06521\n",
      "Epoch 702/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0647 - accuracy: 0.9803 - val_loss: 0.0744 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.06521\n",
      "Epoch 703/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0698 - accuracy: 0.9766 - val_loss: 0.0710 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.06521\n",
      "Epoch 704/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0693 - accuracy: 0.9798 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.06521\n",
      "Epoch 705/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0707 - accuracy: 0.9798 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.06521\n",
      "Epoch 706/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0719 - accuracy: 0.9790 - val_loss: 0.0706 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.06521\n",
      "Epoch 707/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0722 - accuracy: 0.9790 - val_loss: 0.0718 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.06521\n",
      "Epoch 708/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0724 - accuracy: 0.9783 - val_loss: 0.0675 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.06521\n",
      "Epoch 709/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0724 - accuracy: 0.9820 - val_loss: 0.0653 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.06521\n",
      "Epoch 710/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0733 - accuracy: 0.9798 - val_loss: 0.0672 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.06521\n",
      "Epoch 711/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0669 - accuracy: 0.9803 - val_loss: 0.0716 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.06521\n",
      "Epoch 712/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0740 - accuracy: 0.9768 - val_loss: 0.0758 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.06521\n",
      "Epoch 713/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0696 - accuracy: 0.9795 - val_loss: 0.0675 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.06521\n",
      "Epoch 714/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0672 - accuracy: 0.9812 - val_loss: 0.0655 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.06521\n",
      "Epoch 715/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0720 - accuracy: 0.9812 - val_loss: 0.0701 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.06521\n",
      "Epoch 716/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0628 - accuracy: 0.9801 - val_loss: 0.0744 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.06521\n",
      "Epoch 717/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0731 - accuracy: 0.9783 - val_loss: 0.0671 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.06521\n",
      "Epoch 718/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0667 - accuracy: 0.9803 - val_loss: 0.0662 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.06521\n",
      "Epoch 719/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0643 - accuracy: 0.9805 - val_loss: 0.0748 - val_accuracy: 0.9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00719: val_loss did not improve from 0.06521\n",
      "Epoch 720/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0750 - accuracy: 0.9736 - val_loss: 0.0726 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.06521\n",
      "Epoch 721/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0692 - accuracy: 0.9775 - val_loss: 0.0649 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00721: val_loss improved from 0.06521 to 0.06492, saving model to ./model\\721-0.0649.hdf5\n",
      "Epoch 722/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0753 - accuracy: 0.9790 - val_loss: 0.0653 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.06492\n",
      "Epoch 723/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0722 - accuracy: 0.9768 - val_loss: 0.0742 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.06492\n",
      "Epoch 724/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 0.0750 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.06492\n",
      "Epoch 725/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0721 - accuracy: 0.9724 - val_loss: 0.0675 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.06492\n",
      "Epoch 726/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0648 - accuracy: 0.9825 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.06492\n",
      "Epoch 727/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0694 - accuracy: 0.9790 - val_loss: 0.0710 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.06492\n",
      "Epoch 728/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0699 - accuracy: 0.9792 - val_loss: 0.0698 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.06492\n",
      "Epoch 729/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0661 - accuracy: 0.9825 - val_loss: 0.0680 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.06492\n",
      "Epoch 730/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0636 - accuracy: 0.9832 - val_loss: 0.0726 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.06492\n",
      "Epoch 731/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0696 - accuracy: 0.9790 - val_loss: 0.0693 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.06492\n",
      "Epoch 732/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0694 - accuracy: 0.9805 - val_loss: 0.0680 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.06492\n",
      "Epoch 733/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0685 - accuracy: 0.9770 - val_loss: 0.0697 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.06492\n",
      "Epoch 734/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0699 - accuracy: 0.9798 - val_loss: 0.0708 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.06492\n",
      "Epoch 735/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 0.9783 - val_loss: 0.0706 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.06492\n",
      "Epoch 736/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0666 - accuracy: 0.9805 - val_loss: 0.0710 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.06492\n",
      "Epoch 737/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0640 - accuracy: 0.9803 - val_loss: 0.0695 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.06492\n",
      "Epoch 738/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0615 - accuracy: 0.9812 - val_loss: 0.0699 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.06492\n",
      "Epoch 739/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0688 - accuracy: 0.9798 - val_loss: 0.0706 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.06492\n",
      "Epoch 740/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0672 - accuracy: 0.9798 - val_loss: 0.0687 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.06492\n",
      "Epoch 741/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0621 - accuracy: 0.9825 - val_loss: 0.0709 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.06492\n",
      "Epoch 742/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0661 - accuracy: 0.9805 - val_loss: 0.0719 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.06492\n",
      "Epoch 743/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0657 - accuracy: 0.9812 - val_loss: 0.0684 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.06492\n",
      "Epoch 744/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0656 - accuracy: 0.9827 - val_loss: 0.0703 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.06492\n",
      "Epoch 745/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0679 - accuracy: 0.9814 - val_loss: 0.0711 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.06492\n",
      "Epoch 746/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0644 - accuracy: 0.9812 - val_loss: 0.0694 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.06492\n",
      "Epoch 747/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0664 - accuracy: 0.9814 - val_loss: 0.0680 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.06492\n",
      "Epoch 748/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0656 - accuracy: 0.9834 - val_loss: 0.0700 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.06492\n",
      "Epoch 749/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0645 - accuracy: 0.9827 - val_loss: 0.0727 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.06492\n",
      "Epoch 750/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0678 - accuracy: 0.9783 - val_loss: 0.0692 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.06492\n",
      "Epoch 751/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0653 - accuracy: 0.9814 - val_loss: 0.0677 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.06492\n",
      "Epoch 752/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0649 - accuracy: 0.9798 - val_loss: 0.0727 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.06492\n",
      "Epoch 753/3500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0675 - accuracy: 0.9777 - val_loss: 0.0713 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.06492\n",
      "Epoch 754/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0629 - accuracy: 0.9818 - val_loss: 0.0677 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.06492\n",
      "Epoch 755/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0639 - accuracy: 0.9818 - val_loss: 0.0708 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.06492\n",
      "Epoch 756/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0693 - accuracy: 0.9800 - val_loss: 0.0716 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.06492\n",
      "Epoch 757/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0641 - accuracy: 0.9820 - val_loss: 0.0676 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.06492\n",
      "Epoch 758/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0597 - accuracy: 0.9840 - val_loss: 0.0696 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.06492\n",
      "Epoch 759/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0607 - accuracy: 0.9834 - val_loss: 0.0769 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.06492\n",
      "Epoch 760/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0649 - accuracy: 0.9773 - val_loss: 0.0728 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.06492\n",
      "Epoch 761/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0697 - accuracy: 0.9748 - val_loss: 0.0658 - val_accuracy: 0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00761: val_loss did not improve from 0.06492\n",
      "Epoch 762/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0657 - accuracy: 0.9805 - val_loss: 0.0654 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.06492\n",
      "Epoch 763/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0691 - accuracy: 0.9792 - val_loss: 0.0696 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.06492\n",
      "Epoch 764/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0578 - accuracy: 0.9786 - val_loss: 0.0711 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.06492\n",
      "Epoch 765/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0640 - accuracy: 0.9759 - val_loss: 0.0700 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.06492\n",
      "Epoch 766/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0600 - accuracy: 0.9783 - val_loss: 0.0655 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.06492\n",
      "Epoch 767/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 0.0669 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.06492\n",
      "Epoch 768/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0627 - accuracy: 0.9797 - val_loss: 0.0766 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.06492\n",
      "Epoch 769/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0624 - accuracy: 0.9781 - val_loss: 0.0670 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.06492\n",
      "Epoch 770/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0628 - accuracy: 0.9840 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.06492\n",
      "Epoch 771/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0609 - accuracy: 0.9827 - val_loss: 0.0737 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.06492\n",
      "Epoch 772/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0598 - accuracy: 0.9795 - val_loss: 0.0714 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.06492\n",
      "Epoch 773/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0629 - accuracy: 0.9783 - val_loss: 0.0647 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00773: val_loss improved from 0.06492 to 0.06468, saving model to ./model\\773-0.0647.hdf5\n",
      "Epoch 774/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0624 - accuracy: 0.9842 - val_loss: 0.0647 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.06468\n",
      "Epoch 775/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0694 - accuracy: 0.9798 - val_loss: 0.0742 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.06468\n",
      "Epoch 776/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0641 - accuracy: 0.9790 - val_loss: 0.0706 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.06468\n",
      "Epoch 777/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0652 - accuracy: 0.9783 - val_loss: 0.0650 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.06468\n",
      "Epoch 778/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0643 - accuracy: 0.9818 - val_loss: 0.0657 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.06468\n",
      "Epoch 779/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0597 - accuracy: 0.9803 - val_loss: 0.0723 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.06468\n",
      "Epoch 780/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0653 - accuracy: 0.9777 - val_loss: 0.0678 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.06468\n",
      "Epoch 781/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0592 - accuracy: 0.9781 - val_loss: 0.0637 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00781: val_loss improved from 0.06468 to 0.06369, saving model to ./model\\781-0.0637.hdf5\n",
      "Epoch 782/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0645 - accuracy: 0.9829 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.06369\n",
      "Epoch 783/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0565 - accuracy: 0.9847 - val_loss: 0.0719 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.06369\n",
      "Epoch 784/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0639 - accuracy: 0.9790 - val_loss: 0.0668 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.06369\n",
      "Epoch 785/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0619 - accuracy: 0.9837 - val_loss: 0.0641 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.06369\n",
      "Epoch 786/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0614 - accuracy: 0.9814 - val_loss: 0.0666 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.06369\n",
      "Epoch 787/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0573 - accuracy: 0.9849 - val_loss: 0.0674 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.06369\n",
      "Epoch 788/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0584 - accuracy: 0.9829 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.06369\n",
      "Epoch 789/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0617 - accuracy: 0.9829 - val_loss: 0.0654 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.06369\n",
      "Epoch 790/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0611 - accuracy: 0.9829 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.06369\n",
      "Epoch 791/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0622 - accuracy: 0.9822 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.06369\n",
      "Epoch 792/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0558 - accuracy: 0.9873 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.06369\n",
      "Epoch 793/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0588 - accuracy: 0.9851 - val_loss: 0.0685 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.06369\n",
      "Epoch 794/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0578 - accuracy: 0.9798 - val_loss: 0.0668 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.06369\n",
      "Epoch 795/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0556 - accuracy: 0.9873 - val_loss: 0.0661 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.06369\n",
      "Epoch 796/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0582 - accuracy: 0.9842 - val_loss: 0.0668 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.06369\n",
      "Epoch 797/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0637 - accuracy: 0.9824 - val_loss: 0.0667 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.06369\n",
      "Epoch 798/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.0664 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.06369\n",
      "Epoch 799/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0597 - accuracy: 0.9805 - val_loss: 0.0715 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.06369\n",
      "Epoch 800/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0606 - accuracy: 0.9829 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.06369\n",
      "Epoch 801/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0570 - accuracy: 0.9840 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.06369\n",
      "Epoch 802/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0620 - accuracy: 0.9816 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.06369\n",
      "Epoch 803/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0569 - accuracy: 0.9857 - val_loss: 0.0657 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.06369\n",
      "Epoch 804/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0607 - accuracy: 0.9822 - val_loss: 0.0636 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00804: val_loss improved from 0.06369 to 0.06363, saving model to ./model\\804-0.0636.hdf5\n",
      "Epoch 805/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0577 - accuracy: 0.9842 - val_loss: 0.0648 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.06363\n",
      "Epoch 806/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0593 - accuracy: 0.9818 - val_loss: 0.0707 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.06363\n",
      "Epoch 807/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0608 - accuracy: 0.9822 - val_loss: 0.0642 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.06363\n",
      "Epoch 808/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0590 - accuracy: 0.9837 - val_loss: 0.0628 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00808: val_loss improved from 0.06363 to 0.06283, saving model to ./model\\808-0.0628.hdf5\n",
      "Epoch 809/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0565 - accuracy: 0.9849 - val_loss: 0.0673 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.06283\n",
      "Epoch 810/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0616 - accuracy: 0.9807 - val_loss: 0.0734 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.06283\n",
      "Epoch 811/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.0643 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.06283\n",
      "Epoch 812/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0539 - accuracy: 0.9842 - val_loss: 0.0653 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.06283\n",
      "Epoch 813/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0596 - accuracy: 0.9822 - val_loss: 0.0688 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.06283\n",
      "Epoch 814/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0579 - accuracy: 0.9866 - val_loss: 0.0638 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.06283\n",
      "Epoch 815/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 0.0645 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.06283\n",
      "Epoch 816/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0554 - accuracy: 0.9814 - val_loss: 0.0684 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.06283\n",
      "Epoch 817/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0580 - accuracy: 0.9857 - val_loss: 0.0678 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.06283\n",
      "Epoch 818/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0571 - accuracy: 0.9842 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.06283\n",
      "Epoch 819/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0597 - accuracy: 0.9822 - val_loss: 0.0629 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.06283\n",
      "Epoch 820/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0534 - accuracy: 0.9842 - val_loss: 0.0650 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.06283\n",
      "Epoch 821/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0523 - accuracy: 0.9834 - val_loss: 0.0678 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.06283\n",
      "Epoch 822/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0560 - accuracy: 0.9829 - val_loss: 0.0647 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.06283\n",
      "Epoch 823/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0508 - accuracy: 0.9886 - val_loss: 0.0650 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.06283\n",
      "Epoch 824/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0547 - accuracy: 0.9857 - val_loss: 0.0702 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.06283\n",
      "Epoch 825/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0574 - accuracy: 0.9849 - val_loss: 0.0647 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.06283\n",
      "Epoch 826/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0609 - accuracy: 0.9831 - val_loss: 0.0624 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00826: val_loss improved from 0.06283 to 0.06239, saving model to ./model\\826-0.0624.hdf5\n",
      "Epoch 827/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0575 - accuracy: 0.9814 - val_loss: 0.0655 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.06239\n",
      "Epoch 828/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0550 - accuracy: 0.9844 - val_loss: 0.0729 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.06239\n",
      "Epoch 829/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0555 - accuracy: 0.9866 - val_loss: 0.0653 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.06239\n",
      "Epoch 830/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0581 - accuracy: 0.9803 - val_loss: 0.0626 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.06239\n",
      "Epoch 831/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0613 - accuracy: 0.9805 - val_loss: 0.0684 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.06239\n",
      "Epoch 832/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0531 - accuracy: 0.9849 - val_loss: 0.0645 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.06239\n",
      "Epoch 833/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0542 - accuracy: 0.9842 - val_loss: 0.0647 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.06239\n",
      "Epoch 834/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0570 - accuracy: 0.9844 - val_loss: 0.0641 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.06239\n",
      "Epoch 835/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0534 - accuracy: 0.9851 - val_loss: 0.0643 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.06239\n",
      "Epoch 836/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0557 - accuracy: 0.9844 - val_loss: 0.0657 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.06239\n",
      "Epoch 837/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0524 - accuracy: 0.9851 - val_loss: 0.0646 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.06239\n",
      "Epoch 838/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0557 - accuracy: 0.9844 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.06239\n",
      "Epoch 839/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0523 - accuracy: 0.9859 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.06239\n",
      "Epoch 840/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0578 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.06239\n",
      "Epoch 841/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0555 - accuracy: 0.9820 - val_loss: 0.0624 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.06239\n",
      "Epoch 842/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0511 - accuracy: 0.9873 - val_loss: 0.0684 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.06239\n",
      "Epoch 843/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0564 - accuracy: 0.9837 - val_loss: 0.0717 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.06239\n",
      "Epoch 844/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0537 - accuracy: 0.9864 - val_loss: 0.0627 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.06239\n",
      "Epoch 845/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0537 - accuracy: 0.9866 - val_loss: 0.0629 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.06239\n",
      "Epoch 846/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0547 - accuracy: 0.9859 - val_loss: 0.0691 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.06239\n",
      "Epoch 847/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0550 - accuracy: 0.9844 - val_loss: 0.0648 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.06239\n",
      "Epoch 848/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0540 - accuracy: 0.9851 - val_loss: 0.0623 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00848: val_loss improved from 0.06239 to 0.06232, saving model to ./model\\848-0.0623.hdf5\n",
      "Epoch 849/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0493 - accuracy: 0.9877 - val_loss: 0.0668 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.06232\n",
      "Epoch 850/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0518 - accuracy: 0.9864 - val_loss: 0.0705 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.06232\n",
      "Epoch 851/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0541 - accuracy: 0.9866 - val_loss: 0.0610 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00851: val_loss improved from 0.06232 to 0.06096, saving model to ./model\\851-0.0610.hdf5\n",
      "Epoch 852/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0567 - accuracy: 0.9851 - val_loss: 0.0626 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.06096\n",
      "Epoch 853/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0577 - accuracy: 0.9853 - val_loss: 0.0684 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.06096\n",
      "Epoch 854/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0539 - accuracy: 0.9844 - val_loss: 0.0653 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.06096\n",
      "Epoch 855/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0588 - accuracy: 0.9833 - val_loss: 0.0651 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.06096\n",
      "Epoch 856/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0536 - accuracy: 0.9859 - val_loss: 0.0653 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.06096\n",
      "Epoch 857/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0582 - accuracy: 0.9829 - val_loss: 0.0674 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.06096\n",
      "Epoch 858/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0538 - accuracy: 0.9851 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.06096\n",
      "Epoch 859/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0521 - accuracy: 0.9875 - val_loss: 0.0630 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.06096\n",
      "Epoch 860/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0553 - accuracy: 0.9861 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 0.06096\n",
      "Epoch 861/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0504 - accuracy: 0.9844 - val_loss: 0.0650 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.06096\n",
      "Epoch 862/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0541 - accuracy: 0.9837 - val_loss: 0.0630 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.06096\n",
      "Epoch 863/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0552 - accuracy: 0.9861 - val_loss: 0.0644 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.06096\n",
      "Epoch 864/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0556 - accuracy: 0.9844 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.06096\n",
      "Epoch 865/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0523 - accuracy: 0.9844 - val_loss: 0.0631 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.06096\n",
      "Epoch 866/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0558 - accuracy: 0.9853 - val_loss: 0.0634 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.06096\n",
      "Epoch 867/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0576 - accuracy: 0.9846 - val_loss: 0.0682 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.06096\n",
      "Epoch 868/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0529 - accuracy: 0.9859 - val_loss: 0.0654 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.06096\n",
      "Epoch 869/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0570 - accuracy: 0.9839 - val_loss: 0.0627 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.06096\n",
      "Epoch 870/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0550 - accuracy: 0.9846 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.06096\n",
      "Epoch 871/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0527 - accuracy: 0.9853 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.06096\n",
      "Epoch 872/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0479 - accuracy: 0.9879 - val_loss: 0.0654 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.06096\n",
      "Epoch 873/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0521 - accuracy: 0.9820 - val_loss: 0.0652 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.06096\n",
      "Epoch 874/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0519 - accuracy: 0.9851 - val_loss: 0.0614 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.06096\n",
      "Epoch 875/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0525 - accuracy: 0.9859 - val_loss: 0.0645 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.06096\n",
      "Epoch 876/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0480 - accuracy: 0.9866 - val_loss: 0.0672 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.06096\n",
      "Epoch 877/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0515 - accuracy: 0.9859 - val_loss: 0.0655 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.06096\n",
      "Epoch 878/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0492 - accuracy: 0.9881 - val_loss: 0.0628 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.06096\n",
      "Epoch 879/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0552 - accuracy: 0.9853 - val_loss: 0.0662 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.06096\n",
      "Epoch 880/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0522 - accuracy: 0.9868 - val_loss: 0.0666 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.06096\n",
      "Epoch 881/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0503 - accuracy: 0.9866 - val_loss: 0.0641 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.06096\n",
      "Epoch 882/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0478 - accuracy: 0.9857 - val_loss: 0.0661 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 0.06096\n",
      "Epoch 883/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0512 - accuracy: 0.9866 - val_loss: 0.0686 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.06096\n",
      "Epoch 884/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0509 - accuracy: 0.9851 - val_loss: 0.0626 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.06096\n",
      "Epoch 885/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0528 - accuracy: 0.9868 - val_loss: 0.0612 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00885: val_loss did not improve from 0.06096\n",
      "Epoch 886/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0546 - accuracy: 0.9831 - val_loss: 0.0650 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.06096\n",
      "Epoch 887/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0546 - accuracy: 0.9861 - val_loss: 0.0672 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.06096\n",
      "Epoch 888/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0496 - accuracy: 0.9873 - val_loss: 0.0624 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.06096\n",
      "Epoch 889/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0506 - accuracy: 0.9859 - val_loss: 0.0633 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.06096\n",
      "Epoch 890/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0528 - accuracy: 0.9831 - val_loss: 0.0647 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.06096\n",
      "Epoch 891/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0519 - accuracy: 0.9868 - val_loss: 0.0636 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.06096\n",
      "Epoch 892/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0497 - accuracy: 0.9875 - val_loss: 0.0624 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.06096\n",
      "Epoch 893/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0502 - accuracy: 0.9844 - val_loss: 0.0629 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.06096\n",
      "Epoch 894/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0497 - accuracy: 0.9875 - val_loss: 0.0613 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.06096\n",
      "Epoch 895/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0499 - accuracy: 0.9875 - val_loss: 0.0625 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.06096\n",
      "Epoch 896/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0453 - accuracy: 0.9901 - val_loss: 0.0670 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.06096\n",
      "Epoch 897/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0540 - accuracy: 0.9844 - val_loss: 0.0652 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.06096\n",
      "Epoch 898/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0523 - accuracy: 0.9866 - val_loss: 0.0598 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00898: val_loss improved from 0.06096 to 0.05980, saving model to ./model\\898-0.0598.hdf5\n",
      "Epoch 899/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0481 - accuracy: 0.9879 - val_loss: 0.0641 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.05980\n",
      "Epoch 900/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0509 - accuracy: 0.9881 - val_loss: 0.0747 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.05980\n",
      "Epoch 901/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0569 - accuracy: 0.9816 - val_loss: 0.0603 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.05980\n",
      "Epoch 902/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0506 - accuracy: 0.9851 - val_loss: 0.0603 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.05980\n",
      "Epoch 903/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0530 - accuracy: 0.9853 - val_loss: 0.0687 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.05980\n",
      "Epoch 904/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.0705 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.05980\n",
      "Epoch 905/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0498 - accuracy: 0.9849 - val_loss: 0.0632 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.05980\n",
      "Epoch 906/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0520 - accuracy: 0.9868 - val_loss: 0.0627 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.05980\n",
      "Epoch 907/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0495 - accuracy: 0.9851 - val_loss: 0.0631 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.05980\n",
      "Epoch 908/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0520 - accuracy: 0.9868 - val_loss: 0.0670 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 0.05980\n",
      "Epoch 909/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0477 - accuracy: 0.9875 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.05980\n",
      "Epoch 910/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0479 - accuracy: 0.9875 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.05980\n",
      "Epoch 911/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0542 - accuracy: 0.9853 - val_loss: 0.0667 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.05980\n",
      "Epoch 912/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0543 - accuracy: 0.9846 - val_loss: 0.0637 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.05980\n",
      "Epoch 913/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0537 - accuracy: 0.9855 - val_loss: 0.0640 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.05980\n",
      "Epoch 914/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0496 - accuracy: 0.9866 - val_loss: 0.0642 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.05980\n",
      "Epoch 915/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0481 - accuracy: 0.9883 - val_loss: 0.0662 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.05980\n",
      "Epoch 916/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0477 - accuracy: 0.9851 - val_loss: 0.0638 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.05980\n",
      "Epoch 917/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0493 - accuracy: 0.9868 - val_loss: 0.0636 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 0.05980\n",
      "Epoch 918/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0479 - accuracy: 0.9875 - val_loss: 0.0636 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.05980\n",
      "Epoch 919/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0472 - accuracy: 0.9868 - val_loss: 0.0619 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 0.05980\n",
      "Epoch 920/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0474 - accuracy: 0.9881 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.05980\n",
      "Epoch 921/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0471 - accuracy: 0.9875 - val_loss: 0.0684 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.05980\n",
      "Epoch 922/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.05980\n",
      "Epoch 923/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0472 - accuracy: 0.9875 - val_loss: 0.0602 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.05980\n",
      "Epoch 924/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0494 - accuracy: 0.9851 - val_loss: 0.0623 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.05980\n",
      "Epoch 925/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0498 - accuracy: 0.9842 - val_loss: 0.0740 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.05980\n",
      "Epoch 926/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0515 - accuracy: 0.9829 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.05980\n",
      "Epoch 927/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0470 - accuracy: 0.9888 - val_loss: 0.0596 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00927: val_loss improved from 0.05980 to 0.05964, saving model to ./model\\927-0.0596.hdf5\n",
      "Epoch 928/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0541 - accuracy: 0.9846 - val_loss: 0.0670 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.05964\n",
      "Epoch 929/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0478 - accuracy: 0.9856 - val_loss: 0.0674 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.05964\n",
      "Epoch 930/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0508 - accuracy: 0.9853 - val_loss: 0.0599 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.05964\n",
      "Epoch 931/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0508 - accuracy: 0.9859 - val_loss: 0.0621 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.05964\n",
      "Epoch 932/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0477 - accuracy: 0.9892 - val_loss: 0.0722 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.05964\n",
      "Epoch 933/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0506 - accuracy: 0.9857 - val_loss: 0.0633 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.05964\n",
      "Epoch 934/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 0.0605 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.05964\n",
      "Epoch 935/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0475 - accuracy: 0.9868 - val_loss: 0.0645 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.05964\n",
      "Epoch 936/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0459 - accuracy: 0.9890 - val_loss: 0.0667 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.05964\n",
      "Epoch 937/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0493 - accuracy: 0.9859 - val_loss: 0.0643 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.05964\n",
      "Epoch 938/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0478 - accuracy: 0.9876 - val_loss: 0.0637 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.05964\n",
      "Epoch 939/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0463 - accuracy: 0.9890 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.05964\n",
      "Epoch 940/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0480 - accuracy: 0.9875 - val_loss: 0.0627 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.05964\n",
      "Epoch 941/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0485 - accuracy: 0.9868 - val_loss: 0.0605 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.05964\n",
      "Epoch 942/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0467 - accuracy: 0.9859 - val_loss: 0.0607 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.05964\n",
      "Epoch 943/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0512 - accuracy: 0.9839 - val_loss: 0.0631 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.05964\n",
      "Epoch 944/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0471 - accuracy: 0.9890 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.05964\n",
      "Epoch 945/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0481 - accuracy: 0.9868 - val_loss: 0.0666 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.05964\n",
      "Epoch 946/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0454 - accuracy: 0.9866 - val_loss: 0.0642 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.05964\n",
      "Epoch 947/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0430 - accuracy: 0.9888 - val_loss: 0.0615 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.05964\n",
      "Epoch 948/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.9875 - val_loss: 0.0622 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.05964\n",
      "Epoch 949/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0500 - accuracy: 0.9855 - val_loss: 0.0602 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.05964\n",
      "Epoch 950/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.05964\n",
      "Epoch 951/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0477 - accuracy: 0.9866 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.05964\n",
      "Epoch 952/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.9846 - val_loss: 0.0631 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.05964\n",
      "Epoch 953/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0481 - accuracy: 0.9868 - val_loss: 0.0638 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.05964\n",
      "Epoch 954/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0449 - accuracy: 0.9883 - val_loss: 0.0638 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.05964\n",
      "Epoch 955/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0450 - accuracy: 0.9881 - val_loss: 0.0638 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.05964\n",
      "Epoch 956/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0449 - accuracy: 0.9890 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.05964\n",
      "Epoch 957/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0430 - accuracy: 0.9888 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.05964\n",
      "Epoch 958/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.9868 - val_loss: 0.0613 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.05964\n",
      "Epoch 959/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0438 - accuracy: 0.9881 - val_loss: 0.0613 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.05964\n",
      "Epoch 960/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0468 - accuracy: 0.9876 - val_loss: 0.0641 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.05964\n",
      "Epoch 961/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0450 - accuracy: 0.9896 - val_loss: 0.0652 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.05964\n",
      "Epoch 962/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0444 - accuracy: 0.9875 - val_loss: 0.0622 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.05964\n",
      "Epoch 963/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0432 - accuracy: 0.9890 - val_loss: 0.0618 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.05964\n",
      "Epoch 964/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0477 - accuracy: 0.9876 - val_loss: 0.0644 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.05964\n",
      "Epoch 965/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0459 - accuracy: 0.9873 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.05964\n",
      "Epoch 966/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0468 - accuracy: 0.9875 - val_loss: 0.0626 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.05964\n",
      "Epoch 967/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0463 - accuracy: 0.9898 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.05964\n",
      "Epoch 968/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0472 - accuracy: 0.9870 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.05964\n",
      "Epoch 969/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0418 - accuracy: 0.9896 - val_loss: 0.0621 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00969: val_loss did not improve from 0.05964\n",
      "Epoch 970/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0442 - accuracy: 0.9890 - val_loss: 0.0655 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.05964\n",
      "Epoch 971/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0413 - accuracy: 0.9886 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.05964\n",
      "Epoch 972/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0450 - accuracy: 0.9837 - val_loss: 0.0636 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.05964\n",
      "Epoch 973/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 0.0610 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.05964\n",
      "Epoch 974/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0468 - accuracy: 0.9868 - val_loss: 0.0599 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 0.05964\n",
      "Epoch 975/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0490 - accuracy: 0.9846 - val_loss: 0.0646 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.05964\n",
      "Epoch 976/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0430 - accuracy: 0.9851 - val_loss: 0.0627 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.05964\n",
      "Epoch 977/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0459 - accuracy: 0.9898 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.05964\n",
      "Epoch 978/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0454 - accuracy: 0.9866 - val_loss: 0.0629 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.05964\n",
      "Epoch 979/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0464 - accuracy: 0.9876 - val_loss: 0.0690 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.05964\n",
      "Epoch 980/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.0626 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.05964\n",
      "Epoch 981/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0431 - accuracy: 0.9896 - val_loss: 0.0600 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.05964\n",
      "Epoch 982/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0475 - accuracy: 0.9868 - val_loss: 0.0661 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.05964\n",
      "Epoch 983/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0499 - accuracy: 0.9855 - val_loss: 0.0692 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.05964\n",
      "Epoch 984/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0450 - accuracy: 0.9875 - val_loss: 0.0594 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00984: val_loss improved from 0.05964 to 0.05945, saving model to ./model\\984-0.0594.hdf5\n",
      "Epoch 985/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.9875 - val_loss: 0.0591 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00985: val_loss improved from 0.05945 to 0.05912, saving model to ./model\\985-0.0591.hdf5\n",
      "Epoch 986/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0440 - accuracy: 0.9881 - val_loss: 0.0683 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.05912\n",
      "Epoch 987/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.9837 - val_loss: 0.0713 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.05912\n",
      "Epoch 988/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 0.0603 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.05912\n",
      "Epoch 989/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0468 - accuracy: 0.9853 - val_loss: 0.0587 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00989: val_loss improved from 0.05912 to 0.05870, saving model to ./model\\989-0.0587.hdf5\n",
      "Epoch 990/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0455 - accuracy: 0.9868 - val_loss: 0.0650 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.05870\n",
      "Epoch 991/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0483 - accuracy: 0.9853 - val_loss: 0.0637 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.05870\n",
      "Epoch 992/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0440 - accuracy: 0.9851 - val_loss: 0.0607 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.05870\n",
      "Epoch 993/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0411 - accuracy: 0.9888 - val_loss: 0.0654 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.05870\n",
      "Epoch 994/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0467 - accuracy: 0.9844 - val_loss: 0.0645 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.05870\n",
      "Epoch 995/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0490 - accuracy: 0.9833 - val_loss: 0.0594 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.05870\n",
      "Epoch 996/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0435 - accuracy: 0.9888 - val_loss: 0.0612 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.05870\n",
      "Epoch 997/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 0.0670 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.05870\n",
      "Epoch 998/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 0.0603 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.05870\n",
      "Epoch 999/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0449 - accuracy: 0.9883 - val_loss: 0.0598 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.05870\n",
      "Epoch 1000/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0473 - accuracy: 0.9876 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.05870\n",
      "Epoch 1001/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0412 - accuracy: 0.9881 - val_loss: 0.0675 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 0.05870\n",
      "Epoch 1002/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 0.9853 - val_loss: 0.0637 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 0.05870\n",
      "Epoch 1003/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0449 - accuracy: 0.9883 - val_loss: 0.0605 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 0.05870\n",
      "Epoch 1004/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0456 - accuracy: 0.9837 - val_loss: 0.0628 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 0.05870\n",
      "Epoch 1005/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0473 - accuracy: 0.9855 - val_loss: 0.0625 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 0.05870\n",
      "Epoch 1006/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0464 - accuracy: 0.9876 - val_loss: 0.0614 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 0.05870\n",
      "Epoch 1007/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0403 - accuracy: 0.9905 - val_loss: 0.0640 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 0.05870\n",
      "Epoch 1008/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0416 - accuracy: 0.9873 - val_loss: 0.0672 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 0.05870\n",
      "Epoch 1009/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0630 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 0.05870\n",
      "Epoch 1010/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0429 - accuracy: 0.9890 - val_loss: 0.0583 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01010: val_loss improved from 0.05870 to 0.05827, saving model to ./model\\1010-0.0583.hdf5\n",
      "Epoch 1011/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.0634 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 0.05827\n",
      "Epoch 1012/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0433 - accuracy: 0.9873 - val_loss: 0.0689 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 0.05827\n",
      "Epoch 1013/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0469 - accuracy: 0.9837 - val_loss: 0.0611 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 0.05827\n",
      "Epoch 1014/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0446 - accuracy: 0.9868 - val_loss: 0.0622 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 0.05827\n",
      "Epoch 1015/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0407 - accuracy: 0.9912 - val_loss: 0.0640 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 0.05827\n",
      "Epoch 1016/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0427 - accuracy: 0.9859 - val_loss: 0.0644 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 0.05827\n",
      "Epoch 1017/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0427 - accuracy: 0.9876 - val_loss: 0.0601 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 0.05827\n",
      "Epoch 1018/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0425 - accuracy: 0.9873 - val_loss: 0.0605 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 0.05827\n",
      "Epoch 1019/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0472 - accuracy: 0.9885 - val_loss: 0.0676 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 0.05827\n",
      "Epoch 1020/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0471 - accuracy: 0.9822 - val_loss: 0.0608 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 0.05827\n",
      "Epoch 1021/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0408 - accuracy: 0.9905 - val_loss: 0.0608 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 0.05827\n",
      "Epoch 1022/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0413 - accuracy: 0.9896 - val_loss: 0.0649 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 0.05827\n",
      "Epoch 1023/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0399 - accuracy: 0.9879 - val_loss: 0.0662 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 0.05827\n",
      "Epoch 1024/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0463 - accuracy: 0.9846 - val_loss: 0.0602 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 0.05827\n",
      "Epoch 1025/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0401 - accuracy: 0.9888 - val_loss: 0.0598 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 0.05827\n",
      "Epoch 1026/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 0.0660 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 0.05827\n",
      "Epoch 1027/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 0.9837 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 0.05827\n",
      "Epoch 1028/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0402 - accuracy: 0.9881 - val_loss: 0.0643 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 0.05827\n",
      "Epoch 1029/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0439 - accuracy: 0.9876 - val_loss: 0.0621 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 0.05827\n",
      "Epoch 1030/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 0.9870 - val_loss: 0.0623 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 0.05827\n",
      "Epoch 1031/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0467 - accuracy: 0.9861 - val_loss: 0.0627 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 0.05827\n",
      "Epoch 1032/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 0.0602 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 0.05827\n",
      "Epoch 1033/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.0618 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 0.05827\n",
      "Epoch 1034/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.9903 - val_loss: 0.0674 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 0.05827\n",
      "Epoch 1035/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0434 - accuracy: 0.9859 - val_loss: 0.0628 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 0.05827\n",
      "Epoch 1036/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0417 - accuracy: 0.9876 - val_loss: 0.0584 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 0.05827\n",
      "Epoch 1037/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0460 - accuracy: 0.9861 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 0.05827\n",
      "Epoch 1038/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0454 - accuracy: 0.9876 - val_loss: 0.0649 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 0.05827\n",
      "Epoch 1039/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0438 - accuracy: 0.9853 - val_loss: 0.0644 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 0.05827\n",
      "Epoch 1040/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0399 - accuracy: 0.9859 - val_loss: 0.0650 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 0.05827\n",
      "Epoch 1041/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 0.05827\n",
      "Epoch 1042/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0438 - accuracy: 0.9900 - val_loss: 0.0585 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 0.05827\n",
      "Epoch 1043/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0459 - accuracy: 0.9868 - val_loss: 0.0628 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 0.05827\n",
      "Epoch 1044/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0447 - accuracy: 0.9842 - val_loss: 0.0658 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 0.05827\n",
      "Epoch 1045/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0413 - accuracy: 0.9876 - val_loss: 0.0586 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 0.05827\n",
      "Epoch 1046/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.0592 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 0.05827\n",
      "Epoch 1047/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0430 - accuracy: 0.9883 - val_loss: 0.0658 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 0.05827\n",
      "Epoch 1048/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0435 - accuracy: 0.9859 - val_loss: 0.0657 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 0.05827\n",
      "Epoch 1049/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0422 - accuracy: 0.9876 - val_loss: 0.0601 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 0.05827\n",
      "Epoch 1050/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0432 - accuracy: 0.9881 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 0.05827\n",
      "Epoch 1051/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0463 - accuracy: 0.9870 - val_loss: 0.0680 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 0.05827\n",
      "Epoch 1052/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0400 - accuracy: 0.9851 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 0.05827\n",
      "Epoch 1053/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0427 - accuracy: 0.9898 - val_loss: 0.0621 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 0.05827\n",
      "Epoch 1054/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 0.0658 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 0.05827\n",
      "Epoch 1055/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 0.05827\n",
      "Epoch 1056/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0405 - accuracy: 0.9881 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 0.05827\n",
      "Epoch 1057/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0417 - accuracy: 0.9875 - val_loss: 0.0638 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 0.05827\n",
      "Epoch 1058/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0424 - accuracy: 0.9859 - val_loss: 0.0601 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 0.05827\n",
      "Epoch 1059/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0404 - accuracy: 0.9896 - val_loss: 0.0574 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01059: val_loss improved from 0.05827 to 0.05738, saving model to ./model\\1059-0.0574.hdf5\n",
      "Epoch 1060/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0423 - accuracy: 0.9883 - val_loss: 0.0622 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 0.05738\n",
      "Epoch 1061/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 0.05738\n",
      "Epoch 1062/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0444 - accuracy: 0.9846 - val_loss: 0.0591 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 0.05738\n",
      "Epoch 1063/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0400 - accuracy: 0.9873 - val_loss: 0.0617 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 0.05738\n",
      "Epoch 1064/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.0686 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 0.05738\n",
      "Epoch 1065/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.0622 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 0.05738\n",
      "Epoch 1066/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0433 - accuracy: 0.9885 - val_loss: 0.0604 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 0.05738\n",
      "Epoch 1067/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0371 - accuracy: 0.9925 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 0.05738\n",
      "Epoch 1068/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0427 - accuracy: 0.9851 - val_loss: 0.0654 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 0.05738\n",
      "Epoch 1069/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0418 - accuracy: 0.9868 - val_loss: 0.0605 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 0.05738\n",
      "Epoch 1070/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0426 - accuracy: 0.9900 - val_loss: 0.0599 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 0.05738\n",
      "Epoch 1071/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 0.05738\n",
      "Epoch 1072/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0422 - accuracy: 0.9875 - val_loss: 0.0667 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 0.05738\n",
      "Epoch 1073/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0380 - accuracy: 0.9866 - val_loss: 0.0618 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 0.05738\n",
      "Epoch 1074/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0412 - accuracy: 0.9885 - val_loss: 0.0602 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 0.05738\n",
      "Epoch 1075/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0389 - accuracy: 0.9905 - val_loss: 0.0618 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 0.05738\n",
      "Epoch 1076/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0410 - accuracy: 0.9868 - val_loss: 0.0646 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 0.05738\n",
      "Epoch 1077/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.0618 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 0.05738\n",
      "Epoch 1078/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0400 - accuracy: 0.9905 - val_loss: 0.0628 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 0.05738\n",
      "Epoch 1079/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0448 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 0.05738\n",
      "Epoch 1080/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0401 - accuracy: 0.9883 - val_loss: 0.0626 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 0.05738\n",
      "Epoch 1081/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0400 - accuracy: 0.9905 - val_loss: 0.0610 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 0.05738\n",
      "Epoch 1082/3500\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 0.05738\n",
      "Epoch 1083/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0402 - accuracy: 0.9896 - val_loss: 0.0608 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 0.05738\n",
      "Epoch 1084/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.9883 - val_loss: 0.0619 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 0.05738\n",
      "Epoch 1085/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 0.05738\n",
      "Epoch 1086/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.9876 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 0.05738\n",
      "Epoch 1087/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0389 - accuracy: 0.9898 - val_loss: 0.0650 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 0.05738\n",
      "Epoch 1088/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0412 - accuracy: 0.9881 - val_loss: 0.0652 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 0.05738\n",
      "Epoch 1089/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0407 - accuracy: 0.9853 - val_loss: 0.0599 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 0.05738\n",
      "Epoch 1090/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0429 - accuracy: 0.9876 - val_loss: 0.0637 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 0.05738\n",
      "Epoch 1091/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0394 - accuracy: 0.9881 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 0.05738\n",
      "Epoch 1092/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0395 - accuracy: 0.9861 - val_loss: 0.0612 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 0.05738\n",
      "Epoch 1093/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0383 - accuracy: 0.9896 - val_loss: 0.0617 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 0.05738\n",
      "Epoch 1094/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 0.9898 - val_loss: 0.0638 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01094: val_loss did not improve from 0.05738\n",
      "Epoch 1095/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.0622 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 0.05738\n",
      "Epoch 1096/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0393 - accuracy: 0.9859 - val_loss: 0.0586 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 0.05738\n",
      "Epoch 1097/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 0.0572 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01097: val_loss improved from 0.05738 to 0.05720, saving model to ./model\\1097-0.0572.hdf5\n",
      "Epoch 1098/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0422 - accuracy: 0.9853 - val_loss: 0.0625 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 0.05720\n",
      "Epoch 1099/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0400 - accuracy: 0.9898 - val_loss: 0.0682 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 0.05720\n",
      "Epoch 1100/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0389 - accuracy: 0.9861 - val_loss: 0.0621 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 0.05720\n",
      "Epoch 1101/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0387 - accuracy: 0.9896 - val_loss: 0.0613 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 0.05720\n",
      "Epoch 1102/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0412 - accuracy: 0.9892 - val_loss: 0.0680 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 0.05720\n",
      "Epoch 1103/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0424 - accuracy: 0.9844 - val_loss: 0.0644 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 0.05720\n",
      "Epoch 1104/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.0614 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 0.05720\n",
      "Epoch 1105/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0411 - accuracy: 0.9892 - val_loss: 0.0645 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 0.05720\n",
      "Epoch 1106/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 0.05720\n",
      "Epoch 1107/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0401 - accuracy: 0.9892 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 0.05720\n",
      "Epoch 1108/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.0634 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 0.05720\n",
      "Epoch 1109/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0386 - accuracy: 0.9896 - val_loss: 0.0634 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 0.05720\n",
      "Epoch 1110/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.0594 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 0.05720\n",
      "Epoch 1111/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0399 - accuracy: 0.9896 - val_loss: 0.0587 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 0.05720\n",
      "Epoch 1112/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.0676 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 0.05720\n",
      "Epoch 1113/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0419 - accuracy: 0.9831 - val_loss: 0.0655 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 0.05720\n",
      "Epoch 1114/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 0.9875 - val_loss: 0.0593 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 0.05720\n",
      "Epoch 1115/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0367 - accuracy: 0.9881 - val_loss: 0.0598 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 0.05720\n",
      "Epoch 1116/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0376 - accuracy: 0.9914 - val_loss: 0.0669 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 0.05720\n",
      "Epoch 1117/3500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0448 - accuracy: 0.9831 - val_loss: 0.0649 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 0.05720\n",
      "Epoch 1118/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0370 - accuracy: 0.9851 - val_loss: 0.0604 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 0.05720\n",
      "Epoch 1119/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0399 - accuracy: 0.9881 - val_loss: 0.0660 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 0.05720\n",
      "Epoch 1120/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0385 - accuracy: 0.9844 - val_loss: 0.0709 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 0.05720\n",
      "Epoch 1121/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0409 - accuracy: 0.9853 - val_loss: 0.0593 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 0.05720\n",
      "Epoch 1122/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0427 - accuracy: 0.9855 - val_loss: 0.0590 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 0.05720\n",
      "Epoch 1123/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0449 - accuracy: 0.9839 - val_loss: 0.0636 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 0.05720\n",
      "Epoch 1124/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 0.05720\n",
      "Epoch 1125/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0396 - accuracy: 0.9868 - val_loss: 0.0589 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 0.05720\n",
      "Epoch 1126/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0397 - accuracy: 0.9868 - val_loss: 0.0592 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 0.05720\n",
      "Epoch 1127/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0378 - accuracy: 0.9883 - val_loss: 0.0653 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 0.05720\n",
      "Epoch 1128/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0416 - accuracy: 0.9831 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 0.05720\n",
      "Epoch 1129/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0382 - accuracy: 0.9861 - val_loss: 0.0612 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 0.05720\n",
      "Epoch 1130/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 0.0624 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 0.05720\n",
      "Epoch 1131/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0351 - accuracy: 0.9912 - val_loss: 0.0712 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 0.05720\n",
      "Epoch 1132/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0384 - accuracy: 0.9875 - val_loss: 0.0668 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 0.05720\n",
      "Epoch 1133/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 0.0577 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 0.05720\n",
      "Epoch 1134/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0410 - accuracy: 0.9861 - val_loss: 0.0583 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 0.05720\n",
      "Epoch 1135/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0408 - accuracy: 0.9876 - val_loss: 0.0628 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 0.05720\n",
      "Epoch 1136/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0389 - accuracy: 0.9896 - val_loss: 0.0645 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 0.05720\n",
      "Epoch 1137/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0369 - accuracy: 0.9883 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 0.05720\n",
      "Epoch 1138/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0368 - accuracy: 0.9920 - val_loss: 0.0619 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 0.05720\n",
      "Epoch 1139/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0359 - accuracy: 0.9905 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 0.05720\n",
      "Epoch 1140/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0388 - accuracy: 0.9844 - val_loss: 0.0655 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 0.05720\n",
      "Epoch 1141/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0384 - accuracy: 0.9846 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 0.05720\n",
      "Epoch 1142/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0369 - accuracy: 0.9907 - val_loss: 0.0601 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 0.05720\n",
      "Epoch 1143/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0393 - accuracy: 0.9907 - val_loss: 0.0627 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 0.05720\n",
      "Epoch 1144/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 0.05720\n",
      "Epoch 1145/3500\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0378 - accuracy: 0.9881 - val_loss: 0.0610 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 0.05720\n",
      "Epoch 1146/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 0.0621 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 0.05720\n",
      "Epoch 1147/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0385 - accuracy: 0.9892 - val_loss: 0.0630 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 0.05720\n",
      "Epoch 1148/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0356 - accuracy: 0.9905 - val_loss: 0.0638 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 0.05720\n",
      "Epoch 1149/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0366 - accuracy: 0.9898 - val_loss: 0.0674 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 0.05720\n",
      "Epoch 1150/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0359 - accuracy: 0.9883 - val_loss: 0.0636 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 0.05720\n",
      "Epoch 1151/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.0637 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 0.05720\n",
      "Epoch 1152/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0377 - accuracy: 0.9907 - val_loss: 0.0662 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 0.05720\n",
      "Epoch 1153/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0391 - accuracy: 0.9857 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 0.05720\n",
      "Epoch 1154/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0354 - accuracy: 0.9927 - val_loss: 0.0589 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 0.05720\n",
      "Epoch 1155/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0387 - accuracy: 0.9853 - val_loss: 0.0636 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 0.05720\n",
      "Epoch 1156/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0343 - accuracy: 0.9920 - val_loss: 0.0677 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 0.05720\n",
      "Epoch 1157/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0405 - accuracy: 0.9816 - val_loss: 0.0629 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 0.05720\n",
      "Epoch 1158/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0393 - accuracy: 0.9863 - val_loss: 0.0599 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 0.05720\n",
      "Epoch 1159/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 0.9881 - val_loss: 0.0621 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 0.05720\n",
      "Epoch 1160/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 0.9905 - val_loss: 0.0698 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 0.05720\n",
      "Epoch 1161/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0369 - accuracy: 0.9859 - val_loss: 0.0637 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 0.05720\n",
      "Epoch 1162/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0347 - accuracy: 0.9898 - val_loss: 0.0598 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 0.05720\n",
      "Epoch 1163/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 0.9883 - val_loss: 0.0627 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 0.05720\n",
      "Epoch 1164/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.0684 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 0.05720\n",
      "Epoch 1165/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0387 - accuracy: 0.9831 - val_loss: 0.0611 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 0.05720\n",
      "Epoch 1166/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 0.0604 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 0.05720\n",
      "Epoch 1167/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0368 - accuracy: 0.9866 - val_loss: 0.0689 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 0.05720\n",
      "Epoch 1168/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0373 - accuracy: 0.9866 - val_loss: 0.0638 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 0.05720\n",
      "Epoch 1169/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.0598 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 0.05720\n",
      "Epoch 1170/3500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.0618 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 0.05720\n",
      "Epoch 1171/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 0.05720\n",
      "Epoch 1172/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0375 - accuracy: 0.9892 - val_loss: 0.0630 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 0.05720\n",
      "Epoch 1173/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0337 - accuracy: 0.9920 - val_loss: 0.0633 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 0.05720\n",
      "Epoch 1174/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.0687 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 0.05720\n",
      "Epoch 1175/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 0.0643 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 0.05720\n",
      "Epoch 1176/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0370 - accuracy: 0.9898 - val_loss: 0.0578 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 0.05720\n",
      "Epoch 1177/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0376 - accuracy: 0.9873 - val_loss: 0.0609 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 0.05720\n",
      "Epoch 1178/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0380 - accuracy: 0.9875 - val_loss: 0.0697 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 0.05720\n",
      "Epoch 1179/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0359 - accuracy: 0.9857 - val_loss: 0.0644 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 0.05720\n",
      "Epoch 1180/3500\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0330 - accuracy: 0.9883 - val_loss: 0.0638 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 0.05720\n",
      "Epoch 1181/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0378 - accuracy: 0.9898 - val_loss: 0.0653 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 0.05720\n",
      "Epoch 1182/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0365 - accuracy: 0.9898 - val_loss: 0.0652 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 0.05720\n",
      "Epoch 1183/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.0657 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 0.05720\n",
      "Epoch 1184/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0368 - accuracy: 0.9868 - val_loss: 0.0600 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 0.05720\n",
      "Epoch 1185/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0379 - accuracy: 0.9875 - val_loss: 0.0614 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 0.05720\n",
      "Epoch 1186/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 0.0681 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 0.05720\n",
      "Epoch 1187/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0356 - accuracy: 0.9888 - val_loss: 0.0656 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 0.05720\n",
      "Epoch 1188/3500\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0358 - accuracy: 0.9900 - val_loss: 0.0625 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 0.05720\n",
      "Epoch 1189/3500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.0625 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 0.05720\n",
      "Epoch 1190/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 0.0642 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 0.05720\n",
      "Epoch 1191/3500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0347 - accuracy: 0.9875 - val_loss: 0.0679 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 0.05720\n",
      "Epoch 1192/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0346 - accuracy: 0.9871 - val_loss: 0.0621 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 0.05720\n",
      "Epoch 1193/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0333 - accuracy: 0.9914 - val_loss: 0.0603 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 0.05720\n",
      "Epoch 1194/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0400 - accuracy: 0.9859 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 0.05720\n",
      "Epoch 1195/3500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0750 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 0.05720\n",
      "Epoch 1196/3500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0398 - accuracy: 0.9868 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 0.05720\n",
      "Epoch 1197/3500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0344 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 0.05720\n",
      "31/31 [==============================] - 0s 734us/step - loss: 0.0432 - accuracy: 0.9867\n",
      "\n",
      " Accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df_pre = pd.read_csv(\"wine.csv\", header = None)\n",
    "df = df_pre.sample(frac = 0.15)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:12].astype(float)\n",
    "Y = dataset[:,12]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 12, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam', metrics = ['accuracy'])\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss',\n",
    "                               verbose = 1, save_best_only = True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 100)\n",
    "\n",
    "model.fit(X, Y, validation_split = 0.2, epochs = 3500,\n",
    "          batch_size = 500, callbacks = [early_stopping_callback, checkpointer])\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" %(model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ac70f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 880us/step - loss: 20056.3142\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 899us/step - loss: 1925.3600\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 910us/step - loss: 703.1190\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 884us/step - loss: 625.2917\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 868us/step - loss: 613.6478\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 846us/step - loss: 644.6751\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 844us/step - loss: 605.0916\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 877us/step - loss: 655.1075\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 862us/step - loss: 657.1848\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 861us/step - loss: 585.4776\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 936us/step - loss: 588.6399\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 624.4650\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 884us/step - loss: 582.7648\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 864us/step - loss: 591.1735\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 940us/step - loss: 575.8204\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 835us/step - loss: 573.7284\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 879us/step - loss: 556.6114\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 876us/step - loss: 594.8052\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 959us/step - loss: 591.9369\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 905us/step - loss: 557.2388\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 887us/step - loss: 573.6880\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 993us/step - loss: 636.7092\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 935us/step - loss: 638.0409\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 987us/step - loss: 537.1685\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 580.2076\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 937us/step - loss: 600.4361\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 998us/step - loss: 543.4191\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 957us/step - loss: 575.4675\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 1000us/step - loss: 589.4611\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 838us/step - loss: 528.4308\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 839us/step - loss: 584.8097\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 811us/step - loss: 601.6177\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 899us/step - loss: 547.6582\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 946us/step - loss: 544.9698\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 918us/step - loss: 552.1075\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 908us/step - loss: 589.0301\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 836us/step - loss: 578.3629\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 915us/step - loss: 549.5205\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 875us/step - loss: 564.7297\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 873us/step - loss: 565.3115\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 897us/step - loss: 545.1444\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 918us/step - loss: 549.1719\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 898us/step - loss: 524.6942\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 917us/step - loss: 535.9515\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 946us/step - loss: 578.4608\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 899us/step - loss: 537.8080\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 938us/step - loss: 568.4175\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 937us/step - loss: 557.8393\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 531.8066\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 910us/step - loss: 544.4990\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 813us/step - loss: 539.6316\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 880us/step - loss: 537.8266\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 835us/step - loss: 556.4634\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 863us/step - loss: 491.6547\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 802us/step - loss: 520.6314\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 851us/step - loss: 518.7387\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 886us/step - loss: 543.0636\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 871us/step - loss: 544.6312\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 920us/step - loss: 551.3309\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 871us/step - loss: 539.8721\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 837us/step - loss: 529.6416\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 768us/step - loss: 542.1569\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 858us/step - loss: 506.1036\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 865us/step - loss: 523.5403\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 851us/step - loss: 574.0648\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 842us/step - loss: 522.4294\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 875us/step - loss: 491.4148\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 881us/step - loss: 540.7912\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 905us/step - loss: 587.4165\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 901us/step - loss: 528.0022\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 864us/step - loss: 522.5532\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 885us/step - loss: 516.1058\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 879us/step - loss: 553.6214\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 911us/step - loss: 520.3049\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 778us/step - loss: 500.3841\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 817us/step - loss: 466.9413\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 833us/step - loss: 498.5484\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 869us/step - loss: 518.2746\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 866us/step - loss: 559.8065\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 864us/step - loss: 507.7163\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 875us/step - loss: 554.3756\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 888us/step - loss: 495.9535\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 863us/step - loss: 469.1505\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 854us/step - loss: 512.9999\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 873us/step - loss: 486.7375\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 793us/step - loss: 510.8042\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 897us/step - loss: 487.0838\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 810us/step - loss: 461.6878\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 852us/step - loss: 506.7113\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 837us/step - loss: 500.9126\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 914us/step - loss: 501.5503\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 872us/step - loss: 539.6747\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 842us/step - loss: 505.8486\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 898us/step - loss: 489.0862\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 873us/step - loss: 514.9008\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 862us/step - loss: 460.9589\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 883us/step - loss: 485.4952\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 933us/step - loss: 478.3689\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 856us/step - loss: 495.7088\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 861us/step - loss: 498.1565\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 849us/step - loss: 465.2672\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 864us/step - loss: 492.9280\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 868us/step - loss: 491.3417\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 871us/step - loss: 468.2072\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 848us/step - loss: 493.9959\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 832us/step - loss: 475.0261\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 879us/step - loss: 458.5545\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 919us/step - loss: 462.0478\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 883us/step - loss: 460.6328\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 903us/step - loss: 447.8090\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 843us/step - loss: 445.0778\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 894us/step - loss: 450.6251\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 898us/step - loss: 446.4406\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 851us/step - loss: 451.5509\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 823us/step - loss: 493.1429\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 822us/step - loss: 459.2191\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 854us/step - loss: 463.9514\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 835us/step - loss: 473.9589\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 804us/step - loss: 435.4305\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 850us/step - loss: 433.5233\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 859us/step - loss: 436.6218\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 859us/step - loss: 453.3460\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 778us/step - loss: 413.7564\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 814us/step - loss: 463.6218\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 855us/step - loss: 444.1847\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 753us/step - loss: 453.9823\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 858us/step - loss: 446.6421\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 869us/step - loss: 437.0849\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 874us/step - loss: 433.7368\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 838us/step - loss: 427.5089\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 837us/step - loss: 420.5056\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 847us/step - loss: 446.8712\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 859us/step - loss: 396.7505\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 788us/step - loss: 451.2230\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 759us/step - loss: 418.6413\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 901us/step - loss: 421.6675\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 870us/step - loss: 446.4975\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 840us/step - loss: 398.9685\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 807us/step - loss: 432.9840\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 821us/step - loss: 400.8836\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 832us/step - loss: 422.7386\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 921us/step - loss: 438.5408\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 816us/step - loss: 446.1200\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 850us/step - loss: 432.5497\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 822us/step - loss: 410.9626\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 788us/step - loss: 417.5075\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 826us/step - loss: 410.7527\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 839us/step - loss: 425.4022\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 838us/step - loss: 434.9836\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 843us/step - loss: 396.2038\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 794us/step - loss: 403.0158\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 823us/step - loss: 391.8021\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 819us/step - loss: 437.2737\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 423.2416\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 867us/step - loss: 379.8897\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 895us/step - loss: 395.6355\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 830us/step - loss: 390.9288\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 827us/step - loss: 428.8663\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 844us/step - loss: 401.8438\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 835us/step - loss: 400.9731\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 823us/step - loss: 389.2178\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 857us/step - loss: 433.3372\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 827us/step - loss: 415.6783\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 841us/step - loss: 394.3323\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 804us/step - loss: 412.6851\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 828us/step - loss: 367.1164\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 839us/step - loss: 401.2691\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 776us/step - loss: 378.7510\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 738us/step - loss: 423.1260\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 832us/step - loss: 399.2438\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 833us/step - loss: 377.8350\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 841us/step - loss: 408.8091\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 802us/step - loss: 375.2147\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 855us/step - loss: 404.2991\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 901us/step - loss: 389.5346\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 814us/step - loss: 402.6724\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 815us/step - loss: 382.1493\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 736us/step - loss: 413.3587\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 807us/step - loss: 373.5380\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 887us/step - loss: 362.7466\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 791us/step - loss: 335.0890\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 781us/step - loss: 399.7486\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 871us/step - loss: 358.8600\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 830us/step - loss: 376.1984\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 842us/step - loss: 340.2740\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 858us/step - loss: 351.1768\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 840us/step - loss: 395.9186\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 831us/step - loss: 359.6727\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 842us/step - loss: 359.4495\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 820us/step - loss: 384.8935\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 867us/step - loss: 383.9878\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 800us/step - loss: 394.6139\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 866us/step - loss: 350.4856\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 878us/step - loss: 351.1759\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 871us/step - loss: 382.2243\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 795us/step - loss: 362.2807\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 825us/step - loss: 334.7218\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 814us/step - loss: 319.1050\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 842us/step - loss: 337.7007\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 834us/step - loss: 375.8077\n",
      "실제 가격: 22.600, 예상 가격: 6.342\n",
      "실제 가격: 50.000, 예상 가격: 6.342\n",
      "실제 가격: 23.000, 예상 가격: 6.342\n",
      "실제 가격: 8.300, 예상 가격: 6.342\n",
      "실제 가격: 21.200, 예상 가격: 6.342\n",
      "실제 가격: 19.900, 예상 가격: 6.342\n",
      "실제 가격: 20.600, 예상 가격: 6.342\n",
      "실제 가격: 18.700, 예상 가격: 6.342\n",
      "실제 가격: 16.100, 예상 가격: 6.342\n",
      "실제 가격: 18.600, 예상 가격: 6.342\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv(\"housing.csv\", delim_whitespace = True, header = None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y , test_size = 0.3, random_state = seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 13, activation = 'relu'))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error',\n",
    "              optimizer = 'adam')\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = 200, batch_size = 10)\n",
    "\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제 가격: {:.3f}, 예상 가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "29a71a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 이미지 수: 60000 개\n",
      "테스트셋 이미지 수: 10000 개\n",
      "class: 5 \n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()\n",
    "\n",
    "print(\"학습셋 이미지 수: %d 개\" %(X_train.shape[0]))\n",
    "print(\"테스트셋 이미지 수: %d 개\" %(X_test.shape[0]))\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 784)\n",
    "X_train = X_train.astype('float64')\n",
    "X_train = X_train / 255\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float64')  / 255\n",
    "\n",
    "print(\"class: %d \" %(Y_class_train[0]))\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_class_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_class_test, 10)\n",
    "\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60e9d427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 이미지 수: 60000 개\n",
      "테스트셋 이미지 수: 10000 개\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 22.4 GiB for an array with shape (600000000, 10) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22592\\277192282.py\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m   \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 22.4 GiB for an array with shape (600000000, 10) and data type float32"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss',\n",
    "                               verbose = 1, save_best_only = True)\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test),\n",
    "                    epochs = 30, batch_size = 200, verbose = 0,\n",
    "                    callbacks = [early_stopping_callback, checkpointer])\n",
    "\n",
    "print(\"\\n Test Accuracy: %.4f\" %(model.evaliate(X_test, Y_test)[1]))\n",
    "\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = numpy.arange(len(y_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06747fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 이미지 수: 60000 개\n",
      "테스트셋 이미지 수: 10000 개\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14743, saving model to ./model\\01-0.1474.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14743 to 0.10209, saving model to ./model\\02-0.1021.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10209 to 0.08910, saving model to ./model\\03-0.0891.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08910 to 0.07802, saving model to ./model\\04-0.0780.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07802 to 0.07368, saving model to ./model\\05-0.0737.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07368 to 0.06732, saving model to ./model\\06-0.0673.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06732 to 0.06503, saving model to ./model\\07-0.0650.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06503 to 0.06252, saving model to ./model\\08-0.0625.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06252\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06252\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06252\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06252\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06252 to 0.06013, saving model to ./model\\13-0.0601.hdf5\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06013\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06013\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06013\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06013\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06013\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06013\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06013\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06013\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06013\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06013\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0677 - accuracy: 0.9832\n",
      "\n",
      " Test Accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "#from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "print(\"학습셋 이미지 수: %d 개\" %(X_train.shape[0]))\n",
    "print(\"테스트셋 이미지 수: %d 개\" %(X_test.shape[0]))\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 784).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float32')  / 255\n",
    "\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim = 784, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor = 'val_loss',\n",
    "                               verbose = 1, save_best_only = True)\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test),\n",
    "                    epochs = 30, batch_size = 200, verbose = 0,\n",
    "                    callbacks = [early_stopping_callback, checkpointer])\n",
    "\n",
    "print(\"\\n Test Accuracy: %.4f\" %(model.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker = '.', c = 'red', label = 'Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker = '.', c = 'blue', label = 'Trainset_loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
